{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavya2004/molgeo/blob/main/GNN_Shapes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "becOLMJ42Z5w",
        "outputId": "e88244bf-b568-4b18-d1c3-f0245fdc63a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cJj6pS9G4JQ9",
        "outputId": "1d0edcae-3f83-4d57-e2d9-1b9a232934e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m811.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit-pypi, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch-geometric, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdkit-pypi-2022.9.5 torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch-geometric rdkit-pypi pandas numpy networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSgIhWa142Jg",
        "outputId": "3c8ac4ee-4f08-40ee-d708-6898f92a3d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available()) #connect to gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrJBBrx849ix",
        "outputId": "32f6f7aa-6680-495d-9e8e-aae736be90f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0   refcode  ligand_index  eleccount  hapticity  h2-Benzene  \\\n",
            "0           0  AACANI11             0         10          0           0   \n",
            "1           1  AACANI11             1        122          0           0   \n",
            "2           2    AAZDCO             0         23          0           0   \n",
            "3           3    AAZDCO             1         23          0           0   \n",
            "4           4    AAZDCO             2         98          0           0   \n",
            "\n",
            "   h4-Benzene  h2-Butadiene  h5-Cp  h3-Cp  ...  metal_totcharge  number  row  \\\n",
            "0           0             0      0      0  ...                2      28    4   \n",
            "1           0             0      0      0  ...                2      28    4   \n",
            "2           0             0      0      0  ...                3      27    4   \n",
            "3           0             0      0      0  ...                3      27    4   \n",
            "4           0             0      0      0  ...                3      27    4   \n",
            "\n",
            "   group  valence_electrons  valence_to_donate  s_unfilled  p_unfilled  \\\n",
            "0     10                 10                  8           0           0   \n",
            "1     10                 10                  8           0           0   \n",
            "2      9                  9                  9           0           0   \n",
            "3      9                  9                  9           0           0   \n",
            "4      9                  9                  9           0           0   \n",
            "\n",
            "   d_unfilled    geometry  \n",
            "0           2  pyramid_sq  \n",
            "1           2  pyramid_sq  \n",
            "2           3  octahedral  \n",
            "3           3  octahedral  \n",
            "4           3  octahedral  \n",
            "\n",
            "[5 rows x 393 columns]\n",
            "(82880, 393)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data_path = '/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv'\n",
        "data = pd.read_csv(data_path, encoding='utf-8')\n",
        "print(data.head())\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25YG-ai589HI",
        "outputId": "c0b02cc5-0ebf-48d7-9f7c-1f07d558352d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0           0\n",
            "refcode              0\n",
            "ligand_index         0\n",
            "eleccount            0\n",
            "hapticity            0\n",
            "                    ..\n",
            "valence_to_donate    0\n",
            "s_unfilled           0\n",
            "p_unfilled           0\n",
            "d_unfilled           0\n",
            "geometry             0\n",
            "Length: 393, dtype: int64\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().sum())\n",
        "print(data.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96VX8VQVqkxx",
        "outputId": "75ce7620-9e51-4909-8ae3-985362eed626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'refcode', 'ligand_index', 'eleccount', 'hapticity',\n",
            "       'h2-Benzene', 'h4-Benzene', 'h2-Butadiene', 'h5-Cp', 'h3-Cp',\n",
            "       ...\n",
            "       'metal_totcharge', 'number', 'row', 'group', 'valence_electrons',\n",
            "       'valence_to_donate', 's_unfilled', 'p_unfilled', 'd_unfilled',\n",
            "       'geometry'],\n",
            "      dtype='object', length=393)\n"
          ]
        }
      ],
      "source": [
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITvKWCZnvHdy",
        "outputId": "01c169cc-5f3a-477d-876f-244b40156eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Original dataset shape: (82880, 393)\n",
            "Original dataset columns: ['Unnamed: 0', 'refcode', 'ligand_index', 'eleccount', 'hapticity', 'h2-Benzene', 'h4-Benzene', 'h2-Butadiene', 'h5-Cp', 'h3-Cp', 'h4-Butadiene', 'h4-Enone', 'h6-Benzene', 'h3-Allyl', 'natoms', 'numH', 'lig_totmconnec', 'lig_totconnec', 'lig_totcharge', 'ABC', 'ABCGG', 'nAcid', 'nBase', 'nAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', 'nSpiro', 'nBridgehead', 'nHetero', 'nH', 'nB', 'nC', 'nN', 'nO', 'nS', 'nP', 'nF', 'nCl', 'nBr', 'nI', 'nX', 'BalabanJ', 'BertzCT', 'nBonds', 'nBondsO', 'nBondsS', 'nBondsD', 'nBondsT', 'nBondsA', 'nBondsM', 'nBondsKS', 'nBondsKD', 'C1SP1', 'C2SP1', 'C1SP2', 'C2SP2', 'C3SP2', 'C1SP3', 'C2SP3', 'C3SP3', 'C4SP3', 'FCSP3', 'SZ', 'Sm', 'Sv', 'Sse', 'Spe', 'Sare', 'Sp', 'Si', 'MZ', 'Mm', 'Mv', 'Mse', 'Mpe', 'Mare', 'Mp', 'Mi', 'SpAbs_D', 'SpMax_D', 'SpDiam_D', 'SpAD_D', 'SpMAD_D', 'LogEE_D', 'VE1_D', 'VE2_D', 'VE3_D', 'VR1_D', 'VR2_D', 'ECIndex', 'fragCpx', 'fMF', 'nHBAcc', 'nHBDon', 'Lipinski', 'GhoseFilter', 'FilterItLogS', 'VMcGowan', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'SMR_VSA1', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'SlogP_VSA10', 'SlogP_VSA11', 'EState_VSA1', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'EState_VSA10', 'VSA_EState1', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'MID', 'AMID', 'MID_h', 'AMID_h', 'MID_C', 'AMID_C', 'MID_N', 'AMID_N', 'MID_O', 'AMID_O', 'MID_X', 'AMID_X', 'MPC2', 'MPC3', 'MPC4', 'MPC5', 'MPC6', 'MPC7', 'MPC8', 'MPC9', 'MPC10', 'TMPC10', 'piPC1', 'piPC2', 'piPC3', 'piPC4', 'piPC5', 'piPC6', 'piPC7', 'piPC8', 'piPC9', 'piPC10', 'TpiPC10', 'apol', 'bpol', 'nRing', 'n3Ring', 'n4Ring', 'n5Ring', 'n6Ring', 'n7Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'nHRing', 'n3HRing', 'n4HRing', 'n5HRing', 'n6HRing', 'n7HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'naRing', 'n3aRing', 'n4aRing', 'n5aRing', 'n6aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'naHRing', 'n3aHRing', 'n4aHRing', 'n5aHRing', 'n6aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'nARing', 'n3ARing', 'n4ARing', 'n5ARing', 'n6ARing', 'n7ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'nAHRing', 'n3AHRing', 'n4AHRing', 'n5AHRing', 'n6AHRing', 'n7AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'nFRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n9FRing', 'n10FRing', 'n11FRing', 'n12FRing', 'nG12FRing', 'nFHRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n9FHRing', 'n10FHRing', 'n11FHRing', 'n12FHRing', 'nG12FHRing', 'nFaRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n9FaRing', 'n10FaRing', 'n11FaRing', 'n12FaRing', 'nG12FaRing', 'nFaHRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n9FaHRing', 'n10FaHRing', 'n11FaHRing', 'n12FaHRing', 'nG12FaHRing', 'nFARing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n9FARing', 'n10FARing', 'n11FARing', 'n12FARing', 'nG12FARing', 'nFAHRing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n9FAHRing', 'n10FAHRing', 'n11FAHRing', 'n12FAHRing', 'nG12FAHRing', 'nRot', 'RotRatio', 'SLogP', 'SMR', 'TopoPSA(NO)', 'TopoPSA', 'GGI1', 'GGI2', 'GGI3', 'GGI4', 'GGI5', 'GGI6', 'GGI7', 'GGI8', 'GGI9', 'GGI10', 'JGI1', 'JGI2', 'JGI3', 'JGI4', 'JGI5', 'JGI6', 'JGI7', 'JGI8', 'JGI9', 'JGI10', 'JGT10', 'Diameter', 'Radius', 'MWC01', 'MWC02', 'MWC03', 'MWC04', 'MWC05', 'MWC06', 'MWC07', 'MWC08', 'MWC09', 'MWC10', 'TMWC10', 'SRW02', 'SRW03', 'SRW04', 'SRW05', 'SRW06', 'SRW07', 'SRW08', 'SRW09', 'SRW10', 'TSRW10', 'MW', 'AMW', 'WPath', 'WPol', 'Zagreb1', 'Zagreb2', 'radii', 'metal_totmconnec', 'metal_totcharge', 'number', 'row', 'group', 'valence_electrons', 'valence_to_donate', 's_unfilled', 'p_unfilled', 'd_unfilled', 'geometry']\n",
            "First 5 rows of original dataset:\n",
            "   Unnamed: 0   refcode  ligand_index  eleccount  hapticity  h2-Benzene  \\\n",
            "0           0  AACANI11             0         10          0           0   \n",
            "1           1  AACANI11             1        122          0           0   \n",
            "2           2    AAZDCO             0         23          0           0   \n",
            "3           3    AAZDCO             1         23          0           0   \n",
            "4           4    AAZDCO             2         98          0           0   \n",
            "\n",
            "   h4-Benzene  h2-Butadiene  h5-Cp  h3-Cp  ...  metal_totcharge  number  row  \\\n",
            "0           0             0      0      0  ...                2      28    4   \n",
            "1           0             0      0      0  ...                2      28    4   \n",
            "2           0             0      0      0  ...                3      27    4   \n",
            "3           0             0      0      0  ...                3      27    4   \n",
            "4           0             0      0      0  ...                3      27    4   \n",
            "\n",
            "   group  valence_electrons  valence_to_donate  s_unfilled  p_unfilled  \\\n",
            "0     10                 10                  8           0           0   \n",
            "1     10                 10                  8           0           0   \n",
            "2      9                  9                  9           0           0   \n",
            "3      9                  9                  9           0           0   \n",
            "4      9                  9                  9           0           0   \n",
            "\n",
            "   d_unfilled    geometry  \n",
            "0           2  pyramid_sq  \n",
            "1           2  pyramid_sq  \n",
            "2           3  octahedral  \n",
            "3           3  octahedral  \n",
            "4           3  octahedral  \n",
            "\n",
            "[5 rows x 393 columns]\n",
            "Missing values per column:\n",
            "Unnamed: 0           0\n",
            "refcode              0\n",
            "ligand_index         0\n",
            "eleccount            0\n",
            "hapticity            0\n",
            "                    ..\n",
            "valence_to_donate    0\n",
            "s_unfilled           0\n",
            "p_unfilled           0\n",
            "d_unfilled           0\n",
            "geometry             0\n",
            "Length: 393, dtype: int64\n",
            "\n",
            "Refcode column exists: True\n",
            "Ligand_index column exists: True\n",
            "\n",
            "Shape after minimal cleaning (keeping refcode, ligand_index): (82880, 393)\n",
            "Unique refcodes after minimal cleaning: 26979\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (ensure access)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Load the CSV and inspect its content\n",
        "import pandas as pd\n",
        "data_path = '/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv'\n",
        "try:\n",
        "    original_data = pd.read_csv(data_path, encoding='utf-8')\n",
        "    print(\"Original dataset shape:\", original_data.shape)\n",
        "    print(\"Original dataset columns:\", original_data.columns.tolist())\n",
        "    print(\"First 5 rows of original dataset:\")\n",
        "    print(original_data.head())\n",
        "    print(\"Missing values per column:\")\n",
        "    print(original_data.isnull().sum())\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found at {data_path}. Check if the file exists in Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n",
        "\n",
        "# Check if refcode and ligand_index exist\n",
        "print(\"\\nRefcode column exists:\", 'refcode' in original_data.columns)\n",
        "print(\"Ligand_index column exists:\", 'ligand_index' in original_data.columns)\n",
        "\n",
        "# Verify data isn’t empty after basic loading (no cleaning yet)\n",
        "if original_data.empty:\n",
        "    print(\"DataFrame is empty. Possible reasons:\")\n",
        "    print(\"- File is empty or corrupted.\")\n",
        "    print(\"- Path is incorrect (check /content/drive/MyDrive/ligand_metal_with_labels_clean2.csv).\")\n",
        "    print(\"- Encoding or delimiter issues (e.g., try encoding='latin1' or sep=';').\")\n",
        "else:\n",
        "    # Apply minimal cleaning to identify data loss\n",
        "    cleaned_data = original_data.dropna(subset=['refcode', 'ligand_index'])  # Drop only if these are NaN\n",
        "    print(\"\\nShape after minimal cleaning (keeping refcode, ligand_index):\", cleaned_data.shape)\n",
        "    print(\"Unique refcodes after minimal cleaning:\", len(cleaned_data['refcode'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmGw0aLlxLk_",
        "outputId": "0a7c9df2-d94f-4206-e3ea-9ed43c759340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verifying derived features:\n",
            "Ligand_SMILES exists: False\n",
            "Ligand_Fingerprint exists: False\n",
            "Coordination_Number exists: False\n",
            "Metal_Atomic_Number exists: False\n",
            "Metal_d_Electrons exists: False\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nVerifying derived features:\")\n",
        "print(\"Ligand_SMILES exists:\", 'Ligand_SMILES' in data.columns)\n",
        "print(\"Ligand_Fingerprint exists:\", 'Ligand_Fingerprint' in data.columns)\n",
        "print(\"Coordination_Number exists:\", 'Coordination_Number' in data.columns)\n",
        "print(\"Metal_Atomic_Number exists:\", 'Metal_Atomic_Number' in data.columns)\n",
        "print(\"Metal_d_Electrons exists:\", 'Metal_d_Electrons' in data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK9lZlNUvwgJ",
        "outputId": "c3be466e-9b2d-42cd-a3ed-2894afe25677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unnamed: 0', 'refcode', 'ligand_index', 'eleccount', 'hapticity', 'h2-Benzene', 'h4-Benzene', 'h2-Butadiene', 'h5-Cp', 'h3-Cp', 'h4-Butadiene', 'h4-Enone', 'h6-Benzene', 'h3-Allyl', 'natoms', 'numH', 'lig_totmconnec', 'lig_totconnec', 'lig_totcharge', 'ABC', 'ABCGG', 'nAcid', 'nBase', 'nAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', 'nSpiro', 'nBridgehead', 'nHetero', 'nH', 'nB', 'nC', 'nN', 'nO', 'nS', 'nP', 'nF', 'nCl', 'nBr', 'nI', 'nX', 'BalabanJ', 'BertzCT', 'nBonds', 'nBondsO', 'nBondsS', 'nBondsD', 'nBondsT', 'nBondsA', 'nBondsM', 'nBondsKS', 'nBondsKD', 'C1SP1', 'C2SP1', 'C1SP2', 'C2SP2', 'C3SP2', 'C1SP3', 'C2SP3', 'C3SP3', 'C4SP3', 'FCSP3', 'SZ', 'Sm', 'Sv', 'Sse', 'Spe', 'Sare', 'Sp', 'Si', 'MZ', 'Mm', 'Mv', 'Mse', 'Mpe', 'Mare', 'Mp', 'Mi', 'SpAbs_D', 'SpMax_D', 'SpDiam_D', 'SpAD_D', 'SpMAD_D', 'LogEE_D', 'VE1_D', 'VE2_D', 'VE3_D', 'VR1_D', 'VR2_D', 'ECIndex', 'fragCpx', 'fMF', 'nHBAcc', 'nHBDon', 'Lipinski', 'GhoseFilter', 'FilterItLogS', 'VMcGowan', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'SMR_VSA1', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'SlogP_VSA10', 'SlogP_VSA11', 'EState_VSA1', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'EState_VSA10', 'VSA_EState1', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'MID', 'AMID', 'MID_h', 'AMID_h', 'MID_C', 'AMID_C', 'MID_N', 'AMID_N', 'MID_O', 'AMID_O', 'MID_X', 'AMID_X', 'MPC2', 'MPC3', 'MPC4', 'MPC5', 'MPC6', 'MPC7', 'MPC8', 'MPC9', 'MPC10', 'TMPC10', 'piPC1', 'piPC2', 'piPC3', 'piPC4', 'piPC5', 'piPC6', 'piPC7', 'piPC8', 'piPC9', 'piPC10', 'TpiPC10', 'apol', 'bpol', 'nRing', 'n3Ring', 'n4Ring', 'n5Ring', 'n6Ring', 'n7Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'nHRing', 'n3HRing', 'n4HRing', 'n5HRing', 'n6HRing', 'n7HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'naRing', 'n3aRing', 'n4aRing', 'n5aRing', 'n6aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'naHRing', 'n3aHRing', 'n4aHRing', 'n5aHRing', 'n6aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'nARing', 'n3ARing', 'n4ARing', 'n5ARing', 'n6ARing', 'n7ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'nAHRing', 'n3AHRing', 'n4AHRing', 'n5AHRing', 'n6AHRing', 'n7AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'nFRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n9FRing', 'n10FRing', 'n11FRing', 'n12FRing', 'nG12FRing', 'nFHRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n9FHRing', 'n10FHRing', 'n11FHRing', 'n12FHRing', 'nG12FHRing', 'nFaRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n9FaRing', 'n10FaRing', 'n11FaRing', 'n12FaRing', 'nG12FaRing', 'nFaHRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n9FaHRing', 'n10FaHRing', 'n11FaHRing', 'n12FaHRing', 'nG12FaHRing', 'nFARing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n9FARing', 'n10FARing', 'n11FARing', 'n12FARing', 'nG12FARing', 'nFAHRing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n9FAHRing', 'n10FAHRing', 'n11FAHRing', 'n12FAHRing', 'nG12FAHRing', 'nRot', 'RotRatio', 'SLogP', 'SMR', 'TopoPSA(NO)', 'TopoPSA', 'GGI1', 'GGI2', 'GGI3', 'GGI4', 'GGI5', 'GGI6', 'GGI7', 'GGI8', 'GGI9', 'GGI10', 'JGI1', 'JGI2', 'JGI3', 'JGI4', 'JGI5', 'JGI6', 'JGI7', 'JGI8', 'JGI9', 'JGI10', 'JGT10', 'Diameter', 'Radius', 'MWC01', 'MWC02', 'MWC03', 'MWC04', 'MWC05', 'MWC06', 'MWC07', 'MWC08', 'MWC09', 'MWC10', 'TMWC10', 'SRW02', 'SRW03', 'SRW04', 'SRW05', 'SRW06', 'SRW07', 'SRW08', 'SRW09', 'SRW10', 'TSRW10', 'MW', 'AMW', 'WPath', 'WPol', 'Zagreb1', 'Zagreb2', 'radii', 'metal_totmconnec', 'metal_totcharge', 'number', 'row', 'group', 'valence_electrons', 'valence_to_donate', 's_unfilled', 'p_unfilled', 'd_unfilled', 'geometry']\n"
          ]
        }
      ],
      "source": [
        "print(data.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUwe9bQeaHbb",
        "outputId": "1eb7fa90-ee8a-4b5a-87f9-2a5d28b0447f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    pyramid_sq\n",
            "1    pyramid_sq\n",
            "2    octahedral\n",
            "3    octahedral\n",
            "4    octahedral\n",
            "Name: geometry, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(data['geometry'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r05n46u-0wRq",
        "outputId": "74b73e58-ea81-40b9-c202-fb98e4985b32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "'row' in data.columns  # Should return True if it exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0A4hHF8KFnB",
        "outputId": "91feef15-1da8-4e0f-c5e3-99f21b9664eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refcode exists: True\n",
            "Ligand_index exists: True\n",
            "Geometry exists: True\n",
            "Number exists: True\n",
            "Metal_totcharge exists: True\n"
          ]
        }
      ],
      "source": [
        "print(\"Refcode exists:\", 'refcode' in data.columns)\n",
        "print(\"Ligand_index exists:\", 'ligand_index' in data.columns)\n",
        "print(\"Geometry exists:\", 'geometry' in data.columns)\n",
        "print(\"Number exists:\", 'number' in data.columns)\n",
        "print(\"Metal_totcharge exists:\", 'metal_totcharge' in data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMILES**\n",
        "1. Atoms\n",
        "2. Bonds\n",
        "3. Branches\n",
        "4. Rings"
      ],
      "metadata": {
        "id": "RpoU3YAKD2tu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGAjCjN3V5Le",
        "outputId": "425fafac-cd63-4e62-ed9c-8a3e8863ebc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/complexes_smiles.zip\n",
            "  inflating: /content/complexes_smiles/Cr_complexes_smiles.csv  \n",
            "  inflating: /content/complexes_smiles/Fe_complexes_smiles.csv  \n",
            "  inflating: /content/complexes_smiles/Re_complexes_smiles.csv  \n",
            "  inflating: /content/complexes_smiles/Co_complexes_smiles.csv  \n",
            "  inflating: /content/complexes_smiles/Ni_complexes_smiles.csv  \n",
            "  inflating: /content/complexes_smiles/Ru_complexes_smiles.csv  \n",
            "  inflating: /content/complexes_smiles/Cu_complexes_smiles.csv  \n",
            "  inflating: /content/complexes_smiles/Mn_complexes_smiles.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/complexes_smiles.zip -d /content/complexes_smiles/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mWbFFAkW53C",
        "outputId": "8ea94c08-b582-4b7b-80cc-f6745a8cca7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Co_complexes_smiles.csv  Cu_complexes_smiles.csv  Mn_complexes_smiles.csv  Re_complexes_smiles.csv\n",
            "Cr_complexes_smiles.csv  Fe_complexes_smiles.csv  Ni_complexes_smiles.csv  Ru_complexes_smiles.csv\n"
          ]
        }
      ],
      "source": [
        "!ls /content/complexes_smiles/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iZtO1OxW87F",
        "outputId": "f14f7040-25ac-4a63-b521-c5ada3635c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0   refcode                                             SMILES\n",
            "0           0    ABEMAX  ['[H]c1c(C([H])([H])[H])c([H])c(C([H])([H])[H]...\n",
            "1           1    ABIJEB  ['[H]N=O', '[H]SC([H])([H])C([H])([H])N1C([H])...\n",
            "2           2    ABITEM  ['[H][N-]C#[S+]', '[H]c1nc(C([H])([H])N(C([H])...\n",
            "3           3  ABITUC01  ['[H][N-]C#[S+]', '[H]c1nc(C([H])([H])N(C([H])...\n",
            "4           4    ABOZOJ  ['[H]Oc1c(C([H])([H])N([H])C([H])([H])C([H])([...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "complexes_df = pd.read_csv('/content/complexes_smiles/Fe_complexes_smiles.csv')\n",
        "print(complexes_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3w_qfQyZXsb",
        "outputId": "b6ad80ab-d27e-493f-b066-d8f10a073d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unnamed: 0', 'refcode', 'SMILES']\n"
          ]
        }
      ],
      "source": [
        "print(complexes_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD_pAbIOY4r0",
        "outputId": "cb10b8e5-6c99-47c7-f215-8bb51174e9c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torchmetrics-1.7.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.9/960.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.14.2 torchmetrics-1.7.0\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install torch torch-geometric rdkit-pypi pandas numpy networkx torchmetrics\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Graphs**"
      ],
      "metadata": {
        "id": "ClZr0hD10ryJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph with just smiles"
      ],
      "metadata": {
        "id": "pXl3cncnEMK3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-j8rTefZrgd",
        "outputId": "eb5521c2-2727-4877-d022-7c87b3389c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of merged entries: 82880\n",
            "Label mapping: {'bent': np.int64(0), 'linear': np.int64(1), 'octahedral': np.int64(2), 'planar_3': np.int64(3), 'planar_4': np.int64(4), 'planar_5': np.int64(5), 'prism': np.int64(6), 'pyramid_3': np.int64(7), 'pyramid_4': np.int64(8), 'pyramid_bi': np.int64(9), 'pyramid_sq': np.int64(10), 'tetrahedral': np.int64(11), 'tshape': np.int64(12)}\n",
            "Number of valid graphs: 69976\n",
            "Number of valid graphs with edges: 69976\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load labeled data\n",
        "labeled_df = pd.read_csv('/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv')\n",
        "\n",
        "# Load all SMILES CSV files\n",
        "smiles_files = glob.glob('/content/complexes_smiles/*_complexes_smiles.csv')\n",
        "smiles_dfs = [pd.read_csv(file) for file in smiles_files]\n",
        "all_smiles_df = pd.concat(smiles_dfs, ignore_index=True)\n",
        "\n",
        "# Handle duplicate refcodes\n",
        "if all_smiles_df['refcode'].duplicated().any():\n",
        "    print(\"Warning: Duplicate refcodes found. Dropping duplicates.\")\n",
        "    all_smiles_df = all_smiles_df.drop_duplicates(subset='refcode')\n",
        "\n",
        "# Merge with labeled data\n",
        "merged_df = pd.merge(labeled_df, all_smiles_df[['refcode', 'SMILES']], on='refcode', how='inner')\n",
        "print(f\"Number of merged entries: {len(merged_df)}\")\n",
        "\n",
        "# Encode geometry labels\n",
        "#ex: {'tetrahedral': 0, 'octahedral': 1, 'square planar': 2}\n",
        "le = LabelEncoder()\n",
        "merged_df['geometry_encoded'] = le.fit_transform(merged_df['geometry'])\n",
        "print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "# Convert SMILES to graph with edge validation\n",
        "def smiles_to_graph(smiles):\n",
        "    try:\n",
        "        if isinstance(smiles, str) and smiles.startswith('['):\n",
        "            smiles = eval(smiles)[0]  # Handle list-like SMILES\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None or mol.GetNumAtoms() == 0 or mol.GetNumBonds() == 0:\n",
        "            return None\n",
        "        AllChem.Compute2DCoords(mol)\n",
        "        atom_features = [[atom.GetAtomicNum(), atom.GetDegree(), atom.GetFormalCharge()] for atom in mol.GetAtoms()]\n",
        "        edge_index = []\n",
        "        for bond in mol.GetBonds():\n",
        "            i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "            edge_index.extend([[i, j], [j, i]])\n",
        "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "        x = torch.tensor(atom_features, dtype=torch.float)\n",
        "        return Data(x=x, edge_index=edge_index)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing SMILES {smiles}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Apply conversion and filter valid graphs\n",
        "merged_df['graph'] = merged_df['SMILES'].apply(smiles_to_graph)\n",
        "valid_df = merged_df[merged_df['graph'].notnull()].copy()\n",
        "print(f\"Number of valid graphs: {len(valid_df)}\")\n",
        "\n",
        "# Add batch attribute and validate edge_index\n",
        "valid_df['graph'] = [\n",
        "    Data(x=g.x, edge_index=g.edge_index, batch=torch.zeros(g.x.size(0), dtype=torch.long))\n",
        "    for g in valid_df['graph']\n",
        "    if g.edge_index.size(1) > 0  # Ensure graphs have edges\n",
        "]\n",
        "valid_df = valid_df[valid_df['graph'].apply(lambda x: x is not None and x.edge_index.size(1) > 0)].copy()\n",
        "print(f\"Number of valid graphs with edges: {len(valid_df)}\")\n",
        "\n",
        "# Save valid_df for debugging (optional)\n",
        "valid_df.to_csv('/content/drive/MyDrive/valid_df_with_edges.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph with molecular features and smiles"
      ],
      "metadata": {
        "id": "sOQMfdMBERaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "# Load labeled data\n",
        "labeled_df = pd.read_csv('/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv')\n",
        "\n",
        "# Load all SMILES CSV files\n",
        "smiles_files = glob.glob('/content/complexes_smiles/*_complexes_smiles.csv')\n",
        "smiles_dfs = [pd.read_csv(file) for file in smiles_files]\n",
        "all_smiles_df = pd.concat(smiles_dfs, ignore_index=True)\n",
        "\n",
        "# Handle duplicate refcodes\n",
        "if all_smiles_df['refcode'].duplicated().any():\n",
        "    print(\"Warning: Duplicate refcodes found. Dropping duplicates.\")\n",
        "    all_smiles_df = all_smiles_df.drop_duplicates(subset='refcode')\n",
        "\n",
        "# Merge with labeled data\n",
        "merged_df = pd.merge(labeled_df, all_smiles_df[['refcode', 'SMILES']], on='refcode', how='inner')\n",
        "print(f\"Number of merged entries: {len(merged_df)}\")\n",
        "\n",
        "# Encode geometry labels\n",
        "le = LabelEncoder()\n",
        "merged_df['geometry_encoded'] = le.fit_transform(merged_df['geometry'])\n",
        "print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "# Standardize molecular features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "def clean_smiles(smiles):\n",
        "    \"\"\"Handle SMILES stored as Python list strings (e.g., \"['CCO']\" -> \"CCO\")\"\"\"\n",
        "    if isinstance(smiles, str):\n",
        "        if smiles.startswith('[') and smiles.endswith(']'):\n",
        "            try:\n",
        "                # Safely evaluate string as Python list\n",
        "                cleaned = ast.literal_eval(smiles)[0]\n",
        "                return str(cleaned)\n",
        "            except:\n",
        "                return smiles.strip(\"[]'\\\"\")  # Fallback: remove brackets/quotes\n",
        "    return smiles\n",
        "\n",
        "def compute_molecular_features(smiles):\n",
        "    try:\n",
        "        cleaned_smiles = clean_smiles(smiles)\n",
        "        mol = Chem.MolFromSmiles(cleaned_smiles, sanitize=False)\n",
        "        if mol is None:\n",
        "            return None\n",
        "\n",
        "        if mol.GetNumBonds() == 0:\n",
        "            mol = Chem.MolFromSmiles(Chem.MolToSmiles(mol, allHsExplicit=False))\n",
        "\n",
        "        Chem.SanitizeMol(mol)\n",
        "\n",
        "        return [\n",
        "            Descriptors.ExactMolWt(mol),\n",
        "            Descriptors.NumHDonors(mol),\n",
        "            Descriptors.NumHAcceptors(mol),\n",
        "            Descriptors.NumRotatableBonds(mol),\n",
        "            Descriptors.NumAromaticRings(mol) + Descriptors.NumAliphaticRings(mol)\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Error computing features for SMILES {smiles}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Compute molecular properties\n",
        "merged_df['molecular_features'] = merged_df['SMILES'].apply(compute_molecular_features)\n",
        "filtered_df = merged_df[merged_df['molecular_features'].notnull()].copy()\n",
        "\n",
        "# Check for empty dataset\n",
        "if len(filtered_df) == 0:\n",
        "    raise ValueError(\"No valid molecules found after filtering. Check your SMILES input data.\")\n",
        "\n",
        "# Convert list of features to a tensor for scaling\n",
        "molecular_features = np.array(filtered_df['molecular_features'].tolist())\n",
        "\n",
        "# Scale the features\n",
        "if molecular_features.size > 0:\n",
        "    scaled_features = scaler.fit_transform(molecular_features)\n",
        "    filtered_df['molecular_features'] = scaled_features.tolist()\n",
        "else:\n",
        "    raise ValueError(\"No valid molecular features to scale. Check compute_molecular_features()\")\n",
        "\n",
        "# Convert SMILES to graph with additional features\n",
        "def smiles_to_graph(smiles, molecular_features=None):\n",
        "    try:\n",
        "        # Clean SMILES format\n",
        "        cleaned_smiles = clean_smiles(smiles)\n",
        "\n",
        "        # Try parsing with explicit hydrogens first\n",
        "        mol = Chem.MolFromSmiles(cleaned_smiles, sanitize=False)\n",
        "        if mol is None:\n",
        "            return None\n",
        "\n",
        "        # If the molecule has no bonds, try removing explicit hydrogens\n",
        "        if mol.GetNumBonds() == 0:\n",
        "            mol = Chem.MolFromSmiles(Chem.MolToSmiles(mol, allHsExplicit=False))\n",
        "\n",
        "        # Sanitize and compute 2D coordinates\n",
        "        Chem.SanitizeMol(mol)\n",
        "        AllChem.Compute2DCoords(mol)\n",
        "\n",
        "        if mol.GetNumAtoms() == 0:\n",
        "            print(f\"Invalid molecule (no atoms): {cleaned_smiles}\")\n",
        "            return None\n",
        "\n",
        "        # Atom-level features\n",
        "        atom_features = []\n",
        "        for atom in mol.GetAtoms():\n",
        "            atom_features.append([\n",
        "                atom.GetAtomicNum(),\n",
        "                atom.GetDegree(),\n",
        "                atom.GetFormalCharge(),\n",
        "                atom.GetIsAromatic(),\n",
        "                atom.GetTotalNumHs(includeNeighbors=True)  # Include total H count\n",
        "            ])\n",
        "\n",
        "        atom_features_tensor = torch.tensor(atom_features, dtype=torch.float)\n",
        "\n",
        "        # Add molecular features to node features\n",
        "        if molecular_features is not None:\n",
        "            mol_features_tensor = torch.tensor(molecular_features, dtype=torch.float)\n",
        "            atom_features_tensor = torch.cat([\n",
        "                atom_features_tensor,\n",
        "                mol_features_tensor.repeat(atom_features_tensor.size(0), 1)\n",
        "            ], dim=1)\n",
        "\n",
        "        # Edge list (bond information)\n",
        "        edge_index = []\n",
        "        for bond in mol.GetBonds():\n",
        "            i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "            edge_index.extend([[i, j], [j, i]])\n",
        "\n",
        "        # If no bonds, create self-loops\n",
        "        if not edge_index:\n",
        "            edge_index = [[i, i] for i in range(mol.GetNumAtoms())]\n",
        "\n",
        "        edge_index_tensor = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        return Data(x=atom_features_tensor, edge_index=edge_index_tensor)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing SMILES {cleaned_smiles}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Apply conversion\n",
        "filtered_df['graph'] = filtered_df.apply(\n",
        "    lambda row: smiles_to_graph(row['SMILES'], row['molecular_features']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Filter valid graphs\n",
        "valid_df = filtered_df[filtered_df['graph'].notnull()].copy()\n",
        "print(f\"Number of valid graphs: {len(valid_df)}\")\n",
        "\n",
        "# Validate edge_index and finalize graphs\n",
        "valid_graphs = []\n",
        "for g in valid_df['graph']:\n",
        "    if g.edge_index.size(1) > 0:\n",
        "        valid_graphs.append(Data(\n",
        "            x=g.x,\n",
        "            edge_index=g.edge_index,\n",
        "            batch=torch.zeros(g.x.size(0), dtype=torch.long)\n",
        "        ))\n",
        "\n",
        "valid_df = valid_df.iloc[:len(valid_graphs)].copy()\n",
        "valid_df['graph'] = valid_graphs\n",
        "print(f\"Number of valid graphs with edges: {len(valid_df)}\")\n",
        "\n",
        "# Save valid dataset\n",
        "valid_df.to_csv('/content/drive/MyDrive/valid_df_with_features.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAcurFG5-Bd8",
        "outputId": "28b88257-4135-4891-8ce8-4dfc5e1c0b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of merged entries: 82880\n",
            "Label mapping: {'bent': np.int64(0), 'linear': np.int64(1), 'octahedral': np.int64(2), 'planar_3': np.int64(3), 'planar_4': np.int64(4), 'planar_5': np.int64(5), 'prism': np.int64(6), 'pyramid_3': np.int64(7), 'pyramid_4': np.int64(8), 'pyramid_bi': np.int64(9), 'pyramid_sq': np.int64(10), 'tetrahedral': np.int64(11), 'tshape': np.int64(12)}\n",
            "Number of valid graphs: 82880\n",
            "Number of valid graphs with edges: 82880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Representation of Graph"
      ],
      "metadata": {
        "id": "65Nsq13cEVtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsLqc6glEYyX",
        "outputId": "fbce5e4a-706f-40df-f8d3-1f78682f3678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import ast\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "def extract_graph_details(graph_str):\n",
        "    \"\"\"\n",
        "    Extract detailed information from the graph string representation\n",
        "    \"\"\"\n",
        "    details = {}\n",
        "\n",
        "    # Extract x (node features) dimensions\n",
        "    x_match = re.search(r'x=\\[(\\d+), (\\d+)\\]', graph_str)\n",
        "    if x_match:\n",
        "        details['num_nodes'] = int(x_match.group(1))\n",
        "        details['num_features'] = int(x_match.group(2))\n",
        "\n",
        "    # Extract edge index dimensions\n",
        "    edge_match = re.search(r'edge_index=\\[(\\d+), (\\d+)\\]', graph_str)\n",
        "    if edge_match:\n",
        "        details['num_edges'] = int(edge_match.group(2))\n",
        "\n",
        "    # Extract batch information\n",
        "    batch_match = re.search(r'batch=\\[(\\d+)\\]', graph_str)\n",
        "    if batch_match:\n",
        "        details['batch_size'] = int(batch_match.group(1))\n",
        "\n",
        "    return details\n",
        "\n",
        "def summarize_graphs(df):\n",
        "    \"\"\"\n",
        "    Provide a comprehensive summary of graphs in the DataFrame\n",
        "    \"\"\"\n",
        "    # Collect graph details\n",
        "    graph_details = []\n",
        "    for graph_str in df['graph']:\n",
        "        details = extract_graph_details(graph_str)\n",
        "        graph_details.append(details)\n",
        "\n",
        "    # Convert to DataFrame for easy analysis\n",
        "    details_df = pd.DataFrame(graph_details)\n",
        "\n",
        "    print(\"Graph Dataset Summary:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Total Graphs: {len(df)}\")\n",
        "    print(\"\\nNode Features Statistics:\")\n",
        "    print(details_df[['num_nodes', 'num_features']].describe())\n",
        "\n",
        "    print(\"\\nEdge Statistics:\")\n",
        "    print(details_df[['num_edges']].describe())\n",
        "\n",
        "    print(\"\\nBatch Size Distribution:\")\n",
        "    print(details_df['batch_size'].value_counts())\n",
        "\n",
        "def visualize_graph_distributions(df):\n",
        "    \"\"\"\n",
        "    Create visualizations of graph properties\n",
        "    \"\"\"\n",
        "    # Extract details\n",
        "    graph_details = []\n",
        "    for graph_str in df['graph']:\n",
        "        details = extract_graph_details(graph_str)\n",
        "        graph_details.append(details)\n",
        "    details_df = pd.DataFrame(graph_details)\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('Molecular Graph Properties Distribution', fontsize=16)\n",
        "\n",
        "    # Number of Nodes Distribution\n",
        "    axs[0, 0].hist(details_df['num_nodes'], bins=30, edgecolor='black')\n",
        "    axs[0, 0].set_title('Number of Nodes Distribution')\n",
        "    axs[0, 0].set_xlabel('Number of Nodes')\n",
        "    axs[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "    # Number of Features Distribution\n",
        "    axs[0, 1].hist(details_df['num_features'], bins=30, edgecolor='black')\n",
        "    axs[0, 1].set_title('Number of Node Features Distribution')\n",
        "    axs[0, 1].set_xlabel('Number of Features')\n",
        "    axs[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "    # Number of Edges Distribution\n",
        "    axs[1, 0].hist(details_df['num_edges'], bins=30, edgecolor='black')\n",
        "    axs[1, 0].set_title('Number of Edges Distribution')\n",
        "    axs[1, 0].set_xlabel('Number of Edges')\n",
        "    axs[1, 0].set_ylabel('Frequency')\n",
        "\n",
        "    # Batch Size Distribution\n",
        "    axs[1, 1].hist(details_df['batch_size'], bins=30, edgecolor='black')\n",
        "    axs[1, 1].set_title('Batch Size Distribution')\n",
        "    axs[1, 1].set_xlabel('Batch Size')\n",
        "    axs[1, 1].set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Load the DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/valid_df_with_features.csv')\n",
        "\n",
        "# Run analysis\n",
        "summarize_graphs(df)\n",
        "visualize_graph_distributions(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qXG3AoxeG4ue",
        "outputId": "fa30737c-6db9-49a7-c877-36dec676e6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Dataset Summary:\n",
            "--------------------------------------------------\n",
            "Total Graphs: 82880\n",
            "\n",
            "Node Features Statistics:\n",
            "          num_nodes  num_features\n",
            "count  82880.000000       82880.0\n",
            "mean      20.648769          10.0\n",
            "std       19.333290           0.0\n",
            "min        1.000000          10.0\n",
            "25%        4.000000          10.0\n",
            "50%       15.000000          10.0\n",
            "75%       31.000000          10.0\n",
            "max      296.000000          10.0\n",
            "\n",
            "Edge Statistics:\n",
            "          num_edges\n",
            "count  82880.000000\n",
            "mean      41.809447\n",
            "std       41.287665\n",
            "min        1.000000\n",
            "25%        6.000000\n",
            "50%       30.000000\n",
            "75%       64.000000\n",
            "max      640.000000\n",
            "\n",
            "Batch Size Distribution:\n",
            "batch_size\n",
            "3      11134\n",
            "2       5768\n",
            "4       4353\n",
            "6       3667\n",
            "34      2774\n",
            "       ...  \n",
            "296        1\n",
            "140        1\n",
            "133        1\n",
            "180        1\n",
            "141        1\n",
            "Name: count, Length: 150, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1200 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# Function to visualize PyTorch Geometric graph using NetworkX\n",
        "def visualize_graph(data, title=\"Graph\"):\n",
        "    \"\"\"\n",
        "    Visualize a PyTorch Geometric Data object as a graph using NetworkX.\n",
        "    \"\"\"\n",
        "    # Convert PyTorch Geometric Data to NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with atomic number as labels\n",
        "    num_nodes = data.x.size(0)\n",
        "    atomic_nums = data.x[:, 0].tolist()  # First feature is atomic number\n",
        "    for i in range(num_nodes):\n",
        "        G.add_node(i, label=int(atomic_nums[i]))\n",
        "\n",
        "    # Add edges from edge_index\n",
        "    edge_index = data.edge_index.t().tolist()\n",
        "    for edge in edge_index:\n",
        "        G.add_edge(edge[0], edge[1])\n",
        "\n",
        "    # Draw the graph\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    pos = nx.spring_layout(G)  # Layout for visualization\n",
        "    labels = nx.get_node_attributes(G, 'label')\n",
        "\n",
        "    nx.draw(G, pos, with_labels=True, labels=labels, node_color='lightblue',\n",
        "            node_size=500, font_size=10, font_weight='bold', edge_color='gray')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a few example graphs from valid_df\n",
        "num_examples = 1  # Number of graphs to visualize\n",
        "for i in range(min(num_examples, len(valid_df))):\n",
        "    graph_data = valid_df['graph'].iloc[i]  # Access the Data object\n",
        "    refcode = valid_df['refcode'].iloc[i]   # Use refcode as title\n",
        "    visualize_graph(graph_data, title=f\"Graph for {refcode}\")\n",
        "\n",
        "# Optional: Visualize a random sample\n",
        "sample_df = valid_df.sample(n=min(num_examples, len(valid_df)))\n",
        "for i, row in sample_df.iterrows():\n",
        "    visualize_graph(row['graph'], title=f\"Graph for {row['refcode']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4lsrasNDMYFx",
        "outputId": "dea26660-fe4d-4dcb-e205-c40c5c529046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzMAAAKCCAYAAADlSofSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAoJRJREFUeJzs3Xl0W+WZP/DvlXQlWbYl2fEanHiL7cSOY8fZN0JCEgIJS6AtYSnQ8iuF0oGZOczQ6cyU0uU386NMDzNT6NAZmqGUQBtaCGuWhgAhCVltx1nteEscvCW2pESy5Cvp/v7wQpzNurakK1nfzzk5eLm6z2vZSPe57/s8ryDLsgwiIiIiIqIoo1F7AERERERERCPBZIaIiIiIiKISkxkiIiIiIopKTGaIiIiIiCgqMZkhIiIiIqKoxGSGiIiIiIiiEpMZIiIiIiKKSkxmiIiIiIgoKjGZISIiIiKiqMRkhohojGtqaoIgCHj++edHfI66ujqsWLECFosFgiDgnXfeCd4AiYiIRojJDBFRkDQ2NuL73/8+CgsLYTKZYDKZUFxcjMcffxyHDh1Se3ij8uCDD6KmpgY///nP8dprr2HmzJkhizWQfA3802g0SE5Oxs0334zdu3dfdvyPf/zjIcdf+q+trW3w2M7OTjz55JOYPHky4uLikJaWhtmzZ+Ppp5/GhQsXIEkSUlJSsHDhwquOT5ZlTJgwARUVFQCA//3f/4UgCNi/f/8Vj1+9ejVycnKGfE0QBHz/+98fwbNDREQX06k9ACKiseD999/H3XffDZ1Oh/vuuw9lZWXQaDQ4fvw4/vznP+PXv/41GhsbkZ2drfZQFevp6cHu3bvxj//4j2G9AL/nnntwyy23wOfzoba2Fi+99BKWLFmCffv2obS09LLjf/3rXyMhIeGyr1utVgBAV1cXZs6cCYfDgW9/+9uYPHkyzp07h0OHDuHXv/41HnvsMeTk5ODrX/86Xn75ZTQ3N1/x9/XZZ5+hpaUFf/M3fxP0n5mIiJRhMkNENEr19fVYu3YtsrOzsW3bNmRmZg75/v/7f/8PL730EjSaa0+GO51OxMfHh3KoI9LZ2Qngq6QgGAL5WSsqKnD//fcPfr5o0SLcfPPN+PWvf42XXnrpsuO/9rWvISUl5arne+WVV3Dq1Cns3LkT8+fPH/I9h8MBvV4PALjvvvvwX//1X3jjjTfwgx/84LLzrF+/HhqNBmvXrr3m+ImIKPS4zIyIaJSee+45OJ1OrFu37rJEBgB0Oh2eeOIJTJgwYfBrDz30EBISElBfX49bbrkFiYmJuO+++wAAO3bswNe//nVMnDgRBoMBEyZMwN/8zd+gp6dnyHkHztHQ0ICbbroJ8fHxGD9+PH7yk59AluUrjvU3v/kN8vPzYTAYMGvWLOzbt++aP9uPf/zjwdmJv/u7v4MgCEOWTFVWVuLmm2+G2WxGQkICbrzxRnzxxRdDzjGwDOvTTz/F9773PaSlpSErK+uaca9k0aJFAPqSx5Gor6+HVqvF3LlzL/ue2WyG0WgEACxYsAA5OTlYv379ZcdJkoS33noLS5Yswfjx40c0DiIiCh7OzBARjdL777+PSZMmYc6cOYoe5/V6cdNNN2HhwoV4/vnnYTKZAAAbNmyAy+XCY489hnHjxmHv3r34z//8T7S0tGDDhg1DzuHz+bBy5UrMnTsXzz33HDZt2oRnnnkGXq8XP/nJT4Ycu379epw/fx7f/e53IQgCnnvuOdx5551oaGiAKIpXHOOdd94Jq9WKv/mbvxlc9jWwlOvIkSNYtGgRzGYz/v7v/x6iKOLll1/GDTfcgE8//fSy5+N73/seUlNT8aMf/QhOp1PRcwX01dIAQFJS0hW/39XVddnXdDrd4IxSdnY2fD4fXnvtNTz44INXjSMIAu6991783//7f3HkyBGUlJQMfm/Tpk3o6uoaTDyJiEhlMhERjZjdbpcByHfcccdl3+vu7pY7OzsH/7lcrsHvPfjggzIA+Qc/+MFlj7v4uAH/8i//IguCIDc3N192jr/6q78a/Jrf75dXrVol6/V6ubOzU5ZlWW5sbJQByOPGjZO7uroGj924caMMQH7vvfeu+TMOPP4Xv/jFkK/fcccdsl6vl+vr6we/9uWXX8qJiYny9ddfP/i1devWyQDkhQsXyl6v95qxLo737LPPyp2dnXJbW5u8Y8cOedasWTIAecOGDUOOf+aZZ2QAV/xXVFQ0eFxbW5ucmpoqA5AnT54sP/roo/L69etlm8122RiOHDkiA5D/4R/+YcjX165dKxuNRtlut1/28+3bt++KP8+qVavk7OzsIV8DID/++OPDPhdERHRtXGZGRDQKDocDAK5YeH7DDTcgNTV18N+LL7542TGPPfbYZV+Li4sb/NjpdOLs2bOYP38+ZFlGZWXlZcdfXJQ/0CWrt7cXf/nLX4Ycd/fddw+Z1RhYttXQ0DDcj3kZn8+HLVu24I477kBeXt7g1zMzM3Hvvffi888/H3xuBnznO9+BVqsNOMYzzzyD1NRUZGRkYNGiRTh27Bj+7d/+DV/72teuePyf/vQnbN26dci/devWDX4/PT0d1dXVePTRR9Hd3Y3/+q//wr333ou0tDT89Kc/HbI0r7i4GNOnT8ebb745+DWn04l3330Xq1evhtlsDvjnICKi0GEyQ0Q0ComJiQCACxcuXPa9l19+GVu3bsXvf//7Kz5Wp9NdsXbk1KlTeOihh5CcnIyEhASkpqZi8eLFAAC73T7kWI1GMySZAIDCwkIAXy3LGjBx4sQhnw8kNt3d3Vf78a6qs7MTLpcLRUVFl31vypQp8Pv9OH369JCv5+bmKorxyCOPYOvWrXjvvfcGa4Z8Pt9Vj7/++uuxbNmyIf/mzZs35JjMzEz8+te/RmtrK06cOIH/+I//GFz69sorrww59r777kNjYyN27doFAHjnnXfgcrlGtMRMEATFjyEiouGxZoaIaBQsFgsyMzNx+PDhy743UDNyaVIxwGAwXNbhzOfzYfny5ejq6sLTTz+NyZMnIz4+HmfOnMFDDz0Ev98/4rFebVZEvkqzgGC7eMYpEAUFBVi2bBmAvr1atFotfvCDH2DJkiWj3udGEAQUFhaisLAQq1atQkFBAV5//XX8n//zfwaPueeee/D3f//3WL9+PebPn4/169cjKSkJt9xyy5BzDTQOuLRBwwCXyzV4DBERBRdnZoiIRmnVqlU4efIk9u7dO+pz1dTUoLa2Fv/2b/+Gp59+GrfffjuWLVt21c5Zfr//smVitbW1AHDZRo3BlJqaCpPJhBMnTlz2vePHj0Oj0Qzp3hYM//iP/4jExET80z/9U1DPm5eXh6SkJLS2tg75+vjx47FkyRJs2LAB7e3t2Lp1K772ta8NtnAeMNDt7UrPBdD3+4jG/YWIiKIBkxkiolH6+7//e5hMJnz7299Ge3v7Zd9XMvMxMHty8WNkWca///u/X/Uxv/rVr4Yc+6tf/QqiKOLGG28MOK5SWq0WK1aswMaNG4fMPLW3t2P9+vVYuHBh0OtKrFYrvvvd72Lz5s2oqqpS/Pg9e/ZcsYva3r17ce7cuSsumbvvvvvQ0dGB7373u5Ak6YpLzGbMmIG0tDT8z//8Dzwez5DvvfPOOzhz5gxuvvlmxeMlIqLhcZkZEdEoFRQUYP369bjnnntQVFSE++67D2VlZZBlGY2NjYObLAayt8rkyZORn5+Pp556CmfOnIHZbMaf/vSnq9a1GI1GbNq0CQ8++CDmzJmDjz76CB988AF++MMfIjU1Ndg/6hA/+9nPsHXrVixcuBDf+973oNPp8PLLL8Pj8eC5554LScwnn3wSL7zwAv71X/91SHE+ALz11ltXbMSwfPlypKen47XXXsPrr7+ONWvWYMaMGdDr9Th27Bh++9vfwmg04oc//OFlj73rrrvwve99Dxs3bsSECRNw/fXXX3aMXq/H888/jwcffBCzZs3C3XffjXHjxqGyshK//e1vMW3aNDzyyCPBexKIiGgQkxkioiC4/fbbUVNTg3/7t3/Dli1b8Nvf/haCICA7OxurVq3Co48+irKysmHPI4oi3nvvPTzxxBP4l3/5FxiNRqxZswbf//73r/h4rVaLTZs24bHHHsPf/d3fITExEc888wx+9KMfheLHHKKkpAQ7duzAP/zDP+Bf/uVf4Pf7MWfOHPz+979XvOdOoMaPH497770Xr732Gurr65Gfnz/4vSt1hgOA7du3Iz09Hd/97ndhMpmwbds2bNy4EQ6HA6mpqVixYgX+4R/+AdOnT7/ssWazGbfeeis2bNiAe+6556qF/N/85jeRmpqK5557Ds899xx6enqQlZWFJ554Av/8z/88pF5oYNZNSWc3IiK6MkEOV+UnEREF1UMPPYS33nrrip3UKHI5HA5YLBb80z/9E37605+qPRwioqjGmhkiIqIw2rdvH4C+vWyIiGh0uMyMiIgoDA4dOoS//OUv+OUvf4lx48Zh1apVag+JiCjqcWaGiIgoDP785z/jhz/8IXJycvDRRx8FvdsbEVEsYs0MERERERFFJc7MEBERERFRVGIyQ0REREREUYnJDBERERERRSUmM0REREREFJWYzBARERERUVRiMkNERERERFGJyQwREREREUUlJjNERERERBSVmMwQEREREVFUYjJDRERERERRickMERERERFFJSYzREREREQUlZjMEBERERFRVGIyQ0REREREUYnJDBERERERRSUmM0REREREFJWYzBARERERUVRiMkNERERERFGJyQwREREREUUlJjNERERERBSVmMwQEREREVFUYjJDRERERERRickMERERERFFJSYzREREREQUlZjMEBERERFRVGIyQ0REREREUYnJDBERERERRSUmM0REREREFJWYzBARERERUVRiMkNERERERFGJyQwREREREUUlJjNERERERBSVmMwQEREREVFUYjJDRERERERRickMERERERFFJSYzREREREQUlZjMEBERERFRVGIyQ0REREREUYnJDBERERERRSWd2gMgIhqOX5Zh93hhc0uwuSW4fT74/DK0GgFGrRZWowirUYTFoINGENQeLhEREYWJIMuyrPYgiIiuxCV50WBzodHmguTve6kSAFz8onXx56JGQK7VhDyrCSaR92qIiIjGOiYzRBRxJJ8fNZ0ONNl7LktehjNwfI4lDqWpZoharqYlIiIaq5jMEFFEaXd6sL/VBo/PP+pzGbUazMi0Ij3eEISRERERUaRhMkNEEaO+24nqDkfQz1uWZkZ+UnzQz0tERETq4voLIooIoUpkAKC6w4H6bmdIzk1ERETqYTJDRKprd3pClsgMqO5woN3pCWkMIiIiCi8mM0SkKsnnx/5WW1hiHWi1QQpCLQ4RERFFBiYzRKSqmk4HesOUYLj7u6QRERHR2MBkhohU45S8aLL3KGq9PFpN9h64JG8YIxIREVGoMJkhItU02lwQFBx/ZN8X+Nkj9+Nb86birsnjcdfk8dj85u8UxRT64xIREVH0YzJDRKrwyzIabS5FszKNR2twaNdnSLBYRxxXBtBgc8HPrvRERERRj8kMEanC7vFC8itLKBbfdhde238C//w/b4wqtuSXYfdwqRkREVG0YzJDRKqwuSXFj0lMSobBGKdafCIiIoosTGaISBU2t6SoXiaYBDCZISIiGguYzBCRKtw+X1i7mF1M7o9PRERE0Y3JDBGpwqewXmasxSciIqLRYzJDRKrQatRaZBYZ8YmIiGj0BFlmf1IiCr/KNjua7MpaM3+x5UO89vzP4PN60fllCwDAnDwOpoREFEybjr9+/sWAziMAyLGYMD3DonzgREREFDF0ag+AiGKT1ShCtit7jOvCebSdahryNUfXOTi6zmFcembA55H74xMREVF048wMEami2y1he/NZ1eIvyU5BEhMaIiKiqMaaGSJShcWgg6hS3YqoEWAxcGKaiIgo2vHdnGiU/HLfbvI2twSbW4Lb54PPL0OrEWDUamE1irAaRVgMOmgEFp0P0AgCcq0m1HU5w9qiWQCQZzXxd0FERDQGMJkhGiGX5EWDzYVGmwtSf5tfARhyYS4Ag3Uhoqbv4j3PaoJJ5P96QF9SUdvlDGtMGUCu1RTWmERERBQarJkhUkjy+VHT6UCTveey5GU4A8fnWOJQmmqGqOVKz4NtNjTZe8IWL8cSh4oMa9jiERERUegwmSFSoN3pwf5WGzw+/6jPZdRqMCPTivR4QxBGFr0knx9bGzvhDsJzOhyjVoPlualMIomIiMYIvqMTBai+24mdLV1BSWQAwO3zY2dLF+q7w7vMKtKI/UldOMzItDKRISIiGkP4rk4UgPpuJ6o7HCE5d3WHI+YTmvR4A8rSzCGNUZZmjvlZMCIiorGGyQzRMNqdnpAlMgOqOxxod3pCGiPS5SfFhyyhKUszIz8pPiTnJiIiIvUwmSG6Bsnnx/5WW1hiHWi1QQpD3Ugky0+Kx4KsZBiDtBTMqNVgQVYyExkiIqIxig0AiK7hYJsNzfaesO2Dwk5bfdgxjoiIiALBZIboKpySF5sbOsMed2VeKveh6eeSvGi0udAwsJePLEOWZQiarxKUi5MdUSMgz2pCLvfyISIiiglMZoiu4nCnQ5Xd6QuT41GSGtpi+Gjjl2XYPV58umcfXH4NcgsL4fPL0GoEGLVaWI0irEYRFoMOGkFQe7hEREQUJrx1SXQFfllGo80VcCJzZN8XePu/f4X6mio4ursAAI/8+F9x09oHFMWVATTYXJiSksiL8otoBAFJRhHnT9XDYDBg3pK5ag+JiIiIIgAXkxNdgd3j7VvWFKDGozU4tOszJFiso44t+ftmIehydrsdFotF7WEQERFRhGAyQ3QFNrek6PjFt92F1/afwD//zxuqxI8FsiwzmSEiIqIhuMyM6ApsbklRF63EpOSgxRbAZOZKenp64PV6mcwQERHRIM7MEF2B2+cLa+H/xeT++DSU3W4HACYzRERENIjJDNEV+BTUy4zF+JFoIJkxm9npjYiIiPowmSG6Aq1G3U5iasePRHa7HVqtFvHx8WoPhYiIiCIEkxmiKzBqtVArnRD649NQA8X/AltWExERUT82ACC6AqtRhGwP/PgvtnyI157/GXzer1oqv/kfv8C7v/0vFEybjr9+/sWAzyX3x6ehHA4H62WIiIhoCCYzRFegNJlwXTiPtlNNQ77m6DoHR9c5jEvPDHn8scQv9+2zY3NLsLkluH0++PwyvOMnIVEjoNHmgtUowmLQcWNRIiKiGCfIssxKY6JL+GUZH5xsV7RxZrCIGgGrJqXH3IW6S/KiweZCo801+Lxf3B5bluW+pX/9z4uoEZBrNSHPaoJJ5H0ZIiKiWMRkhugqDnc6UNflDGuLZgFAYXI8SlJjp2OX5POjptOBJnuPor19gK+SnRxLHEpTzRC1LAMkIiKKJXznJ7qKPKsp7HvNyAByraYwR1VPu9ODLY2daLL3AFCWyFx8fJO9B1sbO9Hu9AR1fERERBTZmMwQXYVJ1CHHEhfWmDmWuJhZMlXf7cTOli54fP6gnM/t82NnSxfqu51BOR8RERFFPiYzRNdQmmqGMUxLl4xaDUpjZHlZfbcT1R2OkJy7usPBhIaIiChGMJkhugZRq8GMTGtYYs3ItMZEzUe70xOyRGZAdYeDS86IiIhiABsAEAUglDMJAFCWZkZ+0tjf2V7y+bGlsTNoS8uuxajVYHluakwkiMDVW1prNQKMWi2sRpEtrYmIaMyJjcX5RKM0kGgEN6GRAQgxk8gAQE2nA71hSGSAvhqamk4HKjKsYYmnluFaWg9+3r8JLFtaExHRWMKZGSIF2p0eHGi1wT3KC3JZluHz9GDW+CTkpiYHaXSRzSl5sbmhM+xxV+aljsmLdra0JiIiYjJDpFgwLiKz4kXs/PN6JJnNeOCBB6DRjP2LyZHs22PvOocNL/4S+7Zvga2zA3HxCciZXIJHf/oLZEzIHvbxY3XfnnanB/tbbUFZrmfsrwtLjzcEYWREREThNfavoIiCTNRqUJFhxcq8VBQmx0PUfFV/cGklwsWfixoBhcnxWJmXitlZKVhz221obm7Gjh07wjJuNfllGY02l6JExtF9Dj/4xip89Po62Do7kZmTB0tKKk5U7Ud3R1tA55ABNNhc8I+hezZsaU1ERPSVsbf2gihMTKIOJalmTElJHFHhdU5ODq6//np8+umnyM3NxcSJE1X8aULL7vEO1nME6o0XnkNHyylMKCjCM6+8iaS0dACA1NsLJfNhkr+vMD7JKCqKH4lC3dIaQMzUbxER0djAZWZEKvL7/Xj11Vdhs9nw6KOPIi4uvJt0hkujzYXKdnvAx8uyjIfmluCC3Ybpi5bgbNuX6Gg5hYyJuVjzncexaPUaRfGnp1uQazUpHXZEaXd6sLOlK+RxFmQlc8kZERFFDS4zI1KRRqPBnXfeid7eXrz77rsYq/cWbG7psiV41+LoOocLdhsAoHLHdjgdDsSbrWg+cRQvPPU4dm96P+BzCf3xo5nk82N/qy0ssQ602iCFqeMcERHRaDGZIVKZxWLBbbfdhuPHj2P//v1qDyck3D6fonoZn9c7+HFWfgFe2robL23djaz8AgDAR6+vC/hccn/8aKZGS2siIqJowJoZoggwZcoUzJw5E5s3b8bEiRORnp5+2THRvCmiT2G9jDl5HHSiHl6pF9lFxRD1egBAdlExWurr0HHmdEjjRxKn5EWTvSesMZvsPZg8LmFMtrQmIqKxhe9URBFixYoVOHXqFN566y088sgjEMW+gvWxsCmiVqMsudKJIopnzcGhXTvQXHsMXqlvmVhz7TEAQGZObkjjR5JGm0txC/DREvrjjrWW1kRENPZwmRlRhBBFEV/72tdgs9mwadMmSD4/DrbZsKmhE3VdziHdwC69sL34c8kvo67LiU0NnTjYFhn1D0atVlHNDADc8+TT0Il6tJysxWPL5uKxZXPRcrIWGq0Wdz7yRMDnEfrjR6ORtLQ+su8L/OyR+/GteVNx1+TxuGvyeGx+83eK4o7FltZERDQ2MZkhiiCpqam4+eabUftlOz6sax1cXqT0knLg+CZ7D7Y2dqLd6QnqOAMehyyjtbUVnacbFV8YF5ZV4NlX/4iS2fPhdNggedyYNn8Rfr5+I0rnLgh8DACsUdqWeSQtrRuP1uDQrs+QYLGOKvZAS2siIqJIxtbMRBHmZNcFHOo8D9nvh6AJ3v2GsjRzWPYQ6enpQX19PU6ePImTJ0/C6XQiMS0TOUtvDXnsq1mSnRKV+8wobWkNAOe7u6CPi4P97Fk8tmwOAOCRH/8rblr7gOL4Y6GlNRERjW2RsaCeiAD0bYp4qPM8AAQ1kQFCtyniwOxLXV0dTp48iTNnzkCWZaSlpaGsrAwFBQW4LisLmxrPKp5lCAZRI8BiiM6XuoGW1kqetcSk5KDEHgstrYmIaOyLznd4ojGo3ekJ2e7uA6o7HEjQ60a9KaLL5Rqcfamvr4fT6YTBYEBeXh5Wr16NSZMmwWweWjyeazWhrssZ9kL2PKsp4rq7BUppS+tgGgstrYmIaOxjMkMUAcK9KeLy3FSI2sBnfmRZxpdffjlk9gUA0tPTUV5ejoKCAmRlZUF7jUL7PKsJtV3OUY9fCRmI6mVSareUVjs+ERHRcJjMEEUANTZFrMiwXvM4p9M5ZPbF5XLBYDAgPz8fM2bMwKRJk5CYmBhwXJOoQ44lLqx7puRY4iKmPfVIqN1SWu34REREw4ned3miMSJSNkX0+/1DZl++/PJLAEBGRgYqKioGZ180o6jlKU01o+2CB+4QJ26y7IdRq0VplO+TMtDSWo35kWhuaU1ERLGD3cyIVHa406FKLUlhcjyy4zRDZl96enpgNBqRn5+PSZMmYdKkSUhISAhq7HanBztbuoJ6zivG2fsJ7lh2AzIzM0MeK1RG0s3siy0f4rXnfwaf14vOL1sAAObkcTAlJKJg2nT89fMvBnwudjMjIqJIx5kZIhWNZFNEALB3ncOGF3+Jfdu3wNbZgbj4BORMLsGjP/0FMiZkD/t4GcCx9m689edXAVlGZmYmZs6c2dd57LrrRjX7Mpz0eAPK0swhbXZQZNbjbM95rFu3DmvWrMGUKVNCFiuURrI/juvCebSdahryNUfXOTi6zmFcurLELlr35yEiotjBmRkiFXW7JWxvPqvoMY7uc3j666vQ0XIKOlGPzJxcyLKMjpZT+NErb2DKjDkBnyvL04XivOygz74Eor7bGZKEZmA/HUmSsHHjRhw5cgRLlizBokWLIERZVzO/LOODk+2qtbReNSk9ajvBERFRbODMDJGKRrKPxxsvPIeOllOYUFCEZ155E0lp6QAAqbcXSqsrUifmIiFBnWVE+UnxSNDrcKDVFpQaGqNWgxmZ1sG206Io4q677kJKSgq2b9+Ozs5O3HbbbRDF6Jlt0AgCW1oTERFdQ+jWkhDRsAY2RQyULMvYtek9AEBKxng8+/Ba3Ds9H397+zJ8seUDiPrA94+JhE0R0+MNWJ6bihxL3OCYlBg4PscSh+W5qZftnyMIAm644QZ87Wtfw/Hjx/Hqq6/i/Pnzox94GOVZTWFvABDtLa2JiCh2cJkZkYp2n+lC6wVPwMfbz53FtxdMG/w8ub8Goqu9FQDw1Au/wbyVqwM+X2aCAfOuC86O8aPlkrxotLnQYHMNLqu6tJPXxZ+LGgF5VhNyraaA2i9/+eWXePPNNyEIAtauXRtVjQEOttnC3tJ6uNbdREREkYDJDJGKPj99Dh2u3oCP72pvw3cWVwAAsvIL8PzbWwEAT61Zjpb6OpTMmoefvPangM+XZtJj4YRxygYdYn5Zht3jhc0tweaW4Pb54PPL0GoEGLVaWI0irEYRFoNO8TKo8+fP480330RHRwfWrFmD4uLiEP0UwSX5/Nja2BnyltZA33I9pZuqEhERqYU1M0QqUropoTl5HHSiHl6pF9lFxRD1egBAdlExWurr0HHmdEjjh4NGEJBkFJEUgk5aiYmJeOihh7Bx40Zs2LABN9xwA66//vqIbwwg9tcDhaOl9YxMKxMZIiKKGnzHIlLRwKaIgdKJIopn9XUra649Bq8kwStJaK49BgDIzMkN+FyxuiniQGOAG264AZ988gn+/Oc/Q5LUrR0KxPnW02g9uCukMcrSzJfVHREREUUyzswQqchqFCEr2xMR9zz5NI7u24OWk7V4bNlcAH01MxqtFnc+8kTA55ERu/uICIKAxYsXIyUlBe+88w66urqwdu1aJCYmqj20Kzpx4gQ2bNiA/Px8lKYkoObshaDHGGhpTUREFE1YM0OkopHsMwMAxw/uxfoXnsPJmkroDUbkFk/FPU8+jcKyCkXnWZKdEpLlXNFkoDEAANxzzz0R1xjg2LFjeOutt1BUVIS77roLWq0W7U5PyFpaExERRRMmM0Qq4qaIkSFSGwMcOXIEf/rTn1BcXIw1a9ZAe9GyQMnnR02nA032nsu6vg1n4PgcSxxKU82skSEioqjFZIZIZYc7HapsiliYHI+SVHMYo0Y2SZLw7rvv4vDhwyNqDBDsLmyHDh3CO++8g6lTp+KOO+6ARnPlhCPULa2JiIgiGZMZIpW5JC82NXSGPe7KvFRezF5ClmV89tln+OSTTzB16lTcdtttEMVrL8NzSV402FxoVJBM5FpNyLtGMlFVVYWNGzeivLwct95661UTmYuFsqU1ERFRpGIyQxQBuCliZDl69CjefvttpKWlXbUxQKiWeR08eBDvvfceKioqsHr16ohvG01ERKQmJjNEEYCbIkae1tZWvPHGGwCAtWvXYvz48YPfa3d6sL/VBk+QC/D37duHDz/8EDNnzsQtt9zCRIaIiGgYTGaIIkS70xOWTREXZCWzc1WALm4McMcdd6CkpAT13U5UdziCHsvi6sLn776FOXPm4KabbmIiQ0REFAAmM0QRJFQXygO4l4hyFzcGmHPz7XBZ0kMWy9D1JW6ZW8FEhoiIKEBMZogiTKgSGiYyIyfLMrbtOQBH0nUhj8WZMyIiosBx0TxRhMlPiseCrGQYg1TTYtRqsCArmYnMKHj9MjwpE4Aw3Ps50GqDFIbaKSIiorGAyQxRBEqPN2B5bioMLhtGMnk6sEgpxxKH5bmpvNM/SjWdDvT6/EAYln+5+7ukERER0fCYzBBFKNnnxZGt78F46giKkuMhar66kL70kvriz0WNgMLkeKzMS0VFhpVdy0bJKXnRZO8J66amTfYeuCRvGCMSERFFJ+6YRxShKisr4Xa7sWD2LFitZkxJSeSmiCpotLkU7yMzWkJ/3JJUcxijEhERRR8mM0QRyOfzYffu3Zg6dSqsVisAQCMISDKKSDJee0d6Ch6/LKPR5hpRImPvOocNL/4S+7Zvga2zA3HxCciZXIJHf/oLZEzIvuZjZQANNhempCQyMSUiIroGJjNEEejIkSOw2+1YsGCB2kOJaXaPF5JfeSrj6D6HH3xjFTpaTkEn6pGZkwdZlnGiaj+6O9qGTWYAQPLLsHu8TF6JiIiugckMUYSRZRmff/45CgoKkJ4euj1NaHg2tzSix73xwnPoaDmFCQVFeOaVN5GU1vd7lHp7oWTBms0tMZkhIiK6BlYGE0WYuro6dHZ2clYmAtjc0mXNFoYjyzJ2bXoPAJCSMR7PPrwW907Px9/evgxfbPkAoj6wznICRp5MERERxQomM0QRZufOncjKysLEiRPVHkrMc/t8iutlHF3ncMFuAwBU7tgOp8OBeLMVzSeO4oWnHsfuTe8HdB65Pz4RERFdHZMZoghy6tQpnDp1CgsXLoTAwm/V+UZQL+PzftVSOSu/AC9t3Y2Xtu5GVn4BAOCj19eFND4REVEsYTJDFEF27tyJ1NRUFBYWqj0UAqDVKE8ozcnjoBP1AIDsomKIej1EvR7ZRcUAgI4zp0Man4iIKJYwmSGKEB0dHaitrcX8+fM5KxMhjFqt4poZnSiieNYcAEBz7TF4JQleSUJz7TEAQGZObkDnEfrjExER0dWxmxlRhNi1axfMZjNKS0vVHgr1sxpFyHblj7vnyadxdN8etJysxWPL5gIAutpbodFqcecjTwR0Drk/PhEREV0dZ2aIIoDNZkNNTQ3mzZsHLe/GR4yRJhOFZRV49tU/omT2fDgdNkgeN6bNX4Sfr9+I0rmBd6ljMkNERHRtnJkhigC7d++GwWBARUWF2kOhi1gMOogaYUQbZ06umI2f/O6tEccWNQIsBr5EExERXQtnZohU5nK5UFlZiVmzZkGv16s9HLqIRhCQazUprpsZLQFAntUEDWuniIiIronJDJHK9u7dC1mWMWfOHLWHQleQZzUp3mtmtGQAuVZTmKMSERFFHyYzRCrq7e3F3r17UVFRAZOJF6+RyCTqkGOJC2vMHEscTCKXmBEREQ2HyQyRig4ePAi324158+apPRS6htJUM4za8LxcGrUalKaawxKLiIgo2jGZIVKJz+fD7t27UVpaCqvVqvZw6BpErQYzMq1hiTUj0woxTIkTERFRtOM7JpFKDh8+DIfDgQULAm/VS+pJjzegLC20MyZlaWakxxtCGoOIiGgsYTJDpAJZlrFz504UFhYiLS1N7eFQgPKT4kOW0JSlmZGfFB+ScxMREY1VTGaIVFBbW4vOzk7OykSh/KR4LMhKDloNjVGrwYKsZCYyREREI8BkhkgFO3fuxIQJEzBx4kS1h0IjkB5vwPLc1MEuZ0p3gxk4PscSh+W5qVxaRkRENELs/UkUBH5Zht3jhc0tweaW4Pb54PPL0GoEGLVaWI0irEYRFoMOLadP4/Tp01i7dq3aw6ZRELUaVGRYMXlcAhptLjTYXJD8fTvSCMBXe9PIMgRBGPxc1AjIs5qQazWx/TIREdEo8Z2UaBRckhcNNhcar3YhO/C5ve9jUSOg58yXSJ8wEYWFheEeLoWASdShJNWMKSmJlyW0LS1fQhBk5E+cOCSh1QhK53KIiIjoSgRZlsO9uTVR1JN8ftR0OtBk77kseRmO7PdDEATkWE0oTTWzDe8Y9oc//AE+nw/33nuv2kMhIiIakzgzQ6RQu9OD/a02eHx+AMoSGQAQNH3JS5O9B20XPJiRaWXNxBil0+ng8XjUHgYREdGYxVvCRArUdzuxs6VrMJEZLbfPj50tXajvdgblfBRZdDodvF6v2sMgIiIas5jMEAWovtuJ6g5HSM5d3eFgQjMG6XQ6SJKk9jCIiIjGLCYzRAFod3pClsgMqO5woN3JJUljCWdmiIiIQovJDNEwJJ8f+1ttYYl1oNUGKUhL2Eh9TGaIiIhCi8kM0TBqOh3oDVOC4e7vkkZjA5MZIiKi0GIyQ3QNTsmLJnuP4o5lo9Fk74FL4gXwWCCKImtmiIiIQoitmYmuodHmUryPjL3rHDa8+Evs274Fts4OxMUnIGdyCR796S+QMSF72McL/XFLUs0jHTZFCM7MEBERhRaTGaKr8MsyGm0uRYmMo/scfvCNVehoOQWdqEdmTh5kWcaJqv3o7mgLKJmRATTYXJiSksid4qOcTqeDz+eDLMsQ+LskIiIKOiYzEcQvy7B7vLC5JdjcEtw+H3x+GVqNAKNWC6tRhNUowmLQ8SI3DOweLyS/sgVmb7zwHDpaTmFCQRGeeeVNJKWlAwCk3l4omd+R/H1/C0lGUVF8iiw6Xd9LrNfrhSjyd0lERBRsTGYigEvyosHmQqPNNXjxfOnSJgGAbO/7WNQIyLWakGc1wSTyVxgqNreyWgdZlrFr03sAgJSM8Xj24bXoaDmFjIm5WPOdx7Fo9RrF8ZnMRLeBBIbJDBERUWjwSlhFUn/nqiZ7z2XJy6X38C/+XPLLqOtyorbLiRxLHEpTzRC17OUQbDa3pKhextF1DhfsNgBA5Y7tSE7PRLzZiuYTR/HCU49DpxMxb+XqgM4lQHkyRZHn4pkZIiIiCj5eAauk3enBlsZONNl7ACgrML/4+CZ7D7Y2dnKzxRBw+3yKfi++iy5Ys/IL8NLW3Xhp625k5RcAAD56fV3A55L741N0YzJDREQUWkxmVFDf7cTOli54grR3idvnx86WLtR3O4NyPurjU1gvY04eB52oBwBkFxVD1Osh6vXILioGAHScOR3S+BR5BpIZtmcmIiIKDSYzYVbf7UR1R2g2RazucDChCSKtRlmTBZ0oonjWHABAc+0xeCUJXklCc+0xAEBmTm5I41Pk4cwMERFRaLFmJozanZ6QJTIDqjscSNDrkB5vCGmcWGDUahXvMXPPk0/j6L49aDlZi8eWzQUAdLW3QqPV4s5Hngj4PEJ/fIpuFzcAICIiouDjzEyYSD4/9rfawhLrQKsNUpCWsMUyq1FUXMtUWFaBZ1/9I0pmz4fTYYPkcWPa/EX4+fqNKJ27IODzyP3xKbpxZoaIiCi0ODMTJjWdDvSGKcFw93dJq8iwhiXeWDXSZGJyxWz85HdvqRafIgeTGSIiotDizEwYOCUvmuw9iu/yj0aTvQcuiRdQo2HWa6EN62/tK6JGgMXAew3Rjg0AiIiIQotXS2HQaHMFXHtxZN8XePu/f4X6mio4ursAAI/8+F9x09oHFMUU+uOWpJoVjzfW9fb24tChQ9izZw+043OROqUMghC+vF8AkGc1QSOwAUC048wMERFRaDGZCTG/LKPR5gr4/n7j0Roc2vUZ0rMmDiYzIyEDaLC5MCUlkRfFAbLZbNi7dy8qKyvh8XhQVFSE8vJiHOkN7wSmDCDXagprTAoNbX8TByYzREREocFkJsTsHi8kBfuFLL7tLiy/+37Yz57FY8vmjCq25Jdh93iRxNqLq5JlGc3Nzdi7dy+OHz8Og8GA6dOnY/bs2bBarQAAZ5ttcHPTkI/H78f5U/U44WpDeXk5BCaiUU0QBOh0OiYzREREIcJkJsRsbmVr5ROTkoMen8nM5bxeL2pqarBnzx60t7cjJSUFN998M8rKyqDX64ccW5pqRtsFD9xhaOBg1GkhuG14993tqKysxKpVq5Cenh7yuBQ6oiiyZoaIiChEmMyEmM0tKd6rJFgEKE+mxrrz589j3759OHDgAFwuFwoKCrB8+XLk5eVddRZE1GowI9OKnS0jX/YXqJnjk5BecBumTyvFhx9+iJdffhlz587F4sWLYTBw76BoxJkZIiKi0GEyE2Jun0+lflh9CZTb51MpemRpaWnBnj17cPToUeh0OpSXl2P27NkYN25cQI9PjzegLM0c0k1Py9LMg5ud5ubm4tFHH8Xu3bvx6aef4vDhw1i5ciWmTJnCpWdRhskMERFR6DCZCTGfgnqZaI7vl/vqc2xuCTa3BLfPB59fhlYjwKjVwmoUYTWKsBh0YWtI4PP5cPToUezZswdnzpxBUlISli9fjunTp49oliM/KR4AQpLQlKWZB88/QKvVYuHChZg6dSo2bdqEDRs2YNKkSbj55puRnBzc5YgUOkxmiIiIQofJTIhpNereRQ91fJfkRYPNhUaba7DRwaXL6gQAsr3vY1EjINdqQp7VBJMYmj8/p9OJ/fv3Y//+/bhw4QLy8vJwzz33YNKkSdBoRteZLD8pHgl6HQ602oJSQ2PsX8I2MCNzJVarFWvXrsWJEyfw0Ucf4aWXXsLChQuxcOHCwda/FLlEUWQyQ0REFCKCLMvqTh2McZVtdjTZA2/N/MWWD/Ha8z+Dz+tF55ctAABz8jiYEhJRMG06/vr5FwOOLQDIsZgwPcOifODDkHx+1HQ60GTvUVwTNHB8jiUOpalmiNrgtD5ubW3Fnj17cPjwYQiCgGnTpmHOnDlIS0sLyvkvptbPL0kSPvvsM+zatQsWiwW33HILJk2apHD0FE7r1q1DUlIS7rjjDrWHQkRENObwtm6IWY3i4KxEIFwXzqPtVNOQrzm6zsHRdQ7j0jMVxZb74wdbu9OD/a02ePpnJpRmwwPHN9l70HbBM+zMxLX4/X4cP34ce/bswalTp2A2m7FkyRJUVFQgLi5uROcMhKjVoCLDisnjEtBoc6FhuJmpgcdpBORZTcgd4cyUKIq48cYbMW3aNHz44Yd4/fXXUVxcjJtuuglmMzdIjURcZkZERBQ6nJkJsW63hO3NZ1WLPzXOj4IJ44NWNF7f7Qxbzci19PT04ODBg9i3bx/sdjsmTpyIOXPmYPLkyaNeSjYSatQMybKMw4cPY/PmzZAkCTfccANmz549uFHjaEViHVS0uPi523/4GCDqkTl+PJ87IiKiIGMyE2J+WcYHJ9sVbZwZLL5eD46+/TskWa2YOnUqSktLkZqaOuLzhSqRGRBIQtPR0YE9e/bg0KFDkGUZpaWlmD17NjIzlc1ajSVutxsff/wx9u/fj9TUVKxatQoTJ04c8fkCroPq/zgcdVDR4krPnez3A4IweEOBzx0REVHwMJkJg8OdDtR1OcPaolkAUJAUD9OFs6ipqcGxY8fg8XiQkZGBqVOnYurUqbBYAq+laXd6wrLPyoKs5MuWnMmyjNraWuzduxcNDQ1ISEjAzJkzMXPmTMTHBz6bM9Z9+eWX+OCDD/Dll1+ivLwcy5cvh8lkCvjxkVgHFS343BEREamDyUwYuCQvNjV0hj3uyrzUwbu9Xq8XdXV1OHz4MGpra+H1epGdnY2pU6eiuLj4mhe9ks+PLY2dgzUyoWTUarA8NxWiVgOPx4PKykrs3bsX3d3duO666zBnzhwUFxcHbSnVWOP3+3Hw4EFs27YNgiDgxhtvREVFxbDLDC+tgxqNQDq0jSV87oiIiNTDZCZMDrbZ0GTvCVu8HEscKjKsV/yex+PB8ePHUVNTg4aGBgiCgPz8fJSWlqKoqAh6vX7I8QfbbGi294RtZinDIMB+rBJVVVXwer0oLi7GnDlzkJWVFaYRRD+n04mtW7eiuroaWVlZWLVqFTIyMq54bKTUQUUjPndERETqYjITJpLPj62NnUHZm2Q4F89uDOfChQs4evQoampq0NLSAlEUUVRUhNLSUuTn58Ptl7E5zLNKsizj1F/eQVnxZMycOZNdukahubkZH3zwAc6ePYvZs2djyZIlQzYMjYQ6qGjF546IiEh9TGbCSM26k0B0d3fj8OHDqKmpQWdnJ+Li4lC4aBn8yRnoW9kfGHvXOWx48ZfYt30LbJ0diItPQM7kEjz6018gY0L28CeQZRQkxaM0Pfj748Qin8+HL774Ap9++ikMBgNuuukmlJSUoMPVG9F/j5Es0v9fJiIiihVMZsIsGu7myrKMjo4OHKqpgS19ErT6wC+mHN3n8PTXV6Gj5RR0oh6ZObl952s5hR+98gamzJgT0HlEjYBVk9LZtjaI7HY7Nm/ejGPHjiGvoABJM5egNwz/9yuZKYwGatWQERER0eWYzKggWtbZj2SPnJefeRpb/vAaJhQU4ZlX3kRSWjoAQOrtBSBDVJAYLclOQVIINv2MdXV1ddjd3I7463IhhGlPnmvVcEWbcNeQjaXnjoiIKNh4u08F+UnxWJCVDGOQ7rYatRosyEoO+vp6m1tSdLwsy9i16T0AQErGeDz78FrcOz0ff3v7Mnyx5QNFicxI4lNgxufkImFCftgSGQBosvfAJXnDFi9UnJIXTWFMZICx89wRERGFApMZlaTHG7A8NxU5ljgASipSMOT4HEscluemhmRdvc0tKRqXo+scLthtAIDKHdvhdDgQb7ai+cRRvPDU49i96f2AzyWAyUyoNNpciv/eRkvojxvt+NwRERFFFm45rSJRq0FFhhWTxyWg0eZCg4Id1/OsJuSGeNdwt8+n6A60z/vV3eOs/AI8//ZWAMBTa5ajpb4OH72+DvNWrg7oXHJ/fAouvyyj0eZSPLMw2qYOMoAGmwtTUhKjtg6Kzx0REVHkYTITAUyiDiWpZkxJSYTd44XNLcHmluD2+eDzy9BqBBi1WliNIqxGERaDLiwXNT6/sss2c/I46EQ9vFIvsouKIfbvV5NdVIyW+jp0nDkd0vg0PLvHO5gwB8rRfQ4/+MbFTR3yIMsyTlTtR3dHW2Ad6gBIfhl2jzdq66D43BEREUUeJjMRRCMISDKKEXPBotUoS5h0oojiWXNwaNcONNceg1fqWybWXHsMAJCZkxvS+DS8kSzde+OF59DRcuqqTR2Uxo+Uv2+l+NwRERFFHiYzdFVGrfay5W7DuefJp3F03x60nKzFY8vmAgC62luh0Wpx5yNPBHweoT8+BddAHVSgv9MrNXXoaDmFjIm5WPOdx7Fo9ZqAY0d7HRSfOyIiosjD1sx0VY02Fyrb7Yofd/zgXqx/4TmcrKmE3mBEbvFU3PPk0ygsq1B0nunpFuRaTYrj09XtPtOF1guegI+3nzuLby+YNvh5cnomgL4EFQCeeuE3AddBQZZh6HXBer79qocIwyyfDOX3h3vsWVMK3DojEOASz6A+dwAyEwyYd11ywMcTERHFAs7M0FVZR7ikZXLFbPzkd2+pFp+uTmkdUjCbOkAQ0GWz4fDuz696yHD3VgK59zLac1zt+xMX3YSEjKxh4w8I6nMH1pARERFdCZMZuiqLQQdRIygueg4GUSPAYuCfZ7AprUMKdlOHSfl5+Ob1MxU9JlIondUK9nPHGjIiIqLLcZ8ZuiqNICDXalJlX408q4ltaENgoA4qUANNHQAMNnXwStKImjpEex0UnzsiIqLIw1vfdE15VhNqu5xhjSkDrJUJEatRhKywDCpYTR1kRPfSQT53REREkYczM3RNJlGHHEtcWGPmWOJCuhloLBvJBXFhWQWeffWPKJk9H06HDZLHjWnzF+Hn6zeidO6CkMePFHzuiIiIIg+7mdGwJJ8fWxs74fb5Qx7LqNVgeW4qRC3z7FDwyzI+ONmuWh3UqknpUbt8kM8dERFR5OEVIw1L1GowI9MallgzMq1MZEKIdVAjx+eOiIgo8vCqkQKSHm9AWZo5pDHK0sxIjzeENAb1XRiHe25hrNRB8bkjIiKKLExmKGD5SfEhS2jK0szIT4oPyblpqK/qoMJ3WT5W6qBYQ0ZERBRZmMyQIvlJ8ViQlQyt7IPsH30NjVGrwYKsZCYyYSTLMpwNRyH1uALahHK0jFoNSlNDO6sXTqWpZhjDtBRyrD13REREwcZkhhRLMerQvO1dyF3tAKC4hmDg+BxLHJbnpnJpWRj19PTgzTffxMdbt8Jy4SyEMNRhjLU6KNaQERERRQ6uXSDFDhw4ANu5s7incALirUlotLnQYHMNdnkSMHQB08WfixoBeVYTcq0mLp0Jsy+//BIbNmyA2+3GPffcg8LCQtR3O1Hd4QhZzLFaBzVQQ8bnjoiISF28miRFent78dlnn6GsrAypqakAgJJUM6akJMLu8cLmlmBzS3D7fPD5ZWg1AoxaLaxGEVajCItBx65MYSbLMg4cOIBNmzYhPT0dDz74IKxWKwAMLu8LxUX5WK+DCuVzd+7wPiQvXQRg7D5/REREwcBkhhT54osv4Ha7ccMNNwz5ukYQkGQUkcSN/SJKb28vPvjgAxw6dAgzZ87ETTfdBJ1u6P/2+UnxSNDrcKDVFpS9hIz9y7BiYVYhFM9dsUWPd8804bXXmvCtb30LiYmJQRgpERHR2MRNMylgLpcL//7v/46KigrcdNNNag+HhnH27Fn88Y9/hM1mw6233orS0tJrHi/5/KjpdKDJ3nPZUsHhDByfY4lDaao55uo8gv3c2Ww2rFu3DgaDAQ899BBMJrZmJiIiuhImMxSwzZs34+DBg3jiiScQH8/lL5Hs8OHDePfdd2GxWPCNb3xjcElgIFySl3VQIxTM5+7s2bNYt24dLBYLHnjgARiNxnD8CERERFGFyQwFxG634z//8z+xaNEiLF68WO3h0FV4vV5s2bIF+/btQ2lpKVavXg29Xj+ic/llmXVQIxSs566trQ2vvvoq0tLScP/990MUuYyTiIjoYkxmKCAbN25EbW0tnnjiCRgMY78WIhrZbDZs2LAB7e3tWLlyJWbMmBGW1ssUWqdPn8Zrr72GiRMnYu3atZfVPBEREcWy2FrYTiPS2dmJ6upqXH/99UxkIlRdXR1efvllOJ1OfPvb38bMmTOZyIwREyZMwNq1a9HU1IQ///nP8Adhs1oiIqKxgskMDWv79u0wm82YMWOG2kOhS/j9fnz88cdYv349Jk6ciO9+97sYP3682sOiIMvLy8PXv/51HD9+HO+++y44oU5ERNSH6xXoms6cOYNjx47hjjvu4PKWEQhl3cmFCxfw5z//GU1NTbjxxhuxYMECzsaMYUVFRVizZg3+/Oc/Q6/X4+abb+bvm4iIYh6vTumqZFnGX/7yF6Smpg7b1peGckleNNhcaByuq5W972NRIyDXakJegB3Bmpub8dZbb0GWZTzwwAPIyckJ9o9AEai0tBS9vb14//33YTAYcOONN6o9JCIiIlUxmaGramhoQFNTE9auXQuNhisSA3Gt/UYuXRh08eeSX0ZdlxO1Xc5r7tUiyzJ27dqFbdu2YeLEibjrrru4qWKMmTFjBnp7e7Flyxbo9XosWrRI7SERERGphskMXZEsy9i2bRuysrJQWFio9nCiQrvTg/2tNnj6d4JXWtUwcHyTvQdtFzyYkWlFevxXDRfcbjfeeecdnDhxAgsWLMDSpUuZZMaoefPmwePx4OOPP4bBYMDs2bPVHhIREZEqmMzQFR09ehStra146KGHuC4/APXdTlR3OIJ2PrfPj50tXShLMyM/KR6tra344x//CLfbjbVr16KoqChosSg6LV68GB6PBx999BH0ej3Ky8vVHhIREVHYMZmhy/h8Pnz88ccoKChAdna22sOJeMFOZC5W3eHA6dOn8Pm7f0JaWhoeeOABJCUlhSQWRRdBELBixQp4PB68++670Ov1KC4uVntYREREYcVkJgYo7ahVVVWFrq4ufP3rX1d76BGv3ekJWSIzoMtgxbT5i3DL9QvYUY6GEAQBq1evhiRJ+NOf/gS9Xo9JkyapPSwiIqKw4ZXRGDaSjlrZZiM+37sPpaWlyMjICPeQo4rk82N/qy30gWQZuomTIQusj6HLaTQa3HHHHejt7cUf/vAH3H///ZxRJSKimCHI3H1tzLlWR61hyTJkAOONWsyckHrFjlrU52CbDc32HsWF/iOVY4lDRYY1TNEo2ni9Xqxfvx5nzpzBgw8+yM1TiYgoJvBKdYxpd3qwpbETTfYeAMo7akEQIAgCWj1+bG3sRLvTE/QxjgVOyYumMCYyQF+XM5fkDWNEiiY6nQ5r165FWloafv/736Ojo0PtIREREYUcZ2bGkFAVog901KKvHO50oK7LGVAy09FyGo8tm3PV73/j8b/F3X/11LDnEQAUJsejJNUc+EAp5vT09ODVV1+F0+nEt771LSQnJ6s9JCIiopDhzMwYEeqOWvXdzpCcOxr5ZRmNNlfAszKiXo+Csooh/8bn5g9+Pyk1PaDzyAAabC74ef+BriEuLg73338/DAYDfve738HhCG2DCiIiIjVxZmYMaHd6sLOlK+RxFmQlD9nEMVZ1uyVsbz47qnP8909+iE3r/xcJFiv+6+N9iIsPfOZrSXYKkoziqOLT2Ge327Fu3TrodDp861vfQryCvzEiIqJowZmZKBe2jloADrTaIPXvbh/LbG5pVI8/392F7W//AQCwYu0DihKZYMSn2GCxWPDAAw/A4/HgtddeQ09Pj9pDIiIiCjomM1GuptOB3jAlGO7+LmmxzuaWIIzi8ZveeBWenh6IegNuuf/bih4rgMkMBS45ORnf/OY34XA4sH79evT29qo9JCIioqBiMhPF2FFLHW6fb8TPudTrwab1/wsAuP62O5GUmqbo8XJ/fKJApaWl4b777kNHRwfefPNNeL2x/f8vERGNLUxmolijzaV4hsDedQ7/89N/xHeXzsLdpdl4aG4JfvzQN9B2ujmgxwv9cWOZzz/y9PGTd96C7WwnBEHAbd96NOzxKTZdd911uOeee3D69Gm89dZb8DEhJiKiMYLJTJRS2lELABzd5/CDb6zCR6+vg62zE5k5ebCkpOJE1X50d7QFdA521AK0mpEtMpNlGe+u+y8AQMXiG5GVXxDW+BTbcnJy8I1vfAN1dXXYuHEj/H7WvxERUfTTqT0AGhm7xwtJ4R36N154Dh0tpzChoAjPvPImktL6WgJLvb1Qsr2m5Jdh93hjtqOWUauFAOUbku7fvgVfNtYDAG5/+Hsjii30xycaiYKCAtx5553405/+BFEUsXr1aggCk2MiIopeTGailNIicFmWsWvTewCAlIzxePbhtehoOYWMiblY853HsWj1GsXxYzWZsRpFyHblj9v4275ZmYJp01Eya+6IYsv98YlGqqSkBJIkYePGjTAYDFi+fDkTGiIiilpMZqLUQEetQGcHHF3ncMFuAwBU7tiO5PRMxJutaD5xFC889Th0OhHzVq4O6Fyx3lFrpMnEz37/tqrxiQaUl5fD4/Fg06ZNMBgMWLx4sdpDIiIiGhHWzEQppR21fBd1MMrKL8BLW3fjpa27B+s2Pnp9XcDnivWOWhaDDqJKdSuiRoDFwHsQNHpz5szB0qVL8cknn+CLL75QezhEREQjwmQmSintaGVOHgedqAcAZBcVQ9TrIer1yC4qBgB0nDkd0vhjiUYQMN6oBcLcBEEAkGc1QcMlQRQkCxcuxIIFC7B582YcPHhQ7eEQEREpxlu8AfLLfUXvNrcEm1uC2+eDzy9DqxFg1GphNYqwGkVYDLqwXGwq7WilE0UUz5qDQ7t2oLn2GLxS3zKx5tpjAIDMnNyQxh8rnE4nPvvsM1QfPY6CVXePavNMpWQAuVZTGCPSWCcIAm688UZ4PB6899570Ov1mDp16jUfE2mvhUREFNuYzAzDJXnRYHOh0eYa7B52aa2KAAwWhIsaAblWE/KsJpjE0D29I+modc+TT+Povj1oOVmLx5b1FaB3tbdCo9XizkeeCPg8sdhRy+PxYPfu3di9ezcEQcCCBQtgTDTi9AVP2MaQY4kL6d8UxSZBEHDLLbegt7cXb7/9NvR6PQoLCy87LlJfC4mIKLYJshzDG4Zcg+Tzo6bTgSZ7j+KkYeD4HEscSlPNELXBX83XaHOhsl15S63jB/di/QvP4WRNJfQGI3KLp+KeJ59GYVmFovNMT7fExCyB1+vF/v37sWPHDng8HsyePRsLFy6EyWSC5PNja2Mn3L7Q79dh1GqwPDc1JH9LRADg9/uxYcMG1NXV4b777kNubt9sbaS/FhIRUWxjMnMF7U4P9rfa4AnCRapRq8GMTCvS4w1BGNlX6s+0ofqCer+6JdkpY7o1s9/vR01NDbZv3w6Hw4Hy8nIsXrwYFotlyHHtTg92tnSFfDwLspKD/jdEdCmv14s33ngDLS0t+OY3vwkxKTXiXwuJiCi2MZm5RH23E9UdjqCftyzNjPyk+FGdw+l04vDhw6iqqkJbezuK1zwArT78FwaiRsCqSekhWw+v5pp8WZZRW1uLbdu2obOzE1OmTMHSpUuRkpJy1ceE6m9mQDD+dogC1dvbi9///vfoTUhGWtmcoJ+ff89ERBRMTGYuEokXpT6fD3V1daiqqkJdXR0AoLCwEGVlZZCSM3Gy26V4J/rRkP1+xPfYsXTqJOj1+qCeO+A1+f0fB3tNfnNzM7Zt24bTp08jJycHy5Ytw3XXXRfQYyM5CSZS6ninDUe7ekJ2fv5dExFRsDCZ6RdJy4VkWUZrayuqq6tRU1ODnp4eZGZmoqysDKWlpTCZ+mpVXJIXmxo6Qz7mSwaH2g/+AK3fi/nz52PWrFmjTmrUXpPf3t6Obdu2oa6uDhkZGVi2bBny8vIU74re7vTgQKstKDU0XJJDaomk10IiIqLhMJlB38X0lsbOoKwLH861CrnPnz+PmpoaVFdXo6OjAwkJCSgtLUV5eTnS0tKueL6DbTY02UN3B/VSOZY45BmBHTt2oKqqCkajEQsWLMDMmTNHlNSoWZ/U3d2N7du3o6amBsnJyVi6dCmKi4sVJzEXUzsxIxqNSHktJCIiChSTGfQlBM32nrAt18qxxKEiwwqgr+D2+PHjqK6uRn19PTQaDSZPnoyysjLk5+dDo7n2G72aHbVsNlvfnivV1YiLixucqRHFwBoDqLU068KFC/jss89w4MABmEwmLF68GNOnT4c2iO2mXZIXjTYXGhQsmcuzmpDLNrakIjVfC4mIiEYi5pMZp+TF5nAv1QIwzejF8ZpqHD58GB6PB1lZWSgrK0NJSQni4uIUnUvtZSHd3d2DMzUmk2lwpuZaSY0a9Ukejwe7du3C7t27odFosHDhQsyZMyfg5GskuMEgRQu1XgtX5qUygSciohGL+WTmcKcDdV3OgO9EHtn3Bd7+71+hvqYKju6+BOKRH/8rblr7QMAxZdmPzqPV6Gk+gbKyMpSVlWHcuHEjGP1XIqF5QXd39+BMTXx8PBYsWIAZM2ZcliyEO/nyer3Yt28fduzYAUmSBveKUZo0Eo1lSl8Lg0EAUJgcj5JUcxijEhHRWBLTt8P8soxGm7JuYI1Ha3Bo12dIz5o4mMwoJQgaZJaUY/UdK6EdZhlZoAYSDTU7aiUlJeH222/HokWLsGPHDmzZsgU7d+7EwoULUVFRAVEUIfn82N9qC/oYr2R/qw0Z51vx2Sfbcf78eUyfPh2LFy+G2cwLJ6KLKX0t7Gg5jceWXb1t8zce/1vc/VdPDXseGUCDzYUpKYmcmSQiohGJ6WTG7vEO1jMEavFtd2H53ffDfvbsNd/Mh+ODAEevD0nG4BW/5ifFI0GvU72jVnJy8mBS89lnn2Hz5s34/PPPsXDhQmgnFKA3DPU9AOD2elHZ2oWsrCwsWbLkmnvFEMUypa+Fol6PgrKKIV9zOuz4srEeAJCUmh7wuSR/31LMsbwJLxERhU5MJzM2t6T4MYlJyUGNH+w38PR4A5bnpkZER63k5GTccccdgzM1H+/YicLVE0bVLUwJQdAgOX8yVualcU0+0TUofS1MSkvHv/7h/SFf+++f/BBfNtYjwWLFolvvVByfyQwREY1ETF/h2dyS4ov9YBEwsmQqEKJWg4oMKyaPS4iIjlrjxo3DHXfcgetOteO0yxe08wZCgIBGm4tr8omuYbSvhee7u7D97T8AAFasfQBx8YFviBnK10IiIhr7YjqZcft8qiQyQN9Fg9sX2gt7k6hDSaoZU1ISVe+o5ZdltHlkQOH57V3nsOHFX2Lf9i2wdXYgLj4BOZNL8OhPf4GMCdnDPp5r8omGN9rXwk1vvApPTw9EvQG33P9tRY8Nx2shERGNXTGdzPgU1stEa3yNICDJKKq6jGMk9UmO7nP4wTdWoaPlFHSiHpk5eZBlGSeq9qO7oy2gZAbgmnyi4YzmtUjq9WDT+v8FAFx/251ISr3yBr+hik9ERLEtppMZrUbdO/Vqxw+nkSwjeeOF59DRcgoTCorwzCtvIimtr6hY6u2F0gUxXJNPdHWjeS365J23YDvbCUEQcNu3Hg17fCIiim3Ba6UVhYxaLZS+hX6x5UM8vmI+fvTAXYNfe/M/foHHV8zHC089HvB5hP74sWJgTX6gZFnGrk3vAQBSMsbj2YfX4t7p+fjb25fhiy0fQNQH3mGNa/KJrm0kr4VA3/+n7677LwBAxeIbkZVfoPgcsfZaSEREwRXTMzNWowjZruwxrgvn0XaqacjXHF3n4Og6h3HpmQGfR+6PHyuUrsl3dJ3DBbsNAFC5YzuS0zMRb7ai+cRRvPDU49DpRMxbuTqgc3FNPtG1jeS1EAD2b98y2I759oe/N6LYsfZaSEREwRXzyYxSS++8G0vvvFu1+NFK6Zp4n9c7+HFWfgGef3srAOCpNcvRUl+Hj15fF3AyM5L4RLFkpK9FG3/bNytTMG06SmbNDXt8IiKimE5mLAYdRI2guDA9GESNAIshdp5+pWvizcnjoBP18Eq9yC4qhqjXAwCyi4rRUl+HjjOnQxqfKJaM9LXwZ79/e9SxY+21kIiIgiuma2Y0goBcq2lEa8VHQwCQZzXFVKtgpWvydaKI4llzAADNtcfglSR4JQnNtccAAJk5uQGfi2vyia6Nr4VERBStYjqZAfreSMM9LyMDyLWawhxVXVajqPh5vufJp6ET9Wg5WYvHls3FY8vmouVkLTRaLe585ImAz8M1+UTD42shERFFo5hPZkyiDjmWuLDGzLHEwSTG1rKKkSQThWUVePbVP6Jk9nw4HTZIHjemzV+En6/fiNK5C0IenyiW8LWQiIiikSDLcsxXRks+P7Y2dsLt84c8llGrwfLcVIja2Moj/bKMD062q1aftGpSOpeyEA2Dr4VERBRt+C4CQNRqMCPTGpZYMzKtMfnmzTX5RJGPr4VERBRt+E7SLz3egLI0c0hjlKWZkR4f+GaPYw3X5BNFPr4WEhFRNGEyc5H8pPiQvYmXpZmRnxQfknNHC67JJ4oOIXkt7F/RzNdCIiIKJiYzl8hPiseCrGQYg7T8wajVYEFWMt+8+5WmmoP23A7HqNWgNDW0d5iJxqqgvhbKMiR3D0rNOr4WEhFRUDGZuYL0eAOW56YOziIorbYYOD7HEoflualcTnERrsknih7Bei2ckGhEx87N+OzDd+H3h765ABERxQ52MxuGS/Ki0eZCg8012IlLAIbUflz8uagRkGc1Iddq4vKma6jvdqK6wxGy83MpC1Fwjfa18NSpU1i3bh2WLVuGBQuUtVYnIiK6GiYzAfLLMuweL2xuCTa3BLfPB59fhlYjwKjVwmoUYTWKsBh07JwVoFAlNExkiEJnNK+FW7Zswd69e/HII48gLS1NpZ+AiIjGEiYzpKp2pwcHWm1B2dfC2L+Ejcv6iCKT1+vFyy+/DFEU8fDDD0Or1ao9JCIiinIsKCBVDazJ19jPQpZl1icRjWE6nQ5r1qxBW1sbPv/8c7WHQ0REYwCTGVKd5HHjyNZ3kdTZiMLkeIiar1KaS5Obiz8XNQIKk+OxMi8VFRks9ieKBuPHj8eiRYvw2WefobW1Ve3hEBFRlGOFOqlu//79AIA5FeWIj4/HlJRE1icRjWHXX389amtr8c477+A73/kOdDq+FRER0cjwHYRU5fV6sW/fPpSVlSE+vq9oXyMISDKKSDKKKo+OiEJBq9XijjvuwG9+8xt88sknWLZsmdpDIiKiKMV1OaSqmpoaXLhwAXPnzlV7KEQURunp6bjhhhuwa9cutLS0qD0cIiKKUkxmSDWyLOOLL75AYWEhUlJS1B4OEYXZggULMH78eLzzzjuQJEnt4RARURRiMkOqaWhoQEdHB+bNm6f2UIhIBRqNBnfccQfsdju2bdum9nCIiCgKsWaGgkrJhnq7d+9GZmYmsrOz1R42EakkJSUFS5cuxZYtWzB58mTk5OSoPSQiIooi3DSTgsIledFgc6HR5oLk7/uTEgBc/Md18ec6AfjySCVmT8pGRWlJmEdLRJFElmW8+uqrsNvtePTRR2EwjI39opTc3GFnRiKikWEyQ6Mi+fyo6XSgyd5zWfIyHNnvh6DRIMcSh9JUM/eJIYph3d3d+PWvf41p06Zh9erVag9nVJTe3BE1AnKtJuRZTTCJXDBBRKQEkxkasXanB/tbbfD4/KM+l1GrwYxMK9Ljx8YdWSJSbv/+/fjggw9w3333YdKkSWoPR7HR3NwZOJ43d4iIlGEyQyNS3+1EdYcj6OctSzMjPyk+6OclosgnyzJ+//vfo7OzE9/73vdgNBrVHlLAeHOHiEgdvPVDioUqkQGA6g4H6rudITk3EUU2QRBw2223obe3F5s2bVJ7OAGr73ZiZ0tXUBIZAHD7/NjZ0sXXQiKiADCZIUXanZ6QJTIDqjscaHd6QhqDiCKTxWLBypUrUV1djePHj6s9nGHx5g4RkbqYzFDAJJ8f+1ttYYl1oNUGKUh3OYkoupSVlaGwsBDvv/8+XC6X2sO5Kt7cISJSH5MZClhNpwO9YUow3P2FtEQUewRBwK233gq/348PPvhA7eFcEW/uEBFFBiYzFBCn5EWTvUdRd57RarL3wCV5wxiRiCJFQkICVq1ahaNHj+Lw4cNqD+cyvLlDRBQZmMxQQBptLijZ0u3Ivi/ws0fux7fmTcVdk8fjrsnjsfnN3ymKKfTHJaLYVFJSgpKSEnz44Yc4f/682sMZxJs7RESRg8kMDcsvy2i0uRS9cTcercGhXZ8hwWIdcVwZQIPNBT+7hxPFrFtuuQUajQbvv/8+ImUnAaU3d4KBN3eIiK6MyQwNy+7xDu5iHajFt92F1/afwD//zxujii35Zdg9vBtJFKtMJhNuvfVW1NbWorq6Wu3hjOjmTjBmqnlzh4joypjM0LBsbknxYxKTkmEwxqkWn4jGjqKiIpSVlWHTpk2w2+2qjmUkN3eCMVMN8OYOEdGVMJmhYdncUtiXVAwQwGSGiICVK1dCr9fj3XffVXW52Uhej4I1Uz3S+EREYxmTGRqW2+cLa6HrxeT++EQU24xGI26//XY0NDRg//79qo1jJDd3gjVTzZs7RESXYzJDw/IpXFIx1uITUWTIz8/HjBkzsHXrVnR1dakyBt7cISKKLExmaFhajVqLzCIjPhFFjhUrViA+Ph4bN26E3x/+jSTVvrmidnwiokjDZIaGZdRqFS+r+GLLh3h8xXz86IG7Br/25n/8Ao+vmI8Xnno84PMI/fGJiABAr9fj9ttvx6lTp7Bnz56wx1f75ora8YmIIg2TGRqW1SgqXlbhunAebaea0Plly+DXHF3n0HaqCV3tbQGfR+6PT0Q0ICcnB3PmzMG2bdvQ2dkZ1tgjubkTLLy5Q0R0OUGOlF3IKGJ1uyVsbz6rWvwl2SlIYkJDRBeRJAkvv/wyDAYDHn74YWg04bk312hzobJdWXvoL7Z8iNee/xl8Xu/gDR5z8jiYEhJRMG06/vr5FwM+1/R0C3KtJkXxiYjGMs7M0LAsBh1ElZY2iBoBFoNOldhEFLlEUcQdd9yB1tZW7Ny5M2xxRzJTHKyZ6pHGJyIayzgzQwE53OlAXZczrF18BACFyfEoSTWHMSoRRZNt27Zh165d+M53voOMjIyQx/PLMj442a5448xgEDUCVk1Kh0Zg3QwR0QDOzFBA8qymsLcjlQEupyCia1q8eDFSUlLwzjvvwBeGtsUaQUCu1RT2uhkBfa/DTGSIiIZiMkMBMYk65FhGv+mbEjmWOJhELjEjoqvT6XRYs2YNOjs78emnn4YlJm/uEBFFDl4pUsBKU81ou+CB2xf6vR2MWg1KubyMiAKQkZGB66+/Hp9++imKiopw3XXXDfm+X5Zh93hhc0uwuSW4fT74/DK0GgFGrRZWowirUYTFoAto5mPg5k6TvSdUP9JleHOHiOjKWDNDirQ7PdjZEvqdtxdkJSM93hDyOEQ0Nvh8PrzyyiuQJAmPPPIIRFGES/KiweZCo801WOMiAENmVS7+XNT0LSHLs5qGTRwknx8f1n0JryxACHEnNaNWg+W5qRC1XExBRHQpJjOkWH23E9UdjpCdvyzNjPyk+JCdn4jGpo6ODvzmN7/BrDlzkVo6E032nsuSl+EMHJ9jiUNpqvmKCYTf78df/vIX1DSeQu4Nq4I0+qvjzR0ioqtjMkMjEqqEhokMEY3Gx3sPolNvgRgXB4yyTN+o1WBGpnVIItHT04O33noLjY2NWLFiBVKLpqK64/woR311fE0kIro2JjM0Yu1ODw602oJSQ3OliwYiIiUGbrLIsgwhiF2/BhKK9vZ2/OEPf4Db7cbXvvY15OXlDYkbbExkiIiGx2SGRkXy+VHT6QjZcg4iokCEevlrut+FT9/+A5KTk3H33XcjKSlpyPd5c4eISB1MZigoXJIXjTYXGhQU2uZZTcgNoNCWiOhawtWYxN94BLctvR56vf6K3+fNHSKi8GMyQ0EV7BaoRETXIvn82NLYCU+oW8bLMow6bUBdxXhzh4gofJjMEBFR1DrYZkOzvSdsm1jmWOJQkWEN6Fje3CEiCj3eAiIioqjklLxh3bgSAJrsPZg8LiGgGRSNICDJKCLJKIZhZEREsYmLcomIKCo12lyjbL6snNAfl4iIIgNnZoiIKOr4ZRmNNpfi5WX2rnPY8OIvsW/7Ftg6OxAXn4CcySV49Ke/QMaE7GEfLwNosLkwJSWRS8OIiCIAkxkiIoo6do93sLg+UI7uc/jBN1aho+UUdKIemTl5kGUZJ6r2o7ujLaBkBgAkf18tDJePERGpj8kMERFFHZtbUvyYN154Dh0tpzChoAjPvPImktLSAQBSby+UNVLui89khohIfayZISKiqGNzS4rqZWRZxq5N7wEAUjLG49mH1+Le6fn429uX4YstH0DUB75BpYCRJVNERBR8TGaIiCjquH0+RXMpjq5zuGC3AQAqd2yH0+FAvNmK5hNH8cJTj2P3pvcDPpfcH5+IiNTHZIaIiKKOT2G9jM/rHfw4K78AL23djZe27kZWfgEA4KPX14U0PhERhQaTGSIiijpajbJOYubkcdCJegBAdlExRL0eol6P7KJiAEDHmdMhjU9ERKHBZIaIiKKOUatVVDOjE0UUz5oDAGiuPQavJMErSWiuPQYAyMzJDfhcQn98IiJSH7uZERFR1LEaRch2ZY+558mncXTfHrScrMVjy+YCALraW6HRanHnI08EfB65Pz4REamPMzNERBR1RpJMFJZV4NlX/4iS2fPhdNggedyYNn8Rfr5+I0rnLgh5fCIiCj5BlmVWMRIRUVTxyzI+ONmueOPMYBA1AlZNSodGYN0MEZHaODNDRERRRyMIyLWaFNXNBIMAIM9qYiJDRBQhmMwQEVFUyrOaFO01EwwygFyrKcxRiYjoapjMEBFRVDKJOuRY4sIaM8cSB5PI3jlERJGCyQwREUWt0lQzjNrwvJUZtRqUpprDEouIiALDZIaIiKKWqNVgRqY1LLFmZFohhilxIiKiwPBVmYiIolp6vAFlaaGdMSlLMyM93hDSGEREpByTGSIiinr5SfEhS2jK0szIT4oPybmJiGh0uM8MERGNGe1ODw602uD2+Ud9LmP/EjbOyBARRS4mM0RENKZIPj9qOh1osvdAABS2b5YBCMixxKE01cwaGSKiCMdkhoiIxiSX5EWjzYUGmwuSv++t7tLk5uLP/b290Dg6sXJ2OdsvExFFCb5aExHRmGQSdShJNWNKSiLsHi9sbgk2twS3zwefX4ZWI8Co1cJqFGE1iji0dzd2fv45Vs0sBd8eiYiiA1+tiYhoTNMIApKMIpKM4jWPKy8rwyfbt+PIkSOoqKgI0+iIiGg0uBiYiIgIgMViQX5+PqqqqtQeChERBYjJDBERUb/y8nKcPn0aZ8+eVXsoREQUACYzRERE/SZPngyj0cjZGSKiKMFkhoiIqJ9Op8PUqVNx6NAh+P2j36uGiIhCi8kMERHRRcrLy3H+/HnU19erPRQiIhoGkxkiIqKLjB8/HqmpqVxqRkQUBZjMEBERXUQQBJSXl+PEiRPo6elRezhERHQNTGaIiIguMW3aNMiyjJqaGrWHQkRE18BkhoiI6BIJCQkoKCjgUjMiogjHZIaIiOgKysvL0draivb2drWHQkREV8FkhoiI6AoKCgoQHx+PyspKtYdCRERXwWSGiIjoCrRaLUpLS1FTUwOfz6f2cIiI6AqYzBAREV3F9OnT4XK5UFtbq/ZQiIjoCpjMEBERXUVaWhrGjx/PRgBERBGKyQwREdE1lJeXo66uDhcuXFB7KEREdAkmM0RERNcwdepUaDQaVFdXqz0UIiK6BJMZIiKia4iLi8OUKVNQVVUFWZbVHg4REV2EyQwREdEwysvLcfbsWZw5c0btoRAR0UWYzBAREQ0jNzcXZrOZjQCIiCIMkxkiIqJhaDQalJWV4fDhw5AkSe3hEBFRPyYzREREASgvL4fH48Hx48fVHgoREfVjMkNERBSA5ORkTJw4EZWVlWoPhYiI+jGZISIiClB5eTkaGxths9nUHgoREYHJDBERUcBKSkogiiL3nCEiihBMZoiIiAKk1+tRUlLCPWeIiCIEkxkiIiIFysvLYbPZ0NzcrPZQiIhiHpMZIiIiBSZOnIjk5GTuOUNEFAGYzBARESkgCALKyspw9OhReDwetYdDRBTTmMwQEREpVFZWBkmScOTIEbWHQkQU05jMEBERKWSxWJCfn8+lZkREKmMyQ0RENALl5eU4ffo0zp07p/ZQiIhiFpMZIiKiEZg8eTKMRiMqKyvVHgoRUcxiMkNERDQCOp0OU6dOxaFDh+D3+9UeDhFRTGIyQ0RENELTp0/H+fPnUV9fr/ZQiIhiEpMZIiKiEcrMzERaWhobARARqYTJDBER0QgJgoDy8nKcOHECPT09ag+HiCjmMJkhIiIahWnTpkGWZdTU1Kg9FCKimMNkhoiIaBTi4+NRUFDApWZERCpgMkNERDRK5eXlaG1tRXt7u9pDISKKKUxmiIiIRqmgoADx8fHcc4aIKMyYzBAREY2SVqtFaWkpampq4PP51B4OEVHMYDJDREQUBNOnT4fL5UJtba3aQyEiihlMZoiIiIIgLS0N48ePZyMAIqIw0qk9ACIiorGivLwcH330ERznz8MnGmFzS7C5Jbh9Pvj8MrQaAUatFlajCKtRhMWgg0YQ1B42EVHUYjJDREQUJPmTi5Fx5iy2tdghay4AAAQA8kXHCABke9/HokZArtWEPKsJJpFvyURESgmyLMvDH0ZERERXI/n8qOl0oMneA1mWISiYbRlIdnIscShNNUPUcgU4EVGgmMwQERGNQrvTg/2tNnh8/lGfy6jVYEamFenxhiCMjIho7GMyQ0RENEL13U5UdziCft6yNDPyk+KDfl4iorGGc9lEREQjEKpEBgCqOxyo73aG5NxERGMJkxkiIiKF2p2ekCUyA6o7HGh3ekIag4go2jGZISIiUkDy+bG/1RaWWAdabZCCUItDRDRWMZkhIiJSoKbTgd4wJRju/i5pRER0ZUxmiIiIAuSUvH3tl8MYs8neA5fkDWNEIqLowR26iIiIAtRoc122CeZw7F3nsOHFX2Lf9i2wdXYgLj4BOZNL8OhPf4GMCdnDPl7oj1uSah7psClI/LIMu8cLm1uCzS3B7fPB55eh1QgwarWwGkVYjSIsBh00CvYaIqKRYzJDREQUAL8so9HmUpTIOLrP4QffWIWOllPQiXpk5uRBlmWcqNqP7o62gJIZGUCDzYUpKYm8QFaJS/KiweZCo80Fyd/3F3BpUisAkO19H4saAblWE/KsJphEXmoRhRL/DyMiIgqA3eMdvJAN1BsvPIeOllOYUFCEZ155E0lp6QAAqbcXSuZ3JH/fjECSUVQUn0ZH6q9ZarL3XJa8XPrbu/hzyS+jrsuJ2i4ncixxKE01Q9RyZT9RKDCZISIiCoDNLSk6XpZl7Nr0HgAgJWM8nn14LTpaTiFjYi7WfOdxLFq9RnF8JjPh0+70YH+rDZ7+Zg9K66QGjm+y96DtggczMq1IjzcEdYw0elw6GP0EWZbDWcdIREQUlSrb7GiyB77MzH7uLL69YNrg58npmQCArvZWAMBTL/wG81auDuhcAoAciwnTMyxKhkwjFKoNUcvSzMhPig/6eUm5gJcO9n/MpYORi3OeREREAXD7fIruzvu8X3Ugy8ovwEtbd+OlrbuRlV8AAPjo9XUBn0vuj0+hF6pEBujbCLW+2xmSc1NgJJ8fB9ts2NTQibou55Clo4EsHdzU0ImDbdz/KZIwmSEiIgqAT2G9jDl5HHSiHgCQXVQMUa+HqNcju6gYANBx5nRI45Ny7U5PyBKZAdUdDrQ7PSGNQVfW7vRgS2Mnmuw9AEa3dHBrYyd/jxGCyQwREVEAtBpl6+V1oojiWXMAAM21x+CVJHglCc21xwAAmTm5IY1Pykg+P/a32sIS60Ar7+yHW323EztbugZroEbL7fNjZ0sXZ9oiABf9ERERBcCo1SreY+aeJ5/G0X170HKyFo8tmwugr2ZGo9XizkeeCPg8Qn98Cp2aTgd6w5RguPu7pFVkWMMSL9aFeukgANZCqYgzM0RERAGwGkXFy1IKyyrw7Kt/RMns+XA6bJA8bkybvwg/X78RpXMXBHweuT8+hYZT8qLJ3qP49zsaTfYeuCTv8AfSqHDp4NjHbmZEREQB6HZL2N58VrX4S7JT2Jo5RA53OlDX5QxrMiMAKEyOR0mqOYxRY4vk82NLY2fQlpZdi1GrwfLcVO4npAI+40RERAGwGHQQVapbETUCLAauDA8Fvyyj0RZ4y20AOLLvC/zskfvxrXlTcdfk8bhr8nhsfvN3iuLKABpsLvh5Tzlk1Fg6SOHHZIaIiCgAGqFvn4lwpzMCgDyriRv2hYjd4x3SnjcQjUdrcGjXZ0iwWEcVW/L3bdhIwcelg7GDyQwREVGA8qymsF4cAX0zB3qnLcxRY4fNLSl+zOLb7sJr+0/gn//nDVXi0/Aaba6AbzwEY6YN6Lvx0GhzKX4cjQ6TGSIiogCZRB1yLHFhjCjD03oK619dh7feegs2my2MsWODzS0pnm1LTEqGwTj6vwMBTGZCQenSwWDNtHHpoDqYzBARESlQmmqGMUxFvkatFl9bNAu33347mpub8atf/Qrbtm2Dx8POScHi9vnCPts2QO6PT8GldOlgMGfauHQw/FhNSEREpICo1WBGphU7W7pCHmtGphV6nRbl5eUoLi7Gzp07sWvXLlRWVmLp0qUoLy+HRsP7kqPhU1gvM9bij0VKZ7sSk5KDHp+dB8OHr4BEREQKpccbUJYW2pa6ZWlmpMcbBj/X6/VYsmQJvv/97yMvLw/vvfcefvOb36CxsTGk4xjrtCp1qIuU+GPRSJYOBguXDoYfkxkiIqIRyE+KH0xoZDm47V/L0sxX3VHcYrHgzjvvxMMPPwxRFPG73/0Ob775Js6dOxfUMcQKo1ar6oWvUatVKfrYxaWDsYXJDBER0QjlJ8XDYvsSXncPEITLJ6NWgwVZyVdNZC6WlZWFb3/727jrrrvQ2tqKl156CZs3b4bb7R71OGKJ1Sgq/s19seVDPL5iPn70wF2DX3vzP36Bx1fMxwtPPR7weeT++BRcai/dUzt+rGHNDBER0QidO3cOu7d+hNlz5yFl6gw02XsgQFlaM3B8jiUOpalmRTuIC4KAqVOnoqioCLt378bnn3+O6upqLFmyBDNmzGA9TQBGkky4LpxH26mmIV9zdJ2Do+scxqVnhjw+XZvaS/fUjh9rBFlm/zgiIiKlZFnGq6++CofDgcceewyiKMIledFoc6HB5hrspnRpcnPx56JGQJ7VhFyrCSZx9PcXz58/j48//hhVVVVITU3FihUrMGnSpFGfdyzzyzI+ONmueOPMYBA1AlZNSueGqEFW2WZHkz3w1sxfbPkQrz3/M/i8XnR+2QIAMCePgykhEQXTpuOvn38x4NgCgByLCdMzLMoHTiPCmRkiIqIROHDgAJqbm/HAAw9AFPvurptEHUpSzZiSkgi7xwubW4LNLcHt88Hnl6HVCDBqtbAaRViNIiwGXVAvZBMTE3H77bdj9uzZ2Lx5M15//XVMmjQJK1asQGpqatDijCUaQUCu1YS6LmdY6ywE9G3CykQm+KxGEbI98OODOdPGpYPhx5kZIiIihRwOB1588UWUlJTgtttuU3s4VyTLMo4fP46tW7fCZrNh5syZuOGGG2AymdQeWsRxSV5saugMe9yVealBmZGjobrdErY3n1Ut/pLsFLZmDiP+H0RERKSALMv44IMPoNfrsWLFCrWHc1WCIGDKlCkoKCjA3r178dlnn6GmpgbXX389Zs+eDS27aA0yiTrkWOLQZO8JW8wcSxwTmRCxGHQQNYJqSwctBv5ew4mVgURERAocOXIEtbW1WLVqFYxGo9rDGZZOp8P8+fPxV3/1VygpKcHWrVvx0ksv4fjx4+DijK+UppphVNB8YTSMWg1KU0O7T1Es0wgCskwiEOa/by4dVAeXmREREQXI5XLhxRdfRE5ODr7+9a+rPZwR6ejowObNm9HQ0IDc3FysWLECGRkZag8rIrQ7PdjZ0hXyOAuykodsiDoW+WVZlboxt9uNnTt34kDNYeSv/DqEMCcWXDoYfkxmiIiIAvT222+jtrYWjz/+OBISEtQezojJsoy6ujps2bIF586dw/Tp07F06dKo/pmCpb7bieoOR8jOf60NUccCl+RFg82FRgUd/XKtJuSNsqOfJEnYt28fPv/8c0iShLlz58JcVI7Tzt4Rn1OpHEscKjKsYYtHfZjMEBERBeDkyZN4/fXXcfvtt6O8vFzt4QSFz+fD/v378cknn8Dv92PRokWYO3cudLrYvrMcqoRmLCcyks+Pmk5H2Pda8vv9qKqqwqefforz58+joqICixcvRmJiIiSfH1sbO+H2+RX+NMoZtRosz01VNHYKDiYzREREw/B4PPj1r3+NcePG4f777w/70pVQ6+npwaeffop9+/bBbDZj2bJlKC4uHnM/pxLtTg8OtNqCciFs1GowI9M6ZpeWtTs92N9qgyeMz9VAt76PP/4YZ8+eRUlJCZYsWYJx48ZdNjYuHRzbmMwQEREN46OPPkJlZSUee+wxJCUlqT2ckDl79iy2bt2K2tpaTJw4ETfddBPGjx8f9Dhq1VMopdZsQzRRYxarsbER27Ztw5kzZ5Cfn4+lS5de8++USwfHNiYzRERE13D69Gn89re/xU033YS5c+eqPZywaGhowObNm9HR0YGysjIsXboUZvPou2+pVU8xWi7Ji0abCw0BjlsLGZOSE5Cr8rhDLdxJQmtrK7Zt24b6+nqMHz8ey5YtQ25ubkDn4tLBsYvJDBER0VV4vV68/PLLMBgM+Pa3vw2NZmzeXb8Sv9+PgwcPYvv27ZAkCfPnz8eCBQsgiso3AxwrMxzDzShZDDp88NYfUJidhZsieA+iYAjn8i3R48T27dtx+PBhjBs3DkuXLsWUKVMUL4Pk0sGxickMERHRVWzfvh2ff/45vvvd7yItLU3t4ajC7XZjx44d2LNnD0wmE5YtW4bS0tKALyTVqKdQ0zvvvIO2tjY8+uijag8lZCSfH1saO4PyOx2WtxfH3n0DcQY9brjhBpSXl4/qpsJYSazpK0xmiIiIrqC9vR2/+c1vsGjRItxwww1qD0d13d3d2Lp1K44dO4bx48dj5cqVmDBhwjUfE4tLe2pqavDnt9/G/3n8CfRq9RFdEzRSB9tsaLb3KEoERkr2+xHXewHLi/NGNCt4NUqXDooaAXlW05hfOhiNmMwQERFdwu/345VXXoEkSXjkkUdivlXxxZqbm7F582a0traipKQEy5Ytg9Vqvey4WCy6dklenOi0o+6sAzqDEUB01AQp4ZS82NzQGfa4odqMMlqaUdDVMZkhIiK6xO7du7FlyxY8/PDDyMrKUns4EUeWZVRXV2Pbtm3o6enBvHnzsHDhQhgMfcu/Yq0dbiwtXTrc6UBdl1PRz2jvOocNL/4S+7Zvga2zA3HxCciZXIJHf/oLZEzIHvbxAoDC5HiUpI6+CQWNPdFxG4CIiChMurq68PHHH2POnDlMZK5CEASUl5ejuLgYO3fuxK5du1BZWYmlS5eipHQa9rfawjKOA6021TcqvLQmSOkd4oHjm+w9aLvgieiaIL8so9HmUvQzOrrP4QffWIWOllPQiXpk5uRBlmWcqNqP7o62gJIZGUCDzYUpKYmcHaHLMJkhIiLqJ8sy3n//fcTHx2Pp0qVqDyfi6fV6LFmyBBUVFdi2bRvee+89HLN7EDc+G33300PL3T8jUpFhDXmsKwn2Ujq3z4+dLV0RuYQOAOwe72B9SaDeeOE5dLScwoSCIjzzyptISksHAEi9vVCS+kn+vuVgScbg1c3Q2BDZc5lERERhVFVVhcbGRtx6663Q6/VqDydqWCwW3Hnnnbj/Ww/DmBmeRGZAk70HLskbtngDQlkTVN3hQH23MyTnHg2bW1J0vCzL2LXpPQBASsZ4PPvwWtw7PR9/e/syfLHlA4h6ZTNQSuNTbGAyQ0REBOD8+fPYvHkzysrKkJ+fr/ZwolJPnDnsy4AEAI02V1hjtjs9IW1uAPQlNO1OT0hjKGVzS4rSVEfXOVyw2wAAlTu2w+lwIN5sRfOJo3jhqcexe9P7AZ9LAJMZujImM0RERAA++ugj6HQ63HTTTWoPJSqNpJ4C6CsO/5+f/iO+u3QW7i7NxkNzS/Djh76BttPNAT1+oJ7CH6Z+RpLPH9aaICkce7kEyO3zKfr9+rxfzZhl5Rfgpa278dLW3cjKLwAAfPT6uoDPJffHJ7oUkxkiIop5R48exbFjx3DzzTcjLi5O7eFEpZHUUwwUh3/0+jrYOjuRmZMHS0rqYHF4oAbqKcKhptOB3jAlGAM1QZHA7/fD06tsZsScPA46sW+5ZnZRMUS9HqJej+yiYgBAx5nTis7nU/j3RbGBDQCIiCim9fT04KOPPkJRURGKi4vVHk7UGskSoGAVhw/ED3VxuFPyosneE9IYl2qy92DyuISQ70MjyzJ6enrQ3d09+M9msw3+1263Y8L8ZUi8LhtCgEsJdaKI4llzcGjXDjTXHoNX6vsbaa49BgDIzMlVNEathp3M6HJMZoiIKKZt2bIFkiThlltuCfgijS43UE8RaApypeLwjpZTyJiYizXfeRyLVq8JOHa46ikabS7F+8gEY4+VRpsrKHusSJI0mKBcmqx0d3ejt7d38Fij0YikpCQkJSUhMzMTSUlJcJrT0CULin7+e558Gkf37UHLyVo8tmwuAKCrvRUarRZ3PvJEwOcRABi1WgWRKVYwmSEiopjV0NCAqqoqrF69GmYzN+QbDaX1FJcWhyenZw4pDtfpRMxbuTqgc4WjniIa9ljx+/04f/78VWdXLly4MHisVquF1WpFUlISJkyYgGnTpiEpKWnwa0aj8bLzN9pcONduV/AMAIVlFXj21T9i/QvP4WRNJfQGI6bNX4R7nnwahWUVAZ9HBmBlW2a6AiYzREQUk3p7e/Hee+8hJycHFRWBX1TRlSmtZ7i0OPz5t7cCAJ5asxwt9XX46PV1ASczI4mvVCTssWI16OB2u6+arNhsNvj9X9XzJCYmIikpCePGjUN+fv6QZCUxMVHxTORIk4nJFbPxk9+9NaLHBiM+jW1MZoiIKCZt374dFy5cwDe/+U0uLwsCpfUMA8XhXql3sDgc6CsUb6mvU1wcHup6imDssTLSZXSyLOPdLX9B69FqeDxftWs2GAyDS8GKiooGP7ZarbBardDpgnuZZzHoIGoExUldMIgaARYDL1vpcvyrICKiqOaX++5a29wSbG4Jbp8PPr8MrUaAUauF1SjCahRhMegGl+mcOXMGe/bswY033ojk5GSVf4KxwajVKqonCWZxeDjqKZTWBAVzGR1kGZaM6zBpnHnI7Eq4O+9pBAG5VhPqupyKW3CPhgAgz2oK+x5GFB2YzBARUVRySV402FxotLkG7xRferEpAJD7l/iLmr4LsexEI959911kZGRg3rx54R72mGU1ioPPdaCCVRwejnqK0e6xMppldIJGg/TrsjDvOvUT7zyrCbVdzrDGlAHkWk1hjUnRg/vMEBFRVJF8fhxss2FTQyfqupxDlrxcerF58eeSX0ZdlxNbm85CzC7CLbfeCo2Gb4PBMpJkYqA4vGT2fDgdNkgeN6bNX4Sfr9+I0rkLQh5fCaU1OWN1jxWTqEOOJbwzQjmWuJC3pqboxb8MIiKKGu1OD/a32uDp37RQ6eWdDACCgOS8yTjk1EB0epAebwj2MGPSSOspglEcroUMsz60y8yU1uSM5T1WSlPNaLvggTsMm4catRqUBqEtNY1dgizLkZHqExERXUN9txPVHcHfDb0szYz8pPignzcWHe50hL2eQpb96DxaDfepWpSVlaG8vBxJSUlBj1PZZkeTXVlr5trqg/jn+++EV+pFcnomgK+W0f3olTcDnn0SAORYTJieYVE+8BBpd3qws6Ur5HEWZCXzhgNdE5MZIiKKeKFKZAYwoQkOl+TFpobOsMedZvTiaHUljhw5gt7eXuTk5KC8vBxTpkyBvr9L2mg12lyoVLjHCgAcP7h3yB4rucVTFe+xAgDT0y0RVzfC/y8pEjCZISKiiMY7wNHlYJsNTfaesMXLscShIsMKoG/voGPHjqGqqgpNTU3Q6/UoKSlBeXk5JkyYMKoW3N1uCdubzwZp1MotyU5BUgTus8IZU1IbkxkiIopYks+PLY2dgzUyoWTUarA8NxWilk0BRkPy+bG1sTNs9RRX+511d3ejqqoK1dXVsNvtGDduHMrLy1FWVobExETFsfyyjA9Otqu2x8qqSekR25q43enBgVbbqH/nst8PnSBj7oRU3liggDGZISKiiHWwzYZme0/YajAuvstPIxdJs2myLKOxsRFVVVU4duwYfD4f8vPzMX36dBQWFga0saTP50NNTQ2q27qRkF0IIYxd8AQAhcnxKInwInjJ50dNpwNN9h5F+/EAX7VUl7va0LD7E3zvu48gPp6zMhQYJjNERBSRnJIXm1Wov1iZl8o2sEEQifUUbrcbhw8fRlVVFc6cOYO4uDiUlpaivLwcmZmZlx3v9XpRWVmJnTt3wm63o2jqNOinzkHf5Xf4RNPfpEvyotHmQsNw+z/1fyxqBORZTci1muD3uPHiiy+isLAQa9asGXLekWyOS7GByQwREUWkkXTGsnedw4YXf4l927fA1tmBuPgE5EwuwaM//QUyJmQP+/houQseLSK5nqKzs3NwGZrT6UR6ejqmT5+O0tJS6HQ6HDhwALt27YLT6URJSQkWLlyI9PR0VWuCoslIk4/Kykq8++67uO+++zBp0qTAN8ft/3hgc9w8qylqEkAaHSYzREQUcUZSn+DoPoenv74KHS2noBP1yMzJhSzL6Gg5hR+98gamzJgT0HkivT4h2gSrngLoq5GZkWkNaj2Fz+fDyZMnUVVVhdraWsiyDEEQIMsypk2bhkWLFmHcuHGDx0dKTdBYJcsyXnvtNXQ7zmP+mntw+oJnxMvWcixxKE01x9TzF4uYshIRUcSxe7yKC63feOE5dLScwoSCIjzzyptISksHAEi9vVByKST5++4oR2LnqGiUHm/A8tzUUddThOrCVKvVIisrCy0tLWhoaIAkSTAYDOjp6UF9fT0SEhJQXl6OlJQUAIDYn1CFoyZoRqZ18OeNlWVWgiBg/opbcKDNjtPn3YAgjGxzXABN9h60XfAEPQGmyMKZGSIiijhK9/SQZRkPzS3BBbsN0xctwdm2L9HRcgoZE3Ox5juPY9HqNcOf5CKRuKfHWHBpPYUsy9BccrF6tXqKUCwZcjgc2LVrFw4ePAgAmDVrFubNm4f4+Hi0traiqqoKNTU1cLvdyMrKwvTp01FSUgKDwRC2mqBYW2Y1+LzKMhDEpIytnscuJjNERBRxlO62bj93Ft9eMG3w84t3WweAp174DeatXB3QuSJxt/Wxxi/L+OjjT9HucGL6vIVhn2Xo7u7Gzp07UVVVBVEUMXv2bMyZMwcm0+UJrNfrxYkTJ1BZWYn6+nrodDoUFxejvLwcfmsqqjvOB318ZWlmTDTHRexsVqhEYtMIinzRl7ITEdGY5/b5FF28+bzewY+z8gvw/NtbAQBPrVmOlvo6fPT6uoCTGbk/PoWORhDQ9eVpJBgMYU0aOzs78fnnn6OmpgZxcXG44YYbMGvWLBgMV1+CpNPpUFJSgpKSEjgcDlRXV6OqqgqHDh2C1WpF8ez58KRkoTcIJTQDNUEAhuyvFAvLrNqdnpAmMgBQ3eFAgl4X8c8FKcNkhoiIIo5PYb2MOXkcdKIeXqkX2UXFEPV6AEB2UTFa6uvQceZ0SOPTlV2rzsOfno1EcwK63VLI6zxaW1vx+eef4+jRo0hMTMRNN92EiooKiKKyuiiz2YxFixZh4cKFOH36NCorK7Fv+1b4ABQuWg4x9TrFS6MunUU55egJ6kW92+fHzpauiJ6VkHx+7G+1hSXWgVZbzDVVGOuYzBARUcTRapRdEOpEEcWz5uDQrh1orj0GryQBAJprjwEAMnNyQxqfhgqkziN+Qh56BA22N58NWZ3H6dOnsWPHDtTV1SEpKQmrV69GWVlZQBtlXosgCJg4cSImTpyIm2++GUePHkVVVRXqv/gMqUVTMW5SMaDtixHoHismURfSZVYD543EhKam04HeMHSHA/qSu5pOR1S2u6YrY80MERFFHKU1MwBQW30Q/3z/nfBKvUNqZjRaLX70ypsonbsgoPOwZmbkgrEL/GjrPGRZRmNjI3bs2IGmpiakpKRg0aJFmDp1KjSa0N6N7+rq6tu75tAh9Gp0SJ2Qi8zcSUhISoag0VyzJqjd6QlLh7QFWckRtcyKm+PSaDGZISKiiKO0m9mA4wf3Yv0Lz+FkTSX0BiNyi6finiefRmFZhaLzsJuZcu1OD/a32gbrPEZjJPvJyLKMuro67NixAy0tLcjMzMSiRYswefJkCGFuVez3+9HY2IiqqiocO3YMfr8fBQUFKC8vR2FhIbRa7ZDjJZ9/SI1MKEXa3jXcHJdGi8kMERFFnG63hO3NZ1WLvyQ7hfvMKBCq5VGB1Hn4/X4cO3YMO3bsQHt7OyZMmIBFixZh0qRJYU9irqSnpweHDx9GVVUVvvzyS5hMJpSWlmL69OlIT+/bC+lgmw3N9h7Fhf4jlWOJi4hlVtwcl4KB82tERBRxLAYdRI2geOPMYBA1AiwGvj0GSq06D5/Ph5qaGnz++ec4d+4c8vLy8OCDDyI7OzsikpgBcXFxmDVrFmbNmoWOjg5UVlbi0KFD2LNnDzIzMzF1+gy0mceHdUxN9h5MHpeg+jKrWN4cN1Y2QQ0HzswQEVFEGsnyk9Hi8hNl1Kjz8Hq9qKqqws6dO2Gz2VBUVIRFixbhuuuuC/k4gsXn86Gurg5VVVWwG8xImVwGQUE9z1hZZhWLm+PG2iao4cBkhoiIIpJL8mITC4MjVrjrPBZnWXCoshK7du3ChQsXUFJSgkWLFg0u1YpGflnG+3Vt8Cq4EhtLy6xiaXPcSGiOMVbx1ZqIiCKSSdQhxxKHJntP2GLmWOKYyAQorO10vT788dO9aNn7KaZNm4aFCxdi3LhxYYkdSnaPV1EiA4yNZVayLEOSJFzw9MbE5riXNseIhU1Qw4mv2EREFLFKU81ou+CBO0x3/0u5vCwgTskb1iQTggBL9iSsnDkVmeOSwxc3xGxuSdHxsixj16b3AAApGePx7MNrR7XMyuaWrprM+Hw+9Pb2QpKkq/430K9d+j1vf1KSs/hmJGZOCHi80bg5brBryqJhE9RwYzJDREQRS+xv0RuOuowZmVYu3whQo82leKnMqOs8BAFdfh0yRzzqyGNzS4qeR0fXOVyw2wAAlTu2Izk9E/FmK5pPHMULTz0OnU4MfGbC78femiPYXldzxUTE7x/+BoIgCNDr9RBFcfC/F39sNpsv+9rF/20VzTgPGX0LqYYXbZvjxuomqOHGZIaIiCJaerwBZWnmkF0UAH0tgLlsIzB+WUajTdmGpo7uc/jBNy6u88iDLMs4UbUf3R1tASUzMoAGmwtTUhLHTHcnt8+n2jIrCAJ0hjgkJydfNdm4ViIiiiK0Wu2oOsdJbXZcULg57j1PPo2j+/ag5WQtHls2F8BXm+Pe+cgTAZ9HAGC8ZL+fYGp3ekL6mgX0JTQJel3Mv3YxmSEioog3cPdRrb1M6Cux3E432JQucwrmMitBEJCWmYmFs6cqGkMwWY0iZIV74xaWVeDZV/84ZHPcafMXKd4c1y/LOLx/D84aBEycOBETJ05EXFycwp/gyiSfH/tbbUE513AOtNoiahNUNTCZISKiqJCfFI8EvQ57W86h1y8ramV7JSPZZZ4iu84j2ihd5hRty6yGYx3h73FyxWz85HdvjSq2IAiIgw81Ncewa9cuAEBaWtpgYjNx4kRYLCPrdBbW5hj9XdIiYRNUtTCZISKiqJFm0qPzi79AP6EAceOz+1baK1jmwhano6dmnYcA5clUJDNqtYprj6JlmVUg1N4cd9WqlRBWrYTNZsOpU6fQ3NyMxsZG7N+/v298Fguys7MHk5uUlJRhl9WFvTkGImcTVLXE5k9NRERRqa6uDqebGlFmMeNE9R6sXPsATl3oDXjzuTyrCbncfG5U1KzzCGc73XBQc5mVjJHPjASLRujbEFKNzXHzrKbB2qukpCQkJSWhrKwMAOB0OnHq1KnBfzU1NZBlGXFxcUNmbjIzM6G9JCEcSXOMYPw8jTaX6pugqoWv5kREFBVkWcbHH3+MiRMnorGxEZPz8lCWmYxSua+OwuaWYHNLcPt88PllaDUCjFotrEYRVqMIi0E3ZgrH1aRmncdI4kcyNZdZjSZ+MOVZTajtcoY1pgwg12q66vfj4+MxZcoUTJkyBQDg8XjQ0tIymNxs374dXq8XoigiKytrMLkZf911ippjHNn3Bd7+71+hvqYKju6+jo2P/PhfcdPaBxT/PGOtOYYSTGaIiCgqHDlyBO3t7bjxxhuxbds2zJo1C0Df3d0kozhm6igiXazXeQST2susLAb1LwOjYXNcg8GA/Px85OfnA+jbg6e1tXUwudm7dy8+/fRTxCWnYtKKwGvAGo/W4NCuz5CeNXEwmRmpsdYcQwn1/4qJiIiG4fP5sH37dhQUFKC5uRnjx4/H+PHj1R5WTIr1Oo9gipRlVmqLts1xtVotsrKykJWVhfnz50OWZXR2duJo61l0yXLAdXyLb7sLy+++H/azZ/HYsjmjGhMwtppjKMHKRyIiCju/LKPbLaHR5kJlmx27z3Th89PnsPtMFyrb7Gi0udDtluCX+y7xqqqq0NXVhRkzZuDkyZOYOXOmyj9B7LIaRcUX3gN1HiWz58PpsEHyuDFt/iL8fP1GlM5dEPB5IqHOI9jyrKawJjLA8Muswm1gc9xwCMXmuIIgIC0tDZb06xTtu5OYlAyDMTjtoMdacwwlODNDRERh45K8aLC50GhzXbtov78oWtQIyDYb8fnefZg6dSpOnToFo9GIqVPV2xsj1rHOI7iiYZlVOIyFzXGVNscIprHWHEOJyPpLJiKiMUnq3wuhyd5zWfJy6Zv/xZ9Lfhknu13IWnIbMgwCdr39JsrLyyGKY+uCNpqwziP4om2ZVahE++a4ajenUDu+WrjMjIiIQqrd6cGWxs7BO8+K324FAYIgoN0jY+LSW5E3LfD2sxR8A3Ue4a62iLQ6j2CK9mVWwZSfFI8FWckwBmmMRq0GC7KSQ57IAOo3p1A7vloi96+ZiIiiXn23EztbuuAJxh1nQYDOaEKNw4v67vC2cqWhxPPnBuuZwiXS6jyCbWCZVSiFeplVsKTHG/5/e/caHNV95nn8d/oitS5ILYEQCN25mEuwQGDjDOskGPBQOHhsk4nHidn1xHY23lRt8sK1nppKNpuMX+zGnilXKp6aDOPMZKgk3nhqZxKXsQ1OsHHZQVg2Bpk4XCW15aALSC0hNWr6cvaFLuYW6CP16e6j8/1UuQpR4jzNsZDOr//P//lrc0OF6kvH9pNYfUSf+Pz60gJtbqjI2N95YjhGNsy04RhWGKaZ4e9GAABXODUwYnv/eybebcUnhoaGtGfPHh09elRLPrdF+fNqM1a7vrRAzfOCGauXLen+d2OapgzDUGOBoVW189J23UyJxOJqD0d0+kb77MZ/nc3DcdvDER3qSf0U1AN7dmvX008qEY+r7w9dksbOZSosnqXFN6/WN59+1lL91ZWlMzrw/zEzr/EUAJB1PSNRW4OMNNZXX5znc8Q7zU6XSCTU0tKiN954Q36/X/fcc4+WrfiUXus46/p9Hum2sKxIxXk+vXsmnJZ7G/B51PPuW3qju0uLH3lERUXOegOg0O/TiooSLZszK+cPx7U6nCIyfF7doY7Lfm+o/5yG+s9pduV82+vPFKzMAADSKpZIak97X3pay24g4PVoc0NFTu8BcLr29na9/PLLOnv2rG655RZt2LBBgUBA0lhofatreof9pWJ9dbnrQuv1hmbcyMTn15cWaGVFiUbOD2nnzp2qqKjQjh075HVpO5Ldkqapl072ZG04xl2LKmfknrIbIcwAANLqve6wOgcvZGxEqVvajzLt/Pnz2rNnjz744APV1NRo69atmjfv6jYl2gntla42q1AopJ/85CdqamrStm3bLJ2HgtR90DeUlUNQl5QXaYVLVi+vRJgBAKTNSCyuV0/3ZbzulsaKnDs3w6kSiYQOHjyo119/XT6fT5s3b1ZTU9N1H37tCjRuDzKXSprmtNus3n//ff3yl7/Uli1btG7d9E+cx9Uisbhe4XtgRrnzbw0AsEV7OGK5JWaw/5xeePbv9M6+PQr39aqgqFj1S1foa3/zlObV1N3wzxvjdd36rmQ6dXR0aPfu3Tp79qzWrl2rDRs2qKDgxieUp32fx/ioYre1ll2PxzBUFvCrbBr7IlatWqXe3l69+uqrmjNnjhYuXJjGVwiJQ1Czwb1/cwBAWiVNU+3hiKUgMzRwTn/1xbvU2xWSz5+n+fWNMk1Tx95v1UBvd0phxpR0OhzRsjmzXNkvng7nz5/X3r171dbWpurqaj366KOaP9/aBuSJcbrp2ufBPih7bNq0SX19fXrhhRf0yCOPaM6cOdf8vHSsBLkVh6BmFm1mAIC0GBiNaV/nWUt/5kffeUJ7/u8u1Sy+Sd957nmVza2UJMUuXpRkyp+X+jvzG+rmTOtdazdKJpNqaWmZbCnbtGmTVq1aNe39FE4ap+tGo6Ojeu6552Saph5++OHLVt8isbhOhyNqt/D/riFYqEb+312G4RiZQ5gBAKSF1TMWTNPUQ7et0PBgWKtv36Cz3X9Qb1dI82obdO+jX9ftn7/XUn23nrEwVZ2dndq9e7d6e3u1du1a3XHHHSm1lFnBu/u5q7+/Xzt37lRVVZW+/OUvK2GKVbU0YzhGZhBmAABpcah7UB2DqbeZDZ47q6+sv3ny4/LxcxX6e85Ikh5/5h/16S2fT+lahqT60kKtnldq5SW70vDwsPbu3asjR45owYIF2rp1q6qqqrL9spAF7e3t2rVrl5o/c4eM6sVpGafOfqfLMRzDfqwHAgDSYjSRsPRubiIen/x19cLFevrf90qSHr93s7pOndDLP/3nlMOMOV7fSTK9apFMJienlHk8Hm3btk2rV69mRK+LNTQ06D/d/QWFC8qkeEJKw9fCaCKpt7r6edgex3AM+xFmAABpkbB4UFxJ+Wz5/HmKxy6q7qbl8uflSZLqblqurlMn1PvxR7bWz5aU9ySMd+ylY09CKBTSSy+9pN7eXq1Zs0YbN25Me0sZnOfUwMhYkJHSEmQuNbEaQaBhOIbdCDMAgLTweqw9DPn8fi2/ZZ2OvP2mOo9/qHgsJknqPP6hJGl+fYOt9TPteie6X/lgc+nHsaSpE/0jOt4/YvlhZnh4WK+99poOHz6sqqoqPfroo7SUQdLYBnU793NIY4GmOM/HKoIkv9ej5nlBLZ1dzHCMNGPPDAAgLazumZGk44ff07cfvE/x2MXL9sx4vF79z+ee18rb1qd0nVzfM9MzElXrmXDG9iQkk0m988472rdvnzwejzZu3Kjm5mZayiBpLFjvae9Ly9fjjQS8Hm1uqGA14QoMx0gfwgwAIC2sTjOb8Pv3Dupnz3xfJ9sOKS8/oIbln9ID33hCS5qaU76GaZq62PF7LSj0qa6uTlVVVfL7c2NMc6Y3AIdCIe3evVs9PT1qbm7Wxo0bVVjIlDd84r3usDoHL1h642E66ksL1DwvmKFqcBvCDAAgLaZyzkw6jf7uoELHPlQ0GpXX61VVVZVqa2sn/wsEAhl/TZkczToyMqK9e/dOtpRt3bpVCxYssK02nGkkFterp/syXndLYwVtUrAFYQYAHCgXWxQSyaRePNGtpDLfEuH3GLprUaVkmurt7VVnZ6dCoZBCoZCGh4clSZWVlaqpqVFdXZ1qa2tVUmLvqdmZOjTvT6qCCn3Ypt/85jeTLWWrV6+Wx0NbD672Qd+QTvSPZGxVRhprA11SXqQVLj+pHvYgzACAg+Ti6dzxeFxHjx7VwdZ3FVy3SR6fL6N7M673oGSapgYGBhQKhSYDTn//WMAIBoOTwaa2tlazZ89O2+vO3J4EU4loVL9/8edadfNKWspwXUnT1Esneya/d6Ti6DsH9O87f6hTbe9raGDs385X/9f/1p/+xX+2VHviDQf2fyDdWO8DAAfIxiSsGxkZGVFra6taW1s1PDysZRvvktfvkzK8MmNKaghe+wHeMAyVl5ervLxcq1atkjQ24Wti1SYUCunIkSMyTVNFRUWqra2dXL2ZN2/elFc32vqGdDEDm6slQ568fH3u/v+i2xfRUobrG4zGLQUZSWr/XZuOvL1fldW1k2FmKmLJsdXkskBu7GXDzEGYAYAcd+UkLKvL6ROf3zF4Qd3D0WkfuNbd3a2Wlha1tbXJMAw1NTWpae2temcwO4dW1pcWWFp1Ki4u1vLly7V8+XJJUjQa1UcffTQZbn79618rkUgoLy9P1dXVqq2tVV1dnRYsWJDSUIGRWFwdgxem/PexyjAM9SUMRWJx9iTgusKjMct/5rN3b9fm+x/U4NmzemzTumnXJ8wg3fiuBwA5LN0byKd6OncymdTx48fV0tKijo4OlZSUaMOGDWpublZBQYE+6BuSodT78EcjEf3i2b9Vy2uvqL/njHw+v+ZUVeuzf7Zdf/aVx1Ju9/IahlZOsw8/Pz9fixYt0qJFiySNtc2dOXNmsi3twIEDev311+XxeK4aKnCtgyfbwxHLh+JNlzFelz0JuJ7waMzy1+assvK01DY0tTAF3AhhBgBylJ2TsFI9nTsajerQoUM6ePCgBgYGVFNToy984QtaunSpvF6vpLE+/PawtfNldn7vr/X6f/xCklSz+CZFzg8pdPxD7XrqSeXl5WvrjodTvJKZ9sMyfT6fampqVFNTM1bhiqECbW1tevvttyVJc+fOvSzczCopsXwvJGmw/5xeePbv9M6+PQr39aqgqFj1S1foa3/zlObV1N3wz5uSTocjWjZnFnsS8EeNJhIZDdmXMsfrA+lGmAGAHJTt07n7+/t18OBBHTp0SPF4XCtWrND27duvOep3Kn34v3/voCRp9e0b9K2dP1V09IIeWrdCF6Oj6vtDV8rXSZiyvQ/fMAxVVlaqsrJSt956q0zTVDgcnhwq0N7ertbWVknSnJp6zV9/p6XrDw2c01998S71doXk8+dpfn2jTNPUsfdbNdDbnVKYkdiTgBtLWPx3OtPqY2YizABAjoklkmo9E85IrXfPhCdP5zZNUx0dHWppadGxY8dUUFCgdevWae3atdcdYzyV1pFla25Vd6hDh97cp29u26DI+SFdjI5q2dp1uvsvv2bpWpnuwzcMQ2VlZSorK1NTU5OksWEIoVBIp/rPK2qalqai/fyZ76u3K6SaxTfpO889r7K5lZKk2MWLstqsxp4EXE+6VzGdVh8zE2EGAHJM5iZhje2hOdwTlrenUy0tLerp6VFFRYW2bdumlStXprThfSp9+P/1u/9HZtLU6798QR+dOCZJ8vnzVLdkmYpKS1O+Tq704RcVFWnZsmUa7R5Ux2DqbWamaertV16UJM2ZV6XvPvwX6u0KaV5tg+599Ou6/fP3pvwacuVeIHcFvN6M7+eaYIzXB9KNMAMAOSTTk7AkqXNoVMde+40aqqt05513qqGhwdLKwlT68F/8l3/UG7/6Ny1tvkX/44c/1lD/OX37wXv1ys/+RV6fT1/56++ldJ1c68O3ei+G+s9peDAsSTr05j6VV85XUUlQncd+p2ce/7p8Pr8+veXzKV0r1+4Fck8w4Jc5aO3PHNizW7ueflKJeHzy957/wVP61Y//QYtvXq1vPv1sStcxx+sD6cbxwACQQyYmYWWSIenO+x/UAw88oMbGRssHR1rtg49eiOj5Hzwl0zR12513qbR8tmoWLdHS5lskSUd++6at9e1k9bVc+oBYvXCx/n7vb/X3e3+r6oWLJUkv//Sfba0Pd5lKmIgMn1d3qOOyvWxD/efUHepQf0+37fWBG2FlBgByhNWpYOk6mVuGoTNRU0nTnNIkLKt98NHRC5MP8aePHpEkXYyO6qOTxyVJgQJrJ9jnUh++1ddSUj5bPn+e4rGLqrtpufx5eZKkupuWq+vUCfV+/JGt9eEupfk++T2GpYEdd9x3v+647/5p1/Z7DJXm89iJ9GNlBgByhNWpYBMncxeXBqdde2IS1lRM9OGnqqRstpavvU2StP/F/6ev/+l6PbZxnbpDHZKkz93z5ylfK9f68K3eC5/fr+W3jB1E2Hn8Q8VjMcVjMXUe/1CSNL++IeVr5dq9QO7xGIYagoVZWf1tDBYyNhy2IMwAQI6wunn7s3dv167WY/r2P/08K/UnBAN+y3tmnnj2x7rnkf+mqvpGDfR2Kx6LaXFTs77x1A+15UsPpXydXOvDn8q9eOAbT8jnz1PXyeN6bNNtemzTbeo6eVwer1f3ffW/p3ydXLsXyE2NwcKMDwAwJTUEra24AqlivQ8AcoTVqWDpOplbmt4krKk8QBeXBrXj8W9px+PfmlLN6da3y1Rey5KmZn33J7/Qz575vk62HVJefkA3/8nteuAbT2hJU7Pt9eEuhX6f6ksLMjpopL60QIV+HjlhD76yACBHOPV07qn04adLrvXhT/VeLG2+Vd/713+bVu1cuxfIXSsrStQ9HNVoBkbAB7weraz44+dUAdNFmxkA5IhsT6Kaan368D/BvYAT+L0erZkfzEitNfOD8nt53IR9+OoCgByR7UlU06lPH/4nuBdwgsqifDXNtXfFpGluiSqL8m2tARBmACBHWJ2ElU7TnYQ10YefSbnah8+9gFMsLCuyLdA0zS3RwrIiW64NXMowTZMTtgAgB7SHIzrUk/rx3JeezD1xoF1J+WwVFs+ydDL3hNWVpdN6dz+WSGpve1/G+vA3N1TkbPsK9wJO0jMS1btnwmn5eg2Mt7CxIoNM4TsfAOQIq5Oo0nky91TqX4k+/E9wL+AklUX52txQMbmiaHWFeOLz60sLtLmhgiCDjGJlBgByRNI09dLJnqxNBbtrUWVaNpCfGhjR4d6hNLyqa3NS+wr3Ak4TicXVHo7odDgy+b3oypHxl37s9xhqDBaqIVhIqyOygjADADnkg74hnegfyegGckPSkvIirUjj+FS7HuKd+PDOvYATJU1Tg9G4wqMxhUdjGk0klEia8noMBbxeBQN+BQN+leb7mKKHrCLMAEAOicTieuV0X8brbmmsSPu7qpN9+PGENM2HHaf34bMnAQDsQZgBgBzzXnc446dzN88L2nLti/GEfrG/RQVV9fIYhqUVp4lWlvrSAq2sKHH8vpBYIqm2viF1DF64qm3nRmbavQCAdKG5EQByzEw6nfvk8WM69eZeffmhryhaWOrqPny/16PmeUEtnV18/T0JpinjkuA3E+8FAKQLKzMAkIN6RqJ6q6vf9jrrq8tta1cyTVM/+tGPVFRUpB07dkiiD/9S17oXH//hjJKJuBbX17vqXgDAVPEWDwDkoInTue2ehGXnvotjx46pp6dHDz300OTveQxDZQG/yqY5BnomuNa92H34gDo7O/XF25qy+MoAwDlougWAHOXk07lN09Qbb7yh+vp61dXV2VZnpikuLtbw8HC2XwYAOAZhBgBy2MKyIq2vLlcgTRu+A16P1leX2z7S98SJE+ru7tZnPvMZW+vMNMXFxYpEIkokEtl+KQDgCIQZAMhxTjud2zRN7d+/X7W1taqvr7e11kxTXFwsSRoZGcnyKwEAZ2DPDAA4QMqTsJT9qWCnTp3Sxx9/rAcffFAGG9ctmTVrliRpeHhYJSX2TZkDgJmCMAMADlLo92lFRYmWzZmVk1PBJvbKVFdXq7GxMWN1Z4qJlRn2zQBAaggzAOBAuToVrL29XV1dXfrSl77EqswUFBYWSiLMAECqCDMAgOuycjbM/v37VVVVpUWLFmX7ZTuS1+tVYWEhYQYAUkSYAQBcUyQW1+lwRO032p8zOPZrr0yNls7V+uWLWJWZhlmzZhFmACBFhBkAwGViiaTa+obUMXjhqvBiXvG5l36ckKGKZU06IY9i3WGtrCiRP00jpd2Es2YAIHWEGQDApJ6RqFrPhBVNJCVdHV5uxDDGwkvH4AV1D0e1Zn7Q9lHQM8VEO19RdYNGDZ9++3F/Tgx1AIBcZpimafVnFQBgBjo1MKLDvUNpv27T3BLbD+l0sqva+UxTpmnK8HyyqnXluO2GYKEaMzhuGwByFWEGAGBbkJlAoLna9dr5bmTi8+tLC2jnA+BqhBkAcLmekaje6uq3vc766nJazsZd2c43HQGvh3Y+AK7FWzkA4GKxRFKtZ8IZqfXumbBiaXh4d7pTAyN6q6s/LUFGkkYTSb3V1a9TAyNpuR4AOAlhBgBcrK1vSBczFDBGx9uq3MzOdr7DvUMEGgCuQ5gBAJcaicXVMXjB8sSy6egYvKBILJ7BirmjZyRq674kaSzQ9IxEba0BALmEMAMALtUejijVAb9H3zmgJ7/6oP7y05/S9qVV2r60Sq8+/6+Waxrjdd2Gdj4AsAdhBgBcKGmaag9HUl6Vaf9dm468vV/FpcFp1TUlnQ5HlHTZ7Bna+QDAHoQZAHChwWh87EyTFH327u3a1XpM3/6nn0+7diw5djikW9DOBwD2IcwAgAuFR2OWPn9WWbnyAwVZq+9ktPMBgH0IMwDgQuHRWMoP2OlmyD1hhnY+ALAXYQYAXGg0kcho29OlzPH6bkA7HwDYizADAC6UsPCAPRPrZwrtfABgL8IMALiQ15OtJrPcqJ8ptPMBgL182X4BAIDMC3i9MqSUW80O7NmtXU8/qUT8k7al53/wlH7143/Q4ptX65tPP5tybWO8vhvQzgcA9iLMAIALBQN+mYOpf35k+Ly6Qx2X/d5Q/zkN9Z/T7Mr5lmqb4/XdINvtdNmuDwB2I8wAgAtZDRN33He/7rjv/qzVd6pst9Nluz4A2I0wAwAuVJrvk99jWJq0lS5+j6HSfHf8+KGdDwDs5Y6fJgCAy3gMQw3BQp3oH8nong5DUmOwUB7DHSsGtPMBgL0M0+RELQBwo0gsrldO92W87pbGChX63fFe2sBoTPs6z2at/oa6OSoj0ACYwRjNDAAuVej3qb40fWeapKK+tMA1QUb6pJ0vG9zUzgfAvQgzAOBiKytKFPBm5kdBwOvRyoqSjNTKFRPtfJmOM25r5wPgXoQZAHAxv9ejNfODGam1Zn5Q/gwFp1zSGCzM+FkzpqSGYGGGqwJA5rnvpwoA4DKVRflqmmvviknT3BJVFuXbWiNX0c4HAPYhzAAAtLCsyLZA0zS3RAvLimy5tlPQzgcA9iDMAAAkjQWa9dXlaXvoDng9Wl9d7vogI9HOBwB2YTQzAOAysURSbX1D6hi8YOnAR0mTn19fWqCVFSU8VF/h1MCIDvcO2XZ9VsEAuA1hBgBwTZFYXO3hiE6HI4olx35UXBluLv3Y7zHUGCxUQ7CQ/RrXYVegIcgAcCPCDADgupKmqcFoXOHRmMKjMY0mEkokTXk9hgJer4IBv4IBv0rzfYwCTlHPSFTvnglrNJGc9rUC4y1sbh2wAMDdCDMAAGQB7XwAMH2EGQAAsoh2PgCYOsIMAAA5gHY+ALCOMAMAAADAkWiyBQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjkSYAQAAAOBIhBkAAAAAjvT/AQ4T6dqo3ViHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pretraining**"
      ],
      "metadata": {
        "id": "4_WQR47u02Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 1"
      ],
      "metadata": {
        "id": "9fkjnheJ9f59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d25Y3-YrKceI",
        "outputId": "7524978a-fc58-4c06-9eac-abb36af24b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped 252 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 252, 'invalid_loss': 0}\n",
            "Pretrain Epoch 1/20, Loss: 0.1215\n",
            "Skipped 263 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 263, 'invalid_loss': 0}\n",
            "Pretrain Epoch 2/20, Loss: 0.0862\n",
            "Skipped 261 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 261, 'invalid_loss': 0}\n",
            "Pretrain Epoch 3/20, Loss: 0.0810\n",
            "Skipped 287 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 287, 'invalid_loss': 0}\n",
            "Pretrain Epoch 4/20, Loss: 0.0782\n",
            "Skipped 314 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 314, 'invalid_loss': 0}\n",
            "Pretrain Epoch 5/20, Loss: 0.0762\n",
            "Skipped 238 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 238, 'invalid_loss': 0}\n",
            "Pretrain Epoch 6/20, Loss: 0.0750\n",
            "Skipped 275 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 275, 'invalid_loss': 0}\n",
            "Pretrain Epoch 7/20, Loss: 0.0743\n",
            "Skipped 252 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 252, 'invalid_loss': 0}\n",
            "Pretrain Epoch 8/20, Loss: 0.0737\n",
            "Skipped 261 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 261, 'invalid_loss': 0}\n",
            "Pretrain Epoch 9/20, Loss: 0.0732\n",
            "Skipped 273 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 273, 'invalid_loss': 0}\n",
            "Pretrain Epoch 10/20, Loss: 0.0730\n",
            "Skipped 260 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 260, 'invalid_loss': 0}\n",
            "Pretrain Epoch 11/20, Loss: 0.0727\n",
            "Skipped 281 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 281, 'invalid_loss': 0}\n",
            "Pretrain Epoch 12/20, Loss: 0.0725\n",
            "Skipped 283 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 283, 'invalid_loss': 0}\n",
            "Pretrain Epoch 13/20, Loss: 0.0722\n",
            "Skipped 260 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 260, 'invalid_loss': 0}\n",
            "Pretrain Epoch 14/20, Loss: 0.0721\n",
            "Skipped 272 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 272, 'invalid_loss': 0}\n",
            "Pretrain Epoch 15/20, Loss: 0.0719\n",
            "Skipped 261 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 261, 'invalid_loss': 0}\n",
            "Pretrain Epoch 16/20, Loss: 0.0718\n",
            "Skipped 268 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 268, 'invalid_loss': 0}\n",
            "Pretrain Epoch 17/20, Loss: 0.0717\n",
            "Skipped 278 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 278, 'invalid_loss': 0}\n",
            "Pretrain Epoch 18/20, Loss: 0.0716\n",
            "Skipped 276 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 276, 'invalid_loss': 0}\n",
            "Pretrain Epoch 19/20, Loss: 0.0715\n",
            "Skipped 282 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 282, 'invalid_loss': 0}\n",
            "Pretrain Epoch 20/20, Loss: 0.0713\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch.nn import LayerNorm\n",
        "\n",
        "# Define GATPretrain Model\n",
        "class GATPretrain(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GATPretrain, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
        "        self.norm1 = LayerNorm(hidden_dim * 4)  # LayerNorm after GATConv1\n",
        "        self.conv2 = GATConv(hidden_dim * 4, output_dim, heads=1, concat=True)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)  # Apply normalization\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Initialize Model (use device from Step 1)\n",
        "input_dim = 3  # [atomic number, degree, charge]\n",
        "hidden_dim = 32  # Reduced for stability\n",
        "output_dim = input_dim\n",
        "model_pretrain = GATPretrain(input_dim, hidden_dim, output_dim).to(device)  # Assumes device from Step 1\n",
        "optimizer = torch.optim.Adam(model_pretrain.parameters(), lr=1e-4)\n",
        "\n",
        "# Define Pretraining Function\n",
        "def pretrain_epoch(graphs):\n",
        "    model_pretrain.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "    skip_reasons = {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 0, 'invalid_loss': 0}\n",
        "\n",
        "    for i, data in enumerate(graphs):\n",
        "        # Skip invalid or empty graphs\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skip_reasons['empty_graph'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Normalize input features per feature column\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        # Check for NaN or inf in input features\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skip_reasons['nan_inf_input'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model_pretrain(data)\n",
        "\n",
        "        # Check for NaN or inf in model output\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skip_reasons['nan_inf_output'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        # Create mask and ensure at least one element is selected\n",
        "        mask = torch.rand(data.x.size(0), device=device) < 0.8\n",
        "        if mask.sum() == 0:\n",
        "            skip_reasons['empty_mask'] += 1\n",
        "            skipped_graphs += 1\n",
        "            continue\n",
        "\n",
        "        # Compute loss using Huber Loss\n",
        "        loss_fn = torch.nn.SmoothL1Loss()\n",
        "        loss = loss_fn(out[mask], data.x[mask])\n",
        "\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skip_reasons['invalid_loss'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        # Backpropagation with gradient clipping\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_pretrain.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs. Reasons: {skip_reasons}\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Run Pretraining\n",
        "for epoch in range(20):\n",
        "    graphs = valid_df['graph'].tolist()  # Assumes valid_df from Step 2\n",
        "    loss = pretrain_epoch(graphs)\n",
        "    print(f'Pretrain Epoch {epoch+1}/20, Loss: {loss:.4f}')\n",
        "\n",
        "# Save the model\n",
        "\n",
        "torch.save(model_pretrain.state_dict(), '/content/drive/MyDrive/pretrained_gat.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch.nn import LayerNorm\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Preprocess data (same as above, included here for completeness)\n",
        "def preprocess_data():\n",
        "    labeled_df = pd.read_csv('/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv')\n",
        "    smiles_files = glob.glob('/content/complexes_smiles/*_complexes_smiles.csv')\n",
        "    smiles_dfs = [pd.read_csv(file) for file in smiles_files]\n",
        "    all_smiles_df = pd.concat(smiles_dfs, ignore_index=True)\n",
        "\n",
        "    if all_smiles_df['refcode'].duplicated().any():\n",
        "        print(\"Warning: Duplicate refcodes found. Dropping duplicates.\")\n",
        "        all_smiles_df = all_smiles_df.drop_duplicates(subset='refcode')\n",
        "\n",
        "    merged_df = pd.merge(labeled_df, all_smiles_df[['refcode', 'SMILES']], on='refcode', how='inner')\n",
        "    print(f\"Number of merged entries: {len(merged_df)}\")\n",
        "\n",
        "    def clean_smiles(smiles):\n",
        "        try:\n",
        "            if isinstance(smiles, str) and smiles.startswith('[') and smiles.endswith(']'):\n",
        "                smiles = smiles[1:-1]\n",
        "                smiles_parts = smiles.split(',')\n",
        "                if len(smiles_parts) > 0:\n",
        "                    cleaned_smiles = smiles_parts[0].strip().strip(\"'\").strip('\"')\n",
        "                    if cleaned_smiles:\n",
        "                        return cleaned_smiles\n",
        "            elif isinstance(smiles, str):\n",
        "                return smiles\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error cleaning SMILES {smiles}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def smiles_to_graph(smiles, input_dim=3):\n",
        "        try:\n",
        "            cleaned_smiles = clean_smiles(smiles)\n",
        "            if not cleaned_smiles:\n",
        "                return None\n",
        "\n",
        "            mol = Chem.MolFromSmiles(cleaned_smiles)\n",
        "            if mol is None or mol.GetNumAtoms() == 0 or mol.GetNumBonds() == 0:\n",
        "                return None\n",
        "            AllChem.Compute2DCoords(mol)\n",
        "\n",
        "            atom_features = [[atom.GetAtomicNum(), atom.GetDegree(), atom.GetFormalCharge()] for atom in mol.GetAtoms()]\n",
        "            edge_index = []\n",
        "            for bond in mol.GetBonds():\n",
        "                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                edge_index.extend([[i, j], [j, i]])\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "            x = torch.tensor(atom_features, dtype=torch.float)\n",
        "            return Data(x=x, edge_index=edge_index)\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing SMILES {smiles}: {e}\")\n",
        "            return None\n",
        "\n",
        "    merged_df['graph'] = merged_df['SMILES'].apply(lambda x: smiles_to_graph(x, input_dim=3))\n",
        "    valid_df = merged_df[merged_df['graph'].notnull()].copy()\n",
        "    print(f\"Number of valid graphs: {len(valid_df)}\")\n",
        "\n",
        "    valid_df['graph'] = [\n",
        "        Data(x=g.x, edge_index=g.edge_index, batch=torch.zeros(g.x.size(0), dtype=torch.long))\n",
        "        for g in valid_df['graph']\n",
        "        if g.edge_index.size(1) > 0\n",
        "    ]\n",
        "    valid_df = valid_df[valid_df['graph'].apply(lambda x: x is not None and x.edge_index.size(1) > 0)].copy()\n",
        "    print(f\"Number of valid graphs with edges: {len(valid_df)}\")\n",
        "\n",
        "    return valid_df\n",
        "\n",
        "# Load and preprocess data\n",
        "valid_df = preprocess_data()\n",
        "graphs = valid_df['graph'].tolist()\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define GATPretrain Model\n",
        "class GATPretrain(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GATPretrain, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
        "        self.norm1 = LayerNorm(hidden_dim * 4)\n",
        "        self.conv2 = GATConv(hidden_dim * 4, output_dim, heads=1, concat=True)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Initialize Model\n",
        "input_dim = 3  # [atomic number, degree, charge]\n",
        "hidden_dim = 32\n",
        "output_dim = input_dim\n",
        "model_pretrain = GATPretrain(input_dim, hidden_dim, output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model_pretrain.parameters(), lr=1e-4)\n",
        "\n",
        "# Define Pretraining Function\n",
        "def pretrain_epoch(graphs):\n",
        "    model_pretrain.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "    skip_reasons = {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 0, 'invalid_loss': 0}\n",
        "\n",
        "    for i, data in enumerate(graphs):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skip_reasons['empty_graph'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skip_reasons['nan_inf_input'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model_pretrain(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skip_reasons['nan_inf_output'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        mask = torch.rand(data.x.size(0), device=device) < 0.8\n",
        "        if mask.sum() == 0:\n",
        "            skip_reasons['empty_mask'] += 1\n",
        "            skipped_graphs += 1\n",
        "            continue\n",
        "\n",
        "        loss_fn = torch.nn.SmoothL1Loss()\n",
        "        loss = loss_fn(out[mask], data.x[mask])\n",
        "\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skip_reasons['invalid_loss'] += 1\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_pretrain.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs. Reasons: {skip_reasons}\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Run Pretraining\n",
        "for epoch in range(20):\n",
        "    loss = pretrain_epoch(graphs)\n",
        "    print(f'Pretrain Epoch {epoch+1}/20, Loss: {loss:.4f}')\n",
        "\n",
        "# Save the model\n",
        "torch.save(model_pretrain.state_dict(), '/content/drive/MyDrive/pretrained_gat.pth')\n",
        "print(\"Pretrained model saved as pretrained_gat.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emq2xO-S_p2x",
        "outputId": "47f52c32-3574-4cb7-cffb-eb944be9a35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of merged entries: 82880\n",
            "Number of valid graphs: 69976\n",
            "Number of valid graphs with edges: 69976\n",
            "Using device: cpu\n",
            "Skipped 271 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 271, 'invalid_loss': 0}\n",
            "Pretrain Epoch 1/20, Loss: 0.1237\n",
            "Skipped 286 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 286, 'invalid_loss': 0}\n",
            "Pretrain Epoch 2/20, Loss: 0.0849\n",
            "Skipped 266 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 266, 'invalid_loss': 0}\n",
            "Pretrain Epoch 3/20, Loss: 0.0796\n",
            "Skipped 280 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 280, 'invalid_loss': 0}\n",
            "Pretrain Epoch 4/20, Loss: 0.0777\n",
            "Skipped 250 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 250, 'invalid_loss': 0}\n",
            "Pretrain Epoch 5/20, Loss: 0.0767\n",
            "Skipped 281 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 281, 'invalid_loss': 0}\n",
            "Pretrain Epoch 6/20, Loss: 0.0761\n",
            "Skipped 286 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 286, 'invalid_loss': 0}\n",
            "Pretrain Epoch 7/20, Loss: 0.0755\n",
            "Skipped 290 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 290, 'invalid_loss': 0}\n",
            "Pretrain Epoch 8/20, Loss: 0.0749\n",
            "Skipped 257 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 257, 'invalid_loss': 0}\n",
            "Pretrain Epoch 9/20, Loss: 0.0743\n",
            "Skipped 262 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 262, 'invalid_loss': 0}\n",
            "Pretrain Epoch 10/20, Loss: 0.0738\n",
            "Skipped 261 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 261, 'invalid_loss': 0}\n",
            "Pretrain Epoch 11/20, Loss: 0.0734\n",
            "Skipped 248 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 248, 'invalid_loss': 0}\n",
            "Pretrain Epoch 12/20, Loss: 0.0731\n",
            "Skipped 293 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 293, 'invalid_loss': 0}\n",
            "Pretrain Epoch 13/20, Loss: 0.0727\n",
            "Skipped 272 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 272, 'invalid_loss': 0}\n",
            "Pretrain Epoch 14/20, Loss: 0.0723\n",
            "Skipped 239 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 239, 'invalid_loss': 0}\n",
            "Pretrain Epoch 15/20, Loss: 0.0720\n",
            "Skipped 293 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 293, 'invalid_loss': 0}\n",
            "Pretrain Epoch 16/20, Loss: 0.0719\n",
            "Skipped 288 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 288, 'invalid_loss': 0}\n",
            "Pretrain Epoch 17/20, Loss: 0.0716\n",
            "Skipped 264 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 264, 'invalid_loss': 0}\n",
            "Pretrain Epoch 18/20, Loss: 0.0715\n",
            "Skipped 271 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 271, 'invalid_loss': 0}\n",
            "Pretrain Epoch 19/20, Loss: 0.0713\n",
            "Skipped 268 out of 69976 graphs. Reasons: {'empty_graph': 0, 'nan_inf_input': 0, 'nan_inf_output': 0, 'empty_mask': 268, 'invalid_loss': 0}\n",
            "Pretrain Epoch 20/20, Loss: 0.0711\n",
            "Pretrained model saved as pretrained_gat.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 2 - Geometry-Aware Graph Neural Network (GNN)\n"
      ],
      "metadata": {
        "id": "t9Zd4fuJ9ZI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "class GeometryAwareGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=256, num_layers=5):\n",
        "        super().__init__()\n",
        "        self.atom_conv = GATConv(input_dim, hidden_dim, heads=4, concat=False)\n",
        "        self.layers = nn.ModuleList([\n",
        "            GATConv(hidden_dim, hidden_dim, heads=4, concat=False) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.spatial_attn = nn.MultiheadAttention(hidden_dim, num_heads=4)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.elu(self.atom_conv(x, edge_index))\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = F.elu(layer(x, edge_index)) + x  # Residual connection\n",
        "\n",
        "        # Global pooling\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Pretraining wrapper\n",
        "class PretrainingWrapper(nn.Module):\n",
        "    def __init__(self, gnn, num_geometry_types):\n",
        "        super().__init__()\n",
        "        self.gnn = gnn\n",
        "        self.projection = nn.Linear(256, 128)\n",
        "        self.geometry_cls = nn.Linear(128, num_geometry_types)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = self.gnn(data)\n",
        "        x = self.projection(x)\n",
        "        return self.geometry_cls(x)\n",
        "\n",
        "# Pretraining function\n",
        "def pretrain(model, train_loader, val_loader, epochs=100, lr=1e-4, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch)\n",
        "            loss = criterion(out, batch.geometry_encoded)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = out.max(1)\n",
        "            total += batch.geometry_encoded.size(0)\n",
        "            correct += predicted.eq(batch.geometry_encoded).sum().item()\n",
        "\n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch)\n",
        "                _, predicted = out.max(1)\n",
        "                val_total += batch.geometry_encoded.size(0)\n",
        "                val_correct += predicted.eq(batch.geometry_encoded).sum().item()\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_pretrained_model.pth')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Assuming valid_df is your DataFrame with preprocessed data\n",
        "    graphs = valid_df['graph'].tolist()\n",
        "    labels = valid_df['geometry_encoded'].tolist()\n",
        "\n",
        "    # Create PyTorch Geometric dataset\n",
        "    dataset = [Data(x=g.x, edge_index=g.edge_index, geometry_encoded=torch.tensor(l, dtype=torch.long)) for g, l in zip(graphs, labels)]\n",
        "\n",
        "    # Split dataset\n",
        "    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=32)\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = dataset[0].x.size(1)  # Number of node features\n",
        "    num_geometry_types = len(valid_df['geometry'].unique())\n",
        "    gnn = GeometryAwareGNN(input_dim)\n",
        "    model = PretrainingWrapper(gnn, num_geometry_types)\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Pretrain\n",
        "    pretrain(model, train_loader, val_loader, epochs=100, lr=1e-4, device=device)\n",
        "\n",
        "    print(\"Pretraining completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ37lWXv4OVU",
        "outputId": "74c88c2d-de0c-4404-e87a-e83d2867ba6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/100: 100%|██████████| 2072/2072 [10:44<00:00,  3.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Train Loss: 1.4198, Train Acc: 0.5535\n",
            "Validation Accuracy: 0.5596\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/100: 100%|██████████| 2072/2072 [10:25<00:00,  3.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/100, Train Loss: 1.3538, Train Acc: 0.5640\n",
            "Validation Accuracy: 0.5637\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/100: 100%|██████████| 2072/2072 [10:26<00:00,  3.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100, Train Loss: 1.3359, Train Acc: 0.5687\n",
            "Validation Accuracy: 0.5604\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/100: 100%|██████████| 2072/2072 [10:25<00:00,  3.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/100, Train Loss: 1.3224, Train Acc: 0.5728\n",
            "Validation Accuracy: 0.5615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/100: 100%|██████████| 2072/2072 [08:14<00:00,  4.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/100, Train Loss: 1.3128, Train Acc: 0.5741\n",
            "Validation Accuracy: 0.5686\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/100: 100%|██████████| 2072/2072 [08:03<00:00,  4.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/100, Train Loss: 1.3025, Train Acc: 0.5749\n",
            "Validation Accuracy: 0.5722\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/100: 100%|██████████| 2072/2072 [08:00<00:00,  4.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/100, Train Loss: 1.2934, Train Acc: 0.5761\n",
            "Validation Accuracy: 0.5739\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/100: 100%|██████████| 2072/2072 [07:57<00:00,  4.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/100, Train Loss: 1.2834, Train Acc: 0.5775\n",
            "Validation Accuracy: 0.5727\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/100, Train Loss: 1.2740, Train Acc: 0.5794\n",
            "Validation Accuracy: 0.5739\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/100: 100%|██████████| 2072/2072 [07:58<00:00,  4.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/100, Train Loss: 1.2672, Train Acc: 0.5814\n",
            "Validation Accuracy: 0.5719\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/100: 100%|██████████| 2072/2072 [08:06<00:00,  4.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/100, Train Loss: 1.2608, Train Acc: 0.5823\n",
            "Validation Accuracy: 0.5767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/100: 100%|██████████| 2072/2072 [08:01<00:00,  4.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/100, Train Loss: 1.2519, Train Acc: 0.5848\n",
            "Validation Accuracy: 0.5840\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/100: 100%|██████████| 2072/2072 [07:56<00:00,  4.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/100, Train Loss: 1.2461, Train Acc: 0.5886\n",
            "Validation Accuracy: 0.5817\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/100, Train Loss: 1.2397, Train Acc: 0.5904\n",
            "Validation Accuracy: 0.5784\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/100, Train Loss: 1.2345, Train Acc: 0.5922\n",
            "Validation Accuracy: 0.5850\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/100: 100%|██████████| 2072/2072 [07:59<00:00,  4.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/100, Train Loss: 1.2286, Train Acc: 0.5947\n",
            "Validation Accuracy: 0.5899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/100: 100%|██████████| 2072/2072 [08:05<00:00,  4.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/100, Train Loss: 1.2238, Train Acc: 0.5958\n",
            "Validation Accuracy: 0.5844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/100: 100%|██████████| 2072/2072 [08:09<00:00,  4.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/100, Train Loss: 1.2181, Train Acc: 0.5987\n",
            "Validation Accuracy: 0.5910\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/100: 100%|██████████| 2072/2072 [07:52<00:00,  4.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/100, Train Loss: 1.2128, Train Acc: 0.5997\n",
            "Validation Accuracy: 0.5918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/100: 100%|██████████| 2072/2072 [07:53<00:00,  4.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/100, Train Loss: 1.2077, Train Acc: 0.6030\n",
            "Validation Accuracy: 0.5966\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/100: 100%|██████████| 2072/2072 [07:53<00:00,  4.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/100, Train Loss: 1.2029, Train Acc: 0.6033\n",
            "Validation Accuracy: 0.5949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/100: 100%|██████████| 2072/2072 [07:53<00:00,  4.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/100, Train Loss: 1.1973, Train Acc: 0.6060\n",
            "Validation Accuracy: 0.5995\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/100: 100%|██████████| 2072/2072 [07:52<00:00,  4.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/100, Train Loss: 1.1924, Train Acc: 0.6077\n",
            "Validation Accuracy: 0.6028\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/100: 100%|██████████| 2072/2072 [07:54<00:00,  4.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/100, Train Loss: 1.1879, Train Acc: 0.6088\n",
            "Validation Accuracy: 0.6061\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/100: 100%|██████████| 2072/2072 [07:52<00:00,  4.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/100, Train Loss: 1.1836, Train Acc: 0.6111\n",
            "Validation Accuracy: 0.6091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 2072/2072 [07:53<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100, Train Loss: 1.1789, Train Acc: 0.6138\n",
            "Validation Accuracy: 0.6045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100, Train Loss: 1.1725, Train Acc: 0.6147\n",
            "Validation Accuracy: 0.6095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100, Train Loss: 1.1695, Train Acc: 0.6148\n",
            "Validation Accuracy: 0.6109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100, Train Loss: 1.1645, Train Acc: 0.6177\n",
            "Validation Accuracy: 0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100, Train Loss: 1.1595, Train Acc: 0.6178\n",
            "Validation Accuracy: 0.6126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 2072/2072 [07:56<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100, Train Loss: 1.1549, Train Acc: 0.6210\n",
            "Validation Accuracy: 0.6059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 2072/2072 [07:56<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100, Train Loss: 1.1510, Train Acc: 0.6202\n",
            "Validation Accuracy: 0.6146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 2072/2072 [07:55<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100, Train Loss: 1.1472, Train Acc: 0.6214\n",
            "Validation Accuracy: 0.6132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 2072/2072 [07:56<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100, Train Loss: 1.1426, Train Acc: 0.6240\n",
            "Validation Accuracy: 0.6146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 2072/2072 [07:57<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100, Train Loss: 1.1367, Train Acc: 0.6258\n",
            "Validation Accuracy: 0.6181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 2072/2072 [07:56<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100, Train Loss: 1.1328, Train Acc: 0.6268\n",
            "Validation Accuracy: 0.6185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 2072/2072 [07:57<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100, Train Loss: 1.1296, Train Acc: 0.6292\n",
            "Validation Accuracy: 0.6210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 2072/2072 [08:00<00:00,  4.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/100, Train Loss: 1.1258, Train Acc: 0.6302\n",
            "Validation Accuracy: 0.6204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 2072/2072 [07:59<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/100, Train Loss: 1.1211, Train Acc: 0.6313\n",
            "Validation Accuracy: 0.6229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 2072/2072 [07:58<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100, Train Loss: 1.1171, Train Acc: 0.6314\n",
            "Validation Accuracy: 0.6242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 2072/2072 [07:59<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/100, Train Loss: 1.1122, Train Acc: 0.6339\n",
            "Validation Accuracy: 0.6172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 2072/2072 [08:00<00:00,  4.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/100, Train Loss: 1.1090, Train Acc: 0.6353\n",
            "Validation Accuracy: 0.6256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 2072/2072 [08:00<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/100, Train Loss: 1.1053, Train Acc: 0.6353\n",
            "Validation Accuracy: 0.6290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 2072/2072 [08:01<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/100, Train Loss: 1.1015, Train Acc: 0.6378\n",
            "Validation Accuracy: 0.6256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 2072/2072 [08:01<00:00,  4.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/100, Train Loss: 1.0977, Train Acc: 0.6380\n",
            "Validation Accuracy: 0.6256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 2072/2072 [08:01<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/100, Train Loss: 1.0932, Train Acc: 0.6387\n",
            "Validation Accuracy: 0.6292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 2072/2072 [08:02<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/100, Train Loss: 1.0903, Train Acc: 0.6412\n",
            "Validation Accuracy: 0.6272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 2072/2072 [08:03<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/100, Train Loss: 1.0859, Train Acc: 0.6420\n",
            "Validation Accuracy: 0.6287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 2072/2072 [08:03<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/100, Train Loss: 1.0825, Train Acc: 0.6434\n",
            "Validation Accuracy: 0.6281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 2072/2072 [08:03<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100, Train Loss: 1.0785, Train Acc: 0.6438\n",
            "Validation Accuracy: 0.6264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 2072/2072 [08:03<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/100, Train Loss: 1.0749, Train Acc: 0.6441\n",
            "Validation Accuracy: 0.6339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 2072/2072 [08:03<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/100, Train Loss: 1.0713, Train Acc: 0.6459\n",
            "Validation Accuracy: 0.6336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100:  59%|█████▉    | 1222/2072 [04:44<03:16,  4.33it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "class GeometryAwareGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=256, num_layers=5):\n",
        "        super().__init__()\n",
        "        self.atom_conv = GATConv(input_dim, hidden_dim, heads=4, concat=False)\n",
        "        self.layers = nn.ModuleList([\n",
        "            GATConv(hidden_dim, hidden_dim, heads=4, concat=False) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.spatial_attn = nn.MultiheadAttention(hidden_dim, num_heads=4)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.elu(self.atom_conv(x, edge_index))\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = F.elu(layer(x, edge_index)) + x  # Residual connection\n",
        "\n",
        "        # Global pooling\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Pretraining wrapper\n",
        "class PretrainingWrapper(nn.Module):\n",
        "    def __init__(self, gnn, num_geometry_types):\n",
        "        super().__init__()\n",
        "        self.gnn = gnn\n",
        "        self.projection = nn.Linear(256, 128)\n",
        "        self.geometry_cls = nn.Linear(128, num_geometry_types)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = self.gnn(data)\n",
        "        x = self.projection(x)\n",
        "        return self.geometry_cls(x)\n",
        "\n",
        "# Pretraining function\n",
        "def pretrain(model, train_loader, val_loader, epochs=100, lr=1e-4, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch)\n",
        "            loss = criterion(out, batch.geometry_encoded)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = out.max(1)\n",
        "            total += batch.geometry_encoded.size(0)\n",
        "            correct += predicted.eq(batch.geometry_encoded).sum().item()\n",
        "\n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch)\n",
        "                _, predicted = out.max(1)\n",
        "                val_total += batch.geometry_encoded.size(0)\n",
        "                val_correct += predicted.eq(batch.geometry_encoded).sum().item()\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_pretrained_model.pth')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Assuming valid_df is your DataFrame with preprocessed data\n",
        "    graphs = valid_df['graph'].tolist()\n",
        "    labels = valid_df['geometry_encoded'].tolist()\n",
        "\n",
        "    # Create PyTorch Geometric dataset\n",
        "    dataset = [Data(x=g.x, edge_index=g.edge_index, geometry_encoded=torch.tensor(l, dtype=torch.long)) for g, l in zip(graphs, labels)]\n",
        "\n",
        "    # Split dataset\n",
        "    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=32)\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = dataset[0].x.size(1)  # Number of node features\n",
        "    num_geometry_types = len(valid_df['geometry'].unique())\n",
        "    gnn = GeometryAwareGNN(input_dim)\n",
        "    model = PretrainingWrapper(gnn, num_geometry_types)\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Pretrain\n",
        "    pretrain(model, train_loader, val_loader, epochs=100, lr=1e-4, device=device)\n",
        "\n",
        "    print(\"Pretraining completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45769f0d-09ed-4081-f7b4-9f27c374b9c5",
        "id": "AMaqrpQNqXr6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/100: 100%|██████████| 2072/2072 [09:13<00:00,  3.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Train Loss: 1.4233, Train Acc: 0.5538\n",
            "Validation Accuracy: 0.5536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/100: 100%|██████████| 2072/2072 [08:53<00:00,  3.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/100, Train Loss: 1.3619, Train Acc: 0.5611\n",
            "Validation Accuracy: 0.5587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/100: 100%|██████████| 2072/2072 [08:50<00:00,  3.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100, Train Loss: 1.3441, Train Acc: 0.5662\n",
            "Validation Accuracy: 0.5650\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/100: 100%|██████████| 2072/2072 [08:50<00:00,  3.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/100, Train Loss: 1.3303, Train Acc: 0.5719\n",
            "Validation Accuracy: 0.5680\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/100: 100%|██████████| 2072/2072 [08:43<00:00,  3.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/100, Train Loss: 1.3189, Train Acc: 0.5740\n",
            "Validation Accuracy: 0.5709\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/100: 100%|██████████| 2072/2072 [08:46<00:00,  3.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/100, Train Loss: 1.3088, Train Acc: 0.5757\n",
            "Validation Accuracy: 0.5735\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/100: 100%|██████████| 2072/2072 [08:42<00:00,  3.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/100, Train Loss: 1.2991, Train Acc: 0.5763\n",
            "Validation Accuracy: 0.5723\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/100: 100%|██████████| 2072/2072 [08:47<00:00,  3.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/100, Train Loss: 1.2907, Train Acc: 0.5773\n",
            "Validation Accuracy: 0.5757\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/100: 100%|██████████| 2072/2072 [08:36<00:00,  4.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/100, Train Loss: 1.2826, Train Acc: 0.5798\n",
            "Validation Accuracy: 0.5756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/100: 100%|██████████| 2072/2072 [08:35<00:00,  4.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/100, Train Loss: 1.2757, Train Acc: 0.5798\n",
            "Validation Accuracy: 0.5712\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/100: 100%|██████████| 2072/2072 [08:38<00:00,  3.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/100, Train Loss: 1.2676, Train Acc: 0.5821\n",
            "Validation Accuracy: 0.5755\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/100: 100%|██████████| 2072/2072 [08:31<00:00,  4.05it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/100, Train Loss: 1.2608, Train Acc: 0.5820\n",
            "Validation Accuracy: 0.5801\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/100: 100%|██████████| 2072/2072 [08:32<00:00,  4.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/100, Train Loss: 1.2538, Train Acc: 0.5861\n",
            "Validation Accuracy: 0.5848\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/100: 100%|██████████| 2072/2072 [08:39<00:00,  3.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/100, Train Loss: 1.2471, Train Acc: 0.5881\n",
            "Validation Accuracy: 0.5855\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/100: 100%|██████████| 2072/2072 [08:36<00:00,  4.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/100, Train Loss: 1.2406, Train Acc: 0.5895\n",
            "Validation Accuracy: 0.5848\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/100: 100%|██████████| 2072/2072 [08:29<00:00,  4.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/100, Train Loss: 1.2338, Train Acc: 0.5926\n",
            "Validation Accuracy: 0.5869\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/100: 100%|██████████| 2072/2072 [08:33<00:00,  4.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/100, Train Loss: 1.2268, Train Acc: 0.5944\n",
            "Validation Accuracy: 0.5899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/100: 100%|██████████| 2072/2072 [08:27<00:00,  4.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/100, Train Loss: 1.2216, Train Acc: 0.5967\n",
            "Validation Accuracy: 0.5948\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/100: 100%|██████████| 2072/2072 [08:26<00:00,  4.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/100, Train Loss: 1.2167, Train Acc: 0.5993\n",
            "Validation Accuracy: 0.5939\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/100: 100%|██████████| 2072/2072 [08:24<00:00,  4.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/100, Train Loss: 1.2104, Train Acc: 0.6003\n",
            "Validation Accuracy: 0.5998\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/100: 100%|██████████| 2072/2072 [08:29<00:00,  4.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/100, Train Loss: 1.2060, Train Acc: 0.6028\n",
            "Validation Accuracy: 0.5933\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/100: 100%|██████████| 2072/2072 [08:38<00:00,  4.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/100, Train Loss: 1.1994, Train Acc: 0.6049\n",
            "Validation Accuracy: 0.6003\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/100: 100%|██████████| 2072/2072 [08:26<00:00,  4.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/100, Train Loss: 1.1944, Train Acc: 0.6070\n",
            "Validation Accuracy: 0.6045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/100: 100%|██████████| 2072/2072 [09:00<00:00,  3.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/100, Train Loss: 1.1885, Train Acc: 0.6094\n",
            "Validation Accuracy: 0.6056\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/100: 100%|██████████| 2072/2072 [08:27<00:00,  4.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/100, Train Loss: 1.1842, Train Acc: 0.6104\n",
            "Validation Accuracy: 0.6026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/100: 100%|██████████| 2072/2072 [08:34<00:00,  4.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/100, Train Loss: 1.1792, Train Acc: 0.6119\n",
            "Validation Accuracy: 0.6058\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/100: 100%|██████████| 2072/2072 [08:29<00:00,  4.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/100, Train Loss: 1.1741, Train Acc: 0.6122\n",
            "Validation Accuracy: 0.6038\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/100: 100%|██████████| 2072/2072 [08:35<00:00,  4.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/100, Train Loss: 1.1699, Train Acc: 0.6149\n",
            "Validation Accuracy: 0.6106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/100: 100%|██████████| 2072/2072 [08:31<00:00,  4.05it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/100, Train Loss: 1.1644, Train Acc: 0.6170\n",
            "Validation Accuracy: 0.6065\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/100: 100%|██████████| 2072/2072 [08:38<00:00,  3.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/100, Train Loss: 1.1604, Train Acc: 0.6185\n",
            "Validation Accuracy: 0.6137\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/100: 100%|██████████| 2072/2072 [08:43<00:00,  3.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/100, Train Loss: 1.1552, Train Acc: 0.6195\n",
            "Validation Accuracy: 0.6080\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/100: 100%|██████████| 2072/2072 [08:35<00:00,  4.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/100, Train Loss: 1.1524, Train Acc: 0.6204\n",
            "Validation Accuracy: 0.6083\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/100: 100%|██████████| 2072/2072 [08:38<00:00,  4.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/100, Train Loss: 1.1476, Train Acc: 0.6216\n",
            "Validation Accuracy: 0.6150\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/100: 100%|██████████| 2072/2072 [08:39<00:00,  3.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/100, Train Loss: 1.1427, Train Acc: 0.6236\n",
            "Validation Accuracy: 0.6180\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/100: 100%|██████████| 2072/2072 [08:37<00:00,  4.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/100, Train Loss: 1.1396, Train Acc: 0.6246\n",
            "Validation Accuracy: 0.6160\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/100: 100%|██████████| 2072/2072 [07:57<00:00,  4.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/100, Train Loss: 1.1352, Train Acc: 0.6248\n",
            "Validation Accuracy: 0.6174\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/100: 100%|██████████| 2072/2072 [08:41<00:00,  3.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/100, Train Loss: 1.1305, Train Acc: 0.6287\n",
            "Validation Accuracy: 0.6193\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/100: 100%|██████████| 2072/2072 [08:47<00:00,  3.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/100, Train Loss: 1.1266, Train Acc: 0.6278\n",
            "Validation Accuracy: 0.6187\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/100: 100%|██████████| 2072/2072 [08:40<00:00,  3.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/100, Train Loss: 1.1231, Train Acc: 0.6296\n",
            "Validation Accuracy: 0.6220\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/100: 100%|██████████| 2072/2072 [08:46<00:00,  3.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/100, Train Loss: 1.1184, Train Acc: 0.6302\n",
            "Validation Accuracy: 0.6214\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/100: 100%|██████████| 2072/2072 [08:52<00:00,  3.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/100, Train Loss: 1.1147, Train Acc: 0.6318\n",
            "Validation Accuracy: 0.6188\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/100: 100%|██████████| 2072/2072 [08:44<00:00,  3.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/100, Train Loss: 1.1105, Train Acc: 0.6333\n",
            "Validation Accuracy: 0.6260\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/100: 100%|██████████| 2072/2072 [08:46<00:00,  3.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/100, Train Loss: 1.1073, Train Acc: 0.6337\n",
            "Validation Accuracy: 0.6252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/100: 100%|██████████| 2072/2072 [08:48<00:00,  3.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/100, Train Loss: 1.1030, Train Acc: 0.6349\n",
            "Validation Accuracy: 0.6251\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/100: 100%|██████████| 2072/2072 [08:44<00:00,  3.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/100, Train Loss: 1.0991, Train Acc: 0.6366\n",
            "Validation Accuracy: 0.6261\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/100: 100%|██████████| 2072/2072 [08:44<00:00,  3.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/100, Train Loss: 1.0948, Train Acc: 0.6385\n",
            "Validation Accuracy: 0.6292\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/100: 100%|██████████| 2072/2072 [08:45<00:00,  3.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/100, Train Loss: 1.0933, Train Acc: 0.6379\n",
            "Validation Accuracy: 0.6279\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/100: 100%|██████████| 2072/2072 [08:52<00:00,  3.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/100, Train Loss: 1.0876, Train Acc: 0.6409\n",
            "Validation Accuracy: 0.6299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/100: 100%|██████████| 2072/2072 [08:45<00:00,  3.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/100, Train Loss: 1.0848, Train Acc: 0.6403\n",
            "Validation Accuracy: 0.6252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/100: 100%|██████████| 2072/2072 [08:54<00:00,  3.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/100, Train Loss: 1.0809, Train Acc: 0.6412\n",
            "Validation Accuracy: 0.6292\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/100: 100%|██████████| 2072/2072 [08:49<00:00,  3.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51/100, Train Loss: 1.0771, Train Acc: 0.6432\n",
            "Validation Accuracy: 0.6246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/100: 100%|██████████| 2072/2072 [08:48<00:00,  3.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52/100, Train Loss: 1.0738, Train Acc: 0.6453\n",
            "Validation Accuracy: 0.6299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/100: 100%|██████████| 2072/2072 [08:55<00:00,  3.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53/100, Train Loss: 1.0703, Train Acc: 0.6466\n",
            "Validation Accuracy: 0.6312\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/100: 100%|██████████| 2072/2072 [08:49<00:00,  3.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54/100, Train Loss: 1.0665, Train Acc: 0.6472\n",
            "Validation Accuracy: 0.6297\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/100: 100%|██████████| 2072/2072 [08:44<00:00,  3.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55/100, Train Loss: 1.0631, Train Acc: 0.6483\n",
            "Validation Accuracy: 0.6293\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/100: 100%|██████████| 2072/2072 [08:51<00:00,  3.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56/100, Train Loss: 1.0592, Train Acc: 0.6490\n",
            "Validation Accuracy: 0.6336\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/100: 100%|██████████| 2072/2072 [08:47<00:00,  3.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57/100, Train Loss: 1.0557, Train Acc: 0.6512\n",
            "Validation Accuracy: 0.6333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/100: 100%|██████████| 2072/2072 [08:39<00:00,  3.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/100, Train Loss: 1.0524, Train Acc: 0.6508\n",
            "Validation Accuracy: 0.6347\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 59/100: 100%|██████████| 2072/2072 [08:53<00:00,  3.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59/100, Train Loss: 1.0493, Train Acc: 0.6527\n",
            "Validation Accuracy: 0.6391\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 60/100: 100%|██████████| 2072/2072 [08:47<00:00,  3.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60/100, Train Loss: 1.0470, Train Acc: 0.6535\n",
            "Validation Accuracy: 0.6379\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 61/100: 100%|██████████| 2072/2072 [08:45<00:00,  3.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61/100, Train Loss: 1.0423, Train Acc: 0.6550\n",
            "Validation Accuracy: 0.6342\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 62/100: 100%|██████████| 2072/2072 [08:44<00:00,  3.95it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62/100, Train Loss: 1.0390, Train Acc: 0.6560\n",
            "Validation Accuracy: 0.6380\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 63/100: 100%|██████████| 2072/2072 [08:39<00:00,  3.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63/100, Train Loss: 1.0360, Train Acc: 0.6573\n",
            "Validation Accuracy: 0.6384\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 64/100: 100%|██████████| 2072/2072 [08:52<00:00,  3.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64/100, Train Loss: 1.0331, Train Acc: 0.6575\n",
            "Validation Accuracy: 0.6373\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 65/100: 100%|██████████| 2072/2072 [08:48<00:00,  3.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65/100, Train Loss: 1.0302, Train Acc: 0.6587\n",
            "Validation Accuracy: 0.6396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 66/100: 100%|██████████| 2072/2072 [09:17<00:00,  3.72it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66/100, Train Loss: 1.0272, Train Acc: 0.6592\n",
            "Validation Accuracy: 0.6436\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 67/100: 100%|██████████| 2072/2072 [09:02<00:00,  3.82it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67/100, Train Loss: 1.0242, Train Acc: 0.6612\n",
            "Validation Accuracy: 0.6422\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 68/100: 100%|██████████| 2072/2072 [08:49<00:00,  3.91it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68/100, Train Loss: 1.0213, Train Acc: 0.6614\n",
            "Validation Accuracy: 0.6415\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 69/100: 100%|██████████| 2072/2072 [08:52<00:00,  3.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69/100, Train Loss: 1.0183, Train Acc: 0.6632\n",
            "Validation Accuracy: 0.6418\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 70/100: 100%|██████████| 2072/2072 [09:00<00:00,  3.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70/100, Train Loss: 1.0156, Train Acc: 0.6642\n",
            "Validation Accuracy: 0.6452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 71/100: 100%|██████████| 2072/2072 [08:49<00:00,  3.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71/100, Train Loss: 1.0126, Train Acc: 0.6646\n",
            "Validation Accuracy: 0.6453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 2072/2072 [08:41<00:00,  3.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/100, Train Loss: 1.0106, Train Acc: 0.6651\n",
            "Validation Accuracy: 0.6430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 2072/2072 [09:24<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/100, Train Loss: 1.0088, Train Acc: 0.6661\n",
            "Validation Accuracy: 0.6453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 2072/2072 [09:06<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/100, Train Loss: 1.0053, Train Acc: 0.6682\n",
            "Validation Accuracy: 0.6458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 2072/2072 [08:58<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/100, Train Loss: 1.0034, Train Acc: 0.6677\n",
            "Validation Accuracy: 0.6480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100:  42%|████▏     | 864/2072 [03:43<05:31,  3.64it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finetuning**"
      ],
      "metadata": {
        "id": "m2pt0X5406PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch.nn import LayerNorm\n",
        "\n",
        "# Split data into fine-tune and train sets\n",
        "finetune_df, train_df = train_test_split(valid_df, test_size=0.8, random_state=42)\n",
        "finetune_graphs = finetune_df['graph'].tolist()\n",
        "\n",
        "# Calculate class weights for imbalance\n",
        "class_counts = finetune_df['geometry_encoded'].value_counts()\n",
        "class_weights = (1.0 / torch.tensor([class_counts[i] for i in range(len(le.classes_))], dtype=torch.float)).to(device)\n",
        "\n",
        "# Define GATTask Model (with LayerNorm for stability)\n",
        "class GATTask(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(GATTask, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
        "        self.norm1 = LayerNorm(hidden_dim * 4)  # Add LayerNorm for stability\n",
        "        self.conv2 = GATConv(hidden_dim * 4, hidden_dim, heads=1, concat=True)  # Output to hidden_dim\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize GATTask model\n",
        "input_dim = 3  # [atomic number, degree, charge]\n",
        "hidden_dim = 32  # Consistent with pretraining\n",
        "num_classes = len(le.classes_)\n",
        "model_task = GATTask(input_dim, hidden_dim, num_classes).to(device)\n",
        "\n",
        "# Load pretrained weights with partial loading\n",
        "pretrained_dict = torch.load('/content/drive/MyDrive/pretrained_gat.pth')\n",
        "model_dict = model_task.state_dict()\n",
        "\n",
        "# Filter out mismatched layers and load compatible ones\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and (k.startswith('conv1') or k.startswith('norm1'))}\n",
        "model_dict.update(pretrained_dict)\n",
        "model_task.load_state_dict(model_dict)\n",
        "\n",
        "print(\"Pretrained weights loaded for compatible layers:\", list(pretrained_dict.keys()))\n",
        "print(\"Initialized remaining layers (conv2, fc) randomly.\")\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = torch.optim.Adam(model_task.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define Fine-Tuning Function\n",
        "def finetune_epoch(graphs, labels):\n",
        "    model_task.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = torch.tensor([label], dtype=torch.long).to(device)\n",
        "\n",
        "        # Normalize input features (consistent with pretraining)\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model_task(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_task.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs during fine-tuning.\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Run Fine-Tuning\n",
        "for epoch in range(10):\n",
        "    loss = finetune_epoch(finetune_graphs, finetune_df['geometry_encoded'].tolist())\n",
        "    print(f'Finetune Epoch {epoch+1}/10, Loss: {loss:.4f}')\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model_task.state_dict(), '/content/drive/MyDrive/finetuned_gat.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRbrlVWMfgP9",
        "outputId": "4f75d754-5ab5-42d0-a03d-0716a7ec3023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained weights loaded for compatible layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias']\n",
            "Initialized remaining layers (conv2, fc) randomly.\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 1/10, Loss: 1.8823\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 2/10, Loss: 1.7938\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 3/10, Loss: 1.7813\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 4/10, Loss: 1.7658\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 5/10, Loss: 1.7477\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 6/10, Loss: 1.7351\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 7/10, Loss: 1.7266\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 8/10, Loss: 1.7199\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 9/10, Loss: 1.7144\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 10/10, Loss: 1.7111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch.nn import LayerNorm\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Preprocess data (assumes this was defined earlier in your pipeline)\n",
        "def preprocess_data():\n",
        "    labeled_df = pd.read_csv('/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv')\n",
        "    smiles_files = glob.glob('/content/complexes_smiles/*_complexes_smiles.csv')\n",
        "    smiles_dfs = [pd.read_csv(file) for file in smiles_files]\n",
        "    all_smiles_df = pd.concat(smiles_dfs, ignore_index=True)\n",
        "\n",
        "    if all_smiles_df['refcode'].duplicated().any():\n",
        "        print(\"Warning: Duplicate refcodes found. Dropping duplicates.\")\n",
        "        all_smiles_df = all_smiles_df.drop_duplicates(subset='refcode')\n",
        "\n",
        "    merged_df = pd.merge(labeled_df, all_smiles_df[['refcode', 'SMILES']], on='refcode', how='inner')\n",
        "    print(f\"Number of merged entries: {len(merged_df)}\")\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    merged_df['geometry_encoded'] = le.fit_transform(merged_df['geometry'])\n",
        "    print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "    def smiles_to_graph(smiles):\n",
        "        try:\n",
        "            if isinstance(smiles, str) and smiles.startswith('['):\n",
        "                smiles = eval(smiles)[0]\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            if mol is None or mol.GetNumAtoms() == 0 or mol.GetNumBonds() == 0:\n",
        "                return None\n",
        "            AllChem.Compute2DCoords(mol)\n",
        "            # Features to match pretrained: atomic number, degree, charge\n",
        "            atom_features = [[atom.GetAtomicNum(), atom.GetDegree(), atom.GetFormalCharge()] for atom in mol.GetAtoms()]\n",
        "            edge_index = []\n",
        "            for bond in mol.GetBonds():\n",
        "                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                edge_index.extend([[i, j], [j, i]])\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "            x = torch.tensor(atom_features, dtype=torch.float)\n",
        "            return Data(x=x, edge_index=edge_index)\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing SMILES {smiles}: {e}\")\n",
        "            return None\n",
        "\n",
        "    merged_df['graph'] = merged_df['SMILES'].apply(smiles_to_graph)\n",
        "    valid_df = merged_df[merged_df['graph'].notnull()].copy()\n",
        "    print(f\"Number of valid graphs: {len(valid_df)}\")\n",
        "\n",
        "    valid_df['graph'] = [\n",
        "        Data(x=g.x, edge_index=g.edge_index, batch=torch.zeros(g.x.size(0), dtype=torch.long))\n",
        "        for g in valid_df['graph']\n",
        "        if g.edge_index.size(1) > 0\n",
        "    ]\n",
        "    valid_df = valid_df[valid_df['graph'].apply(lambda x: x is not None and x.edge_index.size(1) > 0)].copy()\n",
        "    print(f\"Number of valid graphs with edges: {len(valid_df)}\")\n",
        "\n",
        "    return valid_df, le\n",
        "\n",
        "# Load and preprocess data\n",
        "valid_df, le = preprocess_data()\n",
        "\n",
        "# Split data into fine-tune and train sets\n",
        "finetune_df, train_df = train_test_split(valid_df, test_size=0.8, random_state=42)\n",
        "finetune_graphs = finetune_df['graph'].tolist()\n",
        "finetune_labels = finetune_df['geometry_encoded'].tolist()\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Calculate class weights for imbalance\n",
        "class_counts = finetune_df['geometry_encoded'].value_counts()\n",
        "class_weights = (1.0 / torch.tensor([class_counts[i] for i in range(len(le.classes_))], dtype=torch.float)).to(device)\n",
        "class_weights = torch.clamp(class_weights, min=0.1, max=10.0)\n",
        "\n",
        "# Define GATTask Model to match pretrained architecture\n",
        "class GATTask(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes):\n",
        "        super(GATTask, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim_conv1, heads=4, concat=True)\n",
        "        self.norm1 = LayerNorm(hidden_dim_conv1 * 4)\n",
        "        self.conv2 = GATConv(hidden_dim_conv1 * 4, output_dim_conv2, heads=1, concat=True)\n",
        "        # Map conv2 output to a higher dimension for classification\n",
        "        self.mapping_layer = nn.Linear(output_dim_conv2, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = F.elu(self.mapping_layer(x))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize GATTask model to match pretrained architecture\n",
        "input_dim = 3  # Match pretrained\n",
        "hidden_dim_conv1 = 32  # Match pretrained for conv1\n",
        "output_dim_conv2 = 3   # Match pretrained for conv2 (from GATPretrain output_dim)\n",
        "hidden_dim = 32        # Desired hidden dimension for classification\n",
        "num_classes = len(le.classes_)\n",
        "model_task = GATTask(input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes).to(device)\n",
        "\n",
        "# Load pretrained weights, excluding the fc layer\n",
        "try:\n",
        "    pretrained_dict = torch.load('/content/drive/MyDrive/pretrained_gat.pth', map_location=device)\n",
        "    model_dict = model_task.state_dict()\n",
        "    # Exclude layers that don't match (fc and mapping_layer)\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and not k.startswith('fc') and not k.startswith('mapping_layer')}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model_task.load_state_dict(model_dict)\n",
        "    print(\"Pretrained weights loaded successfully for layers:\", list(pretrained_dict.keys()))\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load pretrained weights: {e}. Initializing all layers randomly.\")\n",
        "\n",
        "print(\"The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\")\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = torch.optim.Adam(model_task.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define Fine-Tuning Function\n",
        "def finetune_epoch(graphs, labels):\n",
        "    model_task.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = torch.tensor([label], dtype=torch.long).to(device)\n",
        "\n",
        "        # Normalize input features (consistent with pretraining)\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model_task(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_task.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs during fine-tuning.\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Run Fine-Tuning for more epochs\n",
        "for epoch in range(20):\n",
        "    loss = finetune_epoch(finetune_graphs, finetune_labels)\n",
        "    print(f'Finetune Epoch {epoch+1}/20, Loss: {loss:.4f}')\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model_task.state_dict(), '/content/drive/MyDrive/finetuned_gat_32dim_3dim.pth')\n",
        "print(\"Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSKe2r9E2ZiB",
        "outputId": "25e3f066-8a4c-45ce-ab50-1a5aba74aa8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of merged entries: 82880\n",
            "Label mapping: {'bent': np.int64(0), 'linear': np.int64(1), 'octahedral': np.int64(2), 'planar_3': np.int64(3), 'planar_4': np.int64(4), 'planar_5': np.int64(5), 'prism': np.int64(6), 'pyramid_3': np.int64(7), 'pyramid_4': np.int64(8), 'pyramid_bi': np.int64(9), 'pyramid_sq': np.int64(10), 'tetrahedral': np.int64(11), 'tshape': np.int64(12)}\n",
            "Number of valid graphs: 69976\n",
            "Number of valid graphs with edges: 69976\n",
            "Using device: cpu\n",
            "Pretrained weights loaded successfully for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight']\n",
            "The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 1/20, Loss: 2.0515\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 2/20, Loss: 1.8610\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 3/20, Loss: 1.8245\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 4/20, Loss: 1.8260\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 5/20, Loss: 1.8242\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 6/20, Loss: 1.8159\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 7/20, Loss: 1.8063\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 8/20, Loss: 1.8020\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 9/20, Loss: 1.7984\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 10/20, Loss: 1.7944\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 11/20, Loss: 1.7905\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 12/20, Loss: 1.7874\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 13/20, Loss: 1.7849\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 14/20, Loss: 1.7826\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 15/20, Loss: 1.7808\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 16/20, Loss: 1.7791\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 17/20, Loss: 1.7773\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 18/20, Loss: 1.7752\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 19/20, Loss: 1.7730\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 20/20, Loss: 1.7711\n",
            "Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch.nn import LayerNorm\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Preprocess data (assumes this was defined earlier in your pipeline)\n",
        "def preprocess_data():\n",
        "    labeled_df = pd.read_csv('/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv')\n",
        "    smiles_files = glob.glob('/content/complexes_smiles/*_complexes_smiles.csv')\n",
        "    smiles_dfs = [pd.read_csv(file) for file in smiles_files]\n",
        "    all_smiles_df = pd.concat(smiles_dfs, ignore_index=True)\n",
        "\n",
        "    if all_smiles_df['refcode'].duplicated().any():\n",
        "        print(\"Warning: Duplicate refcodes found. Dropping duplicates.\")\n",
        "        all_smiles_df = all_smiles_df.drop_duplicates(subset='refcode')\n",
        "\n",
        "    merged_df = pd.merge(labeled_df, all_smiles_df[['refcode', 'SMILES']], on='refcode', how='inner')\n",
        "    print(f\"Number of merged entries: {len(merged_df)}\")\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    merged_df['geometry_encoded'] = le.fit_transform(merged_df['geometry'])\n",
        "    print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "    def smiles_to_graph(smiles):\n",
        "        try:\n",
        "            if isinstance(smiles, str) and smiles.startswith('['):\n",
        "                smiles = eval(smiles)[0]\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            if mol is None or mol.GetNumAtoms() == 0 or mol.GetNumBonds() == 0:\n",
        "                return None\n",
        "            AllChem.Compute2DCoords(mol)\n",
        "            # Features to match pretrained: atomic number, degree, charge\n",
        "            atom_features = [[atom.GetAtomicNum(), atom.GetDegree(), atom.GetFormalCharge()] for atom in mol.GetAtoms()]\n",
        "            edge_index = []\n",
        "            for bond in mol.GetBonds():\n",
        "                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                edge_index.extend([[i, j], [j, i]])\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "            x = torch.tensor(atom_features, dtype=torch.float)\n",
        "            return Data(x=x, edge_index=edge_index)\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing SMILES {smiles}: {e}\")\n",
        "            return None\n",
        "\n",
        "    merged_df['graph'] = merged_df['SMILES'].apply(smiles_to_graph)\n",
        "    valid_df = merged_df[merged_df['graph'].notnull()].copy()\n",
        "    print(f\"Number of valid graphs: {len(valid_df)}\")\n",
        "\n",
        "    valid_df['graph'] = [\n",
        "        Data(x=g.x, edge_index=g.edge_index, batch=torch.zeros(g.x.size(0), dtype=torch.long))\n",
        "        for g in valid_df['graph']\n",
        "        if g.edge_index.size(1) > 0\n",
        "    ]\n",
        "    valid_df = valid_df[valid_df['graph'].apply(lambda x: x is not None and x.edge_index.size(1) > 0)].copy()\n",
        "    print(f\"Number of valid graphs with edges: {len(valid_df)}\")\n",
        "\n",
        "    return valid_df, le\n",
        "\n",
        "# Load and preprocess data\n",
        "valid_df, le = preprocess_data()\n",
        "\n",
        "# Split data into fine-tune and train sets\n",
        "finetune_df, train_df = train_test_split(valid_df, test_size=0.8, random_state=42)\n",
        "finetune_graphs = finetune_df['graph'].tolist()\n",
        "finetune_labels = finetune_df['geometry_encoded'].tolist()\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Calculate class weights for imbalance\n",
        "class_counts = finetune_df['geometry_encoded'].value_counts()\n",
        "class_weights = (1.0 / torch.tensor([class_counts[i] for i in range(len(le.classes_))], dtype=torch.float)).to(device)\n",
        "class_weights = torch.clamp(class_weights, min=0.1, max=10.0)\n",
        "\n",
        "# Define GATTask Model to match pretrained architecture\n",
        "class GATTask(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes):\n",
        "        super(GATTask, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim_conv1, heads=4, concat=True)\n",
        "        self.norm1 = LayerNorm(hidden_dim_conv1 * 4)\n",
        "        self.conv2 = GATConv(hidden_dim_conv1 * 4, output_dim_conv2, heads=1, concat=True)\n",
        "        # Map conv2 output to a higher dimension for classification\n",
        "        self.mapping_layer = nn.Linear(output_dim_conv2, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = F.elu(self.mapping_layer(x))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize GATTask model to match pretrained architecture\n",
        "input_dim = 3  # Match pretrained\n",
        "hidden_dim_conv1 = 32  # Match pretrained for conv1\n",
        "output_dim_conv2 = 3   # Match pretrained for conv2 (from GATPretrain output_dim)\n",
        "hidden_dim = 32        # Desired hidden dimension for classification\n",
        "num_classes = len(le.classes_)\n",
        "model_task = GATTask(input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes).to(device)\n",
        "\n",
        "# Load pretrained weights, excluding the fc layer\n",
        "try:\n",
        "    pretrained_dict = torch.load('/content/drive/MyDrive/pretrained_gat.pth', map_location=device)\n",
        "    model_dict = model_task.state_dict()\n",
        "    # Exclude layers that don't match (fc and mapping_layer)\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and not k.startswith('fc') and not k.startswith('mapping_layer')}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model_task.load_state_dict(model_dict)\n",
        "    print(\"Pretrained weights loaded successfully for layers:\", list(pretrained_dict.keys()))\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load pretrained weights: {e}. Initializing all layers randomly.\")\n",
        "\n",
        "print(\"The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\")\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = torch.optim.Adam(model_task.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define Fine-Tuning Function\n",
        "def finetune_epoch(graphs, labels):\n",
        "    model_task.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = torch.tensor([label], dtype=torch.long).to(device)\n",
        "\n",
        "        # Normalize input features (consistent with pretraining)\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model_task(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_task.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs during fine-tuning.\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Run Fine-Tuning for more epochs\n",
        "for epoch in range(20):\n",
        "    loss = finetune_epoch(finetune_graphs, finetune_labels)\n",
        "    print(f'Finetune Epoch {epoch+1}/20, Loss: {loss:.4f}')\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model_task.state_dict(), '/content/drive/MyDrive/finetuned_gat_32dim_3dim.pth')\n",
        "print(\"Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418a640a-cf72-4d2f-fb1c-3a7f930144af",
        "id": "BtJ4Zkchlc7k"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of merged entries: 82880\n",
            "Label mapping: {'bent': np.int64(0), 'linear': np.int64(1), 'octahedral': np.int64(2), 'planar_3': np.int64(3), 'planar_4': np.int64(4), 'planar_5': np.int64(5), 'prism': np.int64(6), 'pyramid_3': np.int64(7), 'pyramid_4': np.int64(8), 'pyramid_bi': np.int64(9), 'pyramid_sq': np.int64(10), 'tetrahedral': np.int64(11), 'tshape': np.int64(12)}\n",
            "Number of valid graphs: 69976\n",
            "Number of valid graphs with edges: 69976\n",
            "Using device: cpu\n",
            "Pretrained weights loaded successfully for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight']\n",
            "The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 1/20, Loss: 1.9857\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 2/20, Loss: 1.8195\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 3/20, Loss: 1.8031\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 4/20, Loss: 1.7945\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 5/20, Loss: 1.7922\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 6/20, Loss: 1.7929\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 7/20, Loss: 1.7934\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 8/20, Loss: 1.7941\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 9/20, Loss: 1.7909\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 10/20, Loss: 1.7871\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 11/20, Loss: 1.7843\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 12/20, Loss: 1.7806\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 13/20, Loss: 1.7768\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 14/20, Loss: 1.7753\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 15/20, Loss: 1.7727\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 16/20, Loss: 1.7698\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 17/20, Loss: 1.7675\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 18/20, Loss: 1.7659\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 19/20, Loss: 1.7644\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 20/20, Loss: 1.7642\n",
            "Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Training**"
      ],
      "metadata": {
        "id": "G2Umuv2D1GeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool, global_max_pool\n",
        "from torch.nn import LayerNorm, Dropout, BatchNorm1d\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import glob\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    seed = 42\n",
        "    batch_size = 64\n",
        "    hidden_dim = 32  # Changed to match pre-trained model\n",
        "    num_heads = 4    # Changed to match pre-trained model\n",
        "    dropout = 0.4\n",
        "    learning_rate = 5e-4\n",
        "    weight_decay = 1e-5\n",
        "    epochs = 300\n",
        "    patience = 20\n",
        "    min_lr = 1e-6\n",
        "    gamma = 2.0\n",
        "    num_folds = 5\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(Config.seed)\n",
        "np.random.seed(Config.seed)\n",
        "\n",
        "# Define Focal Loss for handling class imbalance\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=Config.gamma, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "# Define the Enhanced Robust Molecular Geometry Model\n",
        "class RobustMolecularGeometryModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, dropout_prob=Config.dropout):\n",
        "        super(RobustMolecularGeometryModel, self).__init__()\n",
        "\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim, heads=Config.num_heads, concat=True, dropout=dropout_prob)\n",
        "        self.norm1 = LayerNorm(hidden_dim * Config.num_heads)\n",
        "        self.dropout1 = Dropout(dropout_prob)\n",
        "\n",
        "        self.conv2 = GATConv(hidden_dim * Config.num_heads, hidden_dim * 2, heads=Config.num_heads, concat=True, dropout=dropout_prob)\n",
        "        self.norm2 = LayerNorm(hidden_dim * 2 * Config.num_heads)\n",
        "        self.dropout2 = Dropout(dropout_prob)\n",
        "\n",
        "        self.conv3 = GATConv(hidden_dim * 2 * Config.num_heads, hidden_dim, heads=1, concat=False, dropout=dropout_prob)\n",
        "        self.norm3 = LayerNorm(hidden_dim)\n",
        "        self.dropout3 = Dropout(dropout_prob)\n",
        "\n",
        "        self.conv4 = GATConv(hidden_dim, hidden_dim, heads=1, concat=False, dropout=dropout_prob)\n",
        "        self.norm4 = LayerNorm(hidden_dim)\n",
        "        self.dropout4 = Dropout(dropout_prob)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.bn1 = BatchNorm1d(hidden_dim)\n",
        "        self.dropout_fc = Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = self.norm2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.elu(self.conv3(x, edge_index))\n",
        "        x = self.norm3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = F.elu(self.conv4(x, edge_index))\n",
        "        x = self.norm4(x)\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x_mean = global_mean_pool(x, batch)\n",
        "        x_max = global_max_pool(x, batch)\n",
        "        x_combined = torch.cat([x_mean, x_max], dim=1)\n",
        "\n",
        "        x = F.relu(self.fc1(x_combined))\n",
        "        x = self.bn1(x)\n",
        "        x = self.dropout_fc(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# ... [Keep the preprocess_graphs, augment_data, and preprocess_data functions as they were] ...\n",
        "\n",
        "# Training and evaluation function\n",
        "def train_and_evaluate(graphs, labels, le, num_folds=Config.num_folds, epochs=Config.epochs):\n",
        "    graphs, labels = preprocess_graphs(graphs, labels)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=Config.seed)\n",
        "\n",
        "    fold_accuracies = []\n",
        "\n",
        "    input_dim = graphs[0].x.shape[1]\n",
        "    num_classes = len(set(labels))\n",
        "\n",
        "    labels_array = np.array(labels)\n",
        "    if labels_array.min() < 0 or labels_array.max() >= num_classes:\n",
        "        raise ValueError(f\"Labels must be in range [0, {num_classes-1}], but found min: {labels_array.min()}, max: {labels_array.max()}\")\n",
        "\n",
        "    class_counts = np.bincount(labels)\n",
        "    print(f\"Class counts: {class_counts}\")\n",
        "    class_weights = np.log1p(1.0 / (class_counts + 1e-6))\n",
        "    class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
        "    class_weights = np.minimum(class_weights, 2.0)\n",
        "    class_weights = np.maximum(class_weights, 0.3)\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "    print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "    sample_weights = np.zeros(len(labels))\n",
        "    for i, label in enumerate(labels):\n",
        "        sample_weights[i] = class_weights[label].item()\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(graphs, labels), 1):\n",
        "        print(f\"\\n=== Fold {fold}/{num_folds} ===\")\n",
        "\n",
        "        train_graphs = [graphs[i] for i in train_index]\n",
        "        val_graphs = [graphs[i] for i in val_index]\n",
        "        train_labels = [labels[i] for i in train_index]\n",
        "\n",
        "        train_sample_weights = [sample_weights[i] for i in train_index]\n",
        "        sampler = WeightedRandomSampler(train_sample_weights, len(train_sample_weights), replacement=True)\n",
        "\n",
        "        train_loader = DataLoader(train_graphs, batch_size=Config.batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(val_graphs, batch_size=Config.batch_size*2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        model = RobustMolecularGeometryModel(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=Config.hidden_dim,\n",
        "            num_classes=num_classes,\n",
        "            dropout_prob=Config.dropout\n",
        "        ).to(device)\n",
        "\n",
        "        try:\n",
        "            finetuned_dict = torch.load('/content/drive/MyDrive/finetuned_gat_32dim_3dim.pth', map_location=device)\n",
        "            model_dict = model.state_dict()\n",
        "\n",
        "            # Filter out incompatible keys\n",
        "            compatible_layers = {k: v for k, v in finetuned_dict.items() if k in model_dict and v.shape == model_dict[k].shape}\n",
        "            model_dict.update(compatible_layers)\n",
        "            model.load_state_dict(model_dict)\n",
        "\n",
        "            print(f\"Fold {fold}: Loaded compatible fine-tuned weights for layers: {list(compatible_layers.keys())}\")\n",
        "            print(f\"Fold {fold}: Initialized remaining layers with new dimensions.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Fold {fold}: Failed to load fine-tuned weights: {e}. Training from scratch.\")\n",
        "\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=Config.learning_rate,\n",
        "            weight_decay=Config.weight_decay\n",
        "        )\n",
        "        criterion = FocalLoss(alpha=class_weights)\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=Config.epochs, eta_min=Config.min_lr)\n",
        "\n",
        "        warmup_epochs = 10\n",
        "        warmup_lr = 1e-6\n",
        "\n",
        "        best_val_accuracy = 0\n",
        "        patience = Config.patience\n",
        "        patience_counter = 0\n",
        "\n",
        "        accum_steps = 4\n",
        "        effective_batch_size = Config.batch_size * accum_steps\n",
        "\n",
        "        for epoch in range(Config.epochs):\n",
        "            model.train()\n",
        "            total_train_loss = 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if epoch < warmup_epochs:\n",
        "                lr = warmup_lr + (Config.learning_rate - warmup_lr) * (epoch / warmup_epochs)\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr\n",
        "\n",
        "            step = 0\n",
        "            for batch in train_loader:\n",
        "                batch = batch.to(device)\n",
        "                batch = augment_data(batch, epoch)\n",
        "\n",
        "                outputs = model(batch)\n",
        "                loss = criterion(outputs, batch.y)\n",
        "                loss = loss / accum_steps\n",
        "\n",
        "                loss.backward()\n",
        "                step += 1\n",
        "\n",
        "                if step % accum_steps == 0:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                total_train_loss += loss.item() * accum_steps * batch.num_graphs\n",
        "\n",
        "            model.eval()\n",
        "            total_val_loss = 0\n",
        "            all_preds = []\n",
        "            all_true = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    batch = batch.to(device)\n",
        "                    outputs = model(batch)\n",
        "                    loss = criterion(outputs, batch.y)\n",
        "                    total_val_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "                    preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "                    all_preds.extend(preds)\n",
        "                    all_true.extend(batch.y.cpu().numpy())\n",
        "\n",
        "            val_accuracy = accuracy_score(all_true, all_preds)\n",
        "            val_f1 = f1_score(all_true, all_preds, average='weighted')\n",
        "            avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
        "            avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
        "\n",
        "            if epoch >= warmup_epochs:\n",
        "                scheduler.step()\n",
        "\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), f\"best_model_fold_{fold}.pth\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            print(f\"Fold {fold}, Epoch {epoch+1}: \"\n",
        "                  f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "                  f\"Val Loss: {avg_val_loss:.4f}, \"\n",
        "                  f\"Val Accuracy: {val_accuracy:.4f}, \"\n",
        "                  f\"Val F1: {val_f1:.4f}, \"\n",
        "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Fold {fold}: Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        fold_accuracies.append(best_val_accuracy)\n",
        "\n",
        "    mean_accuracy = np.mean(fold_accuracies)\n",
        "    print(f\"\\nOverall Mean Accuracy: {mean_accuracy:.4f}\")\n",
        "\n",
        "    print(\"\\nDetailed Performance Analysis\")\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(graphs, labels), 1):\n",
        "        val_graphs = [graphs[i] for i in val_index]\n",
        "        val_labels = [labels[i] for i in val_index]\n",
        "        val_loader = DataLoader(val_graphs, batch_size=Config.batch_size*2, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        model.load_state_dict(torch.load(f\"best_model_fold_{fold}.pth\", map_location=device))\n",
        "\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_true = []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                outputs = model(batch)\n",
        "                preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "                all_preds.extend(preds)\n",
        "                all_true.extend(batch.y.cpu().numpy())\n",
        "\n",
        "        print(f\"\\nFold {fold} Classification Report:\")\n",
        "        print(classification_report(all_true, all_preds))\n",
        "\n",
        "def main():\n",
        "    torch.manual_seed(Config.seed)\n",
        "    np.random.seed(Config.seed)\n",
        "\n",
        "    valid_df, le = preprocess_data()\n",
        "\n",
        "    graphs = valid_df['graph'].tolist()\n",
        "    labels = valid_df['geometry_encoded'].tolist()\n",
        "\n",
        "    train_and_evaluate(graphs, labels, le)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NabaKz2K-2Qd",
        "outputId": "5ebc3c86-ce56-4017-da38-9e779d5d3309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of merged entries: 82880\n",
            "Label mapping: {'bent': np.int64(0), 'linear': np.int64(1), 'octahedral': np.int64(2), 'planar_3': np.int64(3), 'planar_4': np.int64(4), 'planar_5': np.int64(5), 'prism': np.int64(6), 'pyramid_3': np.int64(7), 'pyramid_4': np.int64(8), 'pyramid_bi': np.int64(9), 'pyramid_sq': np.int64(10), 'tetrahedral': np.int64(11), 'tshape': np.int64(12)}\n",
            "Number of valid graphs: 69976\n",
            "Number of valid graphs with edges: 69976\n",
            "Skipped 0 graphs with missing features\n",
            "Using device: cpu\n",
            "Class counts: [    8   395 36865  1038 10631    41  2092   101  4503  4686  5034  4441\n",
            "   141]\n",
            "Class weights: tensor([2.0000, 0.3000, 0.3000, 0.3000, 0.3000, 1.9131, 0.3000, 0.7822, 0.3000,\n",
            "        0.3000, 0.3000, 0.3000, 0.5611])\n",
            "\n",
            "=== Fold 1/5 ===\n",
            "Fold 1: Loaded compatible fine-tuned weights for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight', 'norm2.weight', 'norm2.bias', 'conv3.att_src', 'conv3.att_dst', 'conv3.bias', 'conv3.lin.weight', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n",
            "Fold 1: Initialized remaining layers with new dimensions.\n",
            "Fold 1, Epoch 1: Train Loss: 0.3268, Val Loss: 0.3549, Val Accuracy: 0.1695, Val F1: 0.2012, LR: 0.000001\n",
            "Fold 1, Epoch 2: Train Loss: 0.2936, Val Loss: 0.2888, Val Accuracy: 0.1530, Val F1: 0.1956, LR: 0.000051\n",
            "Fold 1, Epoch 3: Train Loss: 0.2502, Val Loss: 0.2457, Val Accuracy: 0.3633, Val F1: 0.3192, LR: 0.000101\n",
            "Fold 1, Epoch 4: Train Loss: 0.2167, Val Loss: 0.1994, Val Accuracy: 0.5115, Val F1: 0.3635, LR: 0.000151\n",
            "Fold 1, Epoch 5: Train Loss: 0.1924, Val Loss: 0.3931, Val Accuracy: 0.5209, Val F1: 0.3641, LR: 0.000201\n",
            "Fold 1, Epoch 6: Train Loss: 0.1672, Val Loss: 0.5619, Val Accuracy: 0.5266, Val F1: 0.3636, LR: 0.000251\n",
            "Fold 1, Epoch 7: Train Loss: 0.1581, Val Loss: 0.4347, Val Accuracy: 0.5268, Val F1: 0.3635, LR: 0.000300\n",
            "Fold 1, Epoch 8: Train Loss: 0.1464, Val Loss: 0.3443, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000350\n",
            "Fold 1, Epoch 9: Train Loss: 0.1430, Val Loss: 0.3175, Val Accuracy: 0.5268, Val F1: 0.3635, LR: 0.000400\n",
            "Fold 1, Epoch 10: Train Loss: 0.1414, Val Loss: 0.4544, Val Accuracy: 0.5268, Val F1: 0.3635, LR: 0.000450\n",
            "Fold 1, Epoch 11: Train Loss: 0.1422, Val Loss: 0.4925, Val Accuracy: 0.5268, Val F1: 0.3635, LR: 0.000450\n",
            "Fold 1, Epoch 12: Train Loss: 0.1407, Val Loss: 0.3838, Val Accuracy: 0.5266, Val F1: 0.3634, LR: 0.000450\n",
            "Fold 1, Epoch 13: Train Loss: 0.1399, Val Loss: 0.8450, Val Accuracy: 0.5257, Val F1: 0.3645, LR: 0.000450\n",
            "Fold 1, Epoch 14: Train Loss: 0.1379, Val Loss: 0.8605, Val Accuracy: 0.5266, Val F1: 0.3634, LR: 0.000450\n",
            "Fold 1, Epoch 15: Train Loss: 0.1367, Val Loss: 0.3349, Val Accuracy: 0.5234, Val F1: 0.3645, LR: 0.000450\n",
            "Fold 1, Epoch 16: Train Loss: 0.1348, Val Loss: 0.4879, Val Accuracy: 0.5246, Val F1: 0.3647, LR: 0.000450\n",
            "Fold 1, Epoch 17: Train Loss: 0.1364, Val Loss: 0.4685, Val Accuracy: 0.5231, Val F1: 0.3647, LR: 0.000449\n",
            "Fold 1, Epoch 18: Train Loss: 0.1321, Val Loss: 0.5674, Val Accuracy: 0.5243, Val F1: 0.3647, LR: 0.000449\n",
            "Fold 1, Epoch 19: Train Loss: 0.1319, Val Loss: 0.2789, Val Accuracy: 0.5227, Val F1: 0.3654, LR: 0.000449\n",
            "Fold 1, Epoch 20: Train Loss: 0.1323, Val Loss: 0.3444, Val Accuracy: 0.5189, Val F1: 0.3640, LR: 0.000449\n",
            "Fold 1, Epoch 21: Train Loss: 0.1319, Val Loss: 0.3357, Val Accuracy: 0.5214, Val F1: 0.3649, LR: 0.000449\n",
            "Fold 1, Epoch 22: Train Loss: 0.1317, Val Loss: 0.5033, Val Accuracy: 0.5220, Val F1: 0.3648, LR: 0.000448\n",
            "Fold 1, Epoch 23: Train Loss: 0.1319, Val Loss: 0.5153, Val Accuracy: 0.5216, Val F1: 0.3645, LR: 0.000448\n",
            "Fold 1, Epoch 24: Train Loss: 0.1294, Val Loss: 0.6880, Val Accuracy: 0.5234, Val F1: 0.3646, LR: 0.000448\n",
            "Fold 1, Epoch 25: Train Loss: 0.1278, Val Loss: 0.3087, Val Accuracy: 0.5251, Val F1: 0.3652, LR: 0.000447\n",
            "Fold 1, Epoch 26: Train Loss: 0.1294, Val Loss: 0.2800, Val Accuracy: 0.5226, Val F1: 0.3647, LR: 0.000447\n",
            "Fold 1, Epoch 27: Train Loss: 0.1305, Val Loss: 0.5362, Val Accuracy: 0.5213, Val F1: 0.3644, LR: 0.000447\n",
            "Fold 1: Early stopping triggered.\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "Fold 2: Loaded compatible fine-tuned weights for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight', 'norm2.weight', 'norm2.bias', 'conv3.att_src', 'conv3.att_dst', 'conv3.bias', 'conv3.lin.weight', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n",
            "Fold 2: Initialized remaining layers with new dimensions.\n",
            "Fold 2, Epoch 1: Train Loss: 0.3144, Val Loss: 0.4471, Val Accuracy: 0.0965, Val F1: 0.1544, LR: 0.000001\n",
            "Fold 2, Epoch 2: Train Loss: 0.2888, Val Loss: 0.3167, Val Accuracy: 0.0875, Val F1: 0.1434, LR: 0.000051\n",
            "Fold 2, Epoch 3: Train Loss: 0.2471, Val Loss: 0.2435, Val Accuracy: 0.0741, Val F1: 0.1221, LR: 0.000101\n",
            "Fold 2, Epoch 4: Train Loss: 0.2187, Val Loss: 0.2073, Val Accuracy: 0.3426, Val F1: 0.3378, LR: 0.000151\n",
            "Fold 2, Epoch 5: Train Loss: 0.1960, Val Loss: 0.1701, Val Accuracy: 0.5229, Val F1: 0.3651, LR: 0.000201\n",
            "Fold 2, Epoch 6: Train Loss: 0.1699, Val Loss: 0.1539, Val Accuracy: 0.5263, Val F1: 0.3640, LR: 0.000251\n",
            "Fold 2, Epoch 7: Train Loss: 0.1596, Val Loss: 0.1484, Val Accuracy: 0.5263, Val F1: 0.3647, LR: 0.000300\n",
            "Fold 2, Epoch 8: Train Loss: 0.1491, Val Loss: 0.1419, Val Accuracy: 0.5265, Val F1: 0.3650, LR: 0.000350\n",
            "Fold 2, Epoch 9: Train Loss: 0.1491, Val Loss: 0.1424, Val Accuracy: 0.5256, Val F1: 0.3645, LR: 0.000400\n",
            "Fold 2, Epoch 10: Train Loss: 0.1436, Val Loss: 0.1399, Val Accuracy: 0.5264, Val F1: 0.3642, LR: 0.000450\n",
            "Fold 2, Epoch 11: Train Loss: 0.1421, Val Loss: 0.1364, Val Accuracy: 0.5266, Val F1: 0.3643, LR: 0.000450\n",
            "Fold 2, Epoch 12: Train Loss: 0.1438, Val Loss: 0.1479, Val Accuracy: 0.5255, Val F1: 0.3641, LR: 0.000450\n",
            "Fold 2, Epoch 13: Train Loss: 0.1392, Val Loss: 0.3910, Val Accuracy: 0.5257, Val F1: 0.3644, LR: 0.000450\n",
            "Fold 2, Epoch 14: Train Loss: 0.1381, Val Loss: 0.3304, Val Accuracy: 0.5262, Val F1: 0.3645, LR: 0.000450\n",
            "Fold 2, Epoch 15: Train Loss: 0.1388, Val Loss: 0.2474, Val Accuracy: 0.5062, Val F1: 0.3572, LR: 0.000450\n",
            "Fold 2, Epoch 16: Train Loss: 0.1391, Val Loss: 0.1438, Val Accuracy: 0.5032, Val F1: 0.3607, LR: 0.000450\n",
            "Fold 2, Epoch 17: Train Loss: 0.1375, Val Loss: 0.3013, Val Accuracy: 0.5055, Val F1: 0.3577, LR: 0.000449\n",
            "Fold 2, Epoch 18: Train Loss: 0.1358, Val Loss: 0.3313, Val Accuracy: 0.5245, Val F1: 0.3650, LR: 0.000449\n",
            "Fold 2, Epoch 19: Train Loss: 0.1343, Val Loss: 0.1529, Val Accuracy: 0.5053, Val F1: 0.3580, LR: 0.000449\n",
            "Fold 2, Epoch 20: Train Loss: 0.1328, Val Loss: 0.1915, Val Accuracy: 0.5175, Val F1: 0.3619, LR: 0.000449\n",
            "Fold 2, Epoch 21: Train Loss: 0.1339, Val Loss: 0.2609, Val Accuracy: 0.5252, Val F1: 0.3646, LR: 0.000449\n",
            "Fold 2, Epoch 22: Train Loss: 0.1319, Val Loss: 0.3030, Val Accuracy: 0.5229, Val F1: 0.3643, LR: 0.000448\n",
            "Fold 2, Epoch 23: Train Loss: 0.1342, Val Loss: 0.3994, Val Accuracy: 0.4908, Val F1: 0.3559, LR: 0.000448\n",
            "Fold 2, Epoch 24: Train Loss: 0.1339, Val Loss: 0.1665, Val Accuracy: 0.5031, Val F1: 0.3577, LR: 0.000448\n",
            "Fold 2, Epoch 25: Train Loss: 0.1327, Val Loss: 0.1344, Val Accuracy: 0.5247, Val F1: 0.3656, LR: 0.000447\n",
            "Fold 2, Epoch 26: Train Loss: 0.1292, Val Loss: 0.1731, Val Accuracy: 0.5210, Val F1: 0.3632, LR: 0.000447\n",
            "Fold 2, Epoch 27: Train Loss: 0.1315, Val Loss: 0.1289, Val Accuracy: 0.5240, Val F1: 0.3645, LR: 0.000447\n",
            "Fold 2, Epoch 28: Train Loss: 0.1293, Val Loss: 0.1597, Val Accuracy: 0.5134, Val F1: 0.3605, LR: 0.000446\n",
            "Fold 2, Epoch 29: Train Loss: 0.1306, Val Loss: 0.2067, Val Accuracy: 0.5117, Val F1: 0.3606, LR: 0.000446\n",
            "Fold 2, Epoch 30: Train Loss: 0.1292, Val Loss: 0.2890, Val Accuracy: 0.5058, Val F1: 0.3587, LR: 0.000445\n",
            "Fold 2, Epoch 31: Train Loss: 0.1311, Val Loss: 0.1705, Val Accuracy: 0.5204, Val F1: 0.3627, LR: 0.000445\n",
            "Fold 2: Early stopping triggered.\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "Fold 3: Loaded compatible fine-tuned weights for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight', 'norm2.weight', 'norm2.bias', 'conv3.att_src', 'conv3.att_dst', 'conv3.bias', 'conv3.lin.weight', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n",
            "Fold 3: Initialized remaining layers with new dimensions.\n",
            "Fold 3, Epoch 1: Train Loss: 0.3200, Val Loss: 0.2686, Val Accuracy: 0.1193, Val F1: 0.1658, LR: 0.000001\n",
            "Fold 3, Epoch 2: Train Loss: 0.2937, Val Loss: 0.2364, Val Accuracy: 0.1577, Val F1: 0.1946, LR: 0.000051\n",
            "Fold 3, Epoch 3: Train Loss: 0.2538, Val Loss: 0.2011, Val Accuracy: 0.3187, Val F1: 0.2869, LR: 0.000101\n",
            "Fold 3, Epoch 4: Train Loss: 0.2273, Val Loss: 0.2022, Val Accuracy: 0.4028, Val F1: 0.3203, LR: 0.000151\n",
            "Fold 3, Epoch 5: Train Loss: 0.1954, Val Loss: 0.1776, Val Accuracy: 0.5226, Val F1: 0.3630, LR: 0.000201\n",
            "Fold 3, Epoch 6: Train Loss: 0.1780, Val Loss: 0.1519, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000251\n",
            "Fold 3, Epoch 7: Train Loss: 0.1587, Val Loss: 0.1515, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000300\n",
            "Fold 3, Epoch 8: Train Loss: 0.1523, Val Loss: 0.3425, Val Accuracy: 0.5238, Val F1: 0.3652, LR: 0.000350\n",
            "Fold 3, Epoch 9: Train Loss: 0.1459, Val Loss: 0.2065, Val Accuracy: 0.5236, Val F1: 0.3651, LR: 0.000400\n",
            "Fold 3, Epoch 10: Train Loss: 0.1424, Val Loss: 0.2261, Val Accuracy: 0.5220, Val F1: 0.3622, LR: 0.000450\n",
            "Fold 3, Epoch 11: Train Loss: 0.1438, Val Loss: 0.2451, Val Accuracy: 0.5193, Val F1: 0.3654, LR: 0.000450\n",
            "Fold 3, Epoch 12: Train Loss: 0.1405, Val Loss: 0.1458, Val Accuracy: 0.5243, Val F1: 0.3673, LR: 0.000450\n",
            "Fold 3, Epoch 13: Train Loss: 0.1366, Val Loss: 0.3109, Val Accuracy: 0.5165, Val F1: 0.3634, LR: 0.000450\n",
            "Fold 3, Epoch 14: Train Loss: 0.1353, Val Loss: 0.3762, Val Accuracy: 0.5262, Val F1: 0.3637, LR: 0.000450\n",
            "Fold 3, Epoch 15: Train Loss: 0.1376, Val Loss: 0.3087, Val Accuracy: 0.5265, Val F1: 0.3636, LR: 0.000450\n",
            "Fold 3, Epoch 16: Train Loss: 0.1342, Val Loss: 0.3510, Val Accuracy: 0.5258, Val F1: 0.3643, LR: 0.000450\n",
            "Fold 3, Epoch 17: Train Loss: 0.1357, Val Loss: 0.4418, Val Accuracy: 0.5027, Val F1: 0.3571, LR: 0.000449\n",
            "Fold 3, Epoch 18: Train Loss: 0.1340, Val Loss: 0.4265, Val Accuracy: 0.5245, Val F1: 0.3652, LR: 0.000449\n",
            "Fold 3, Epoch 19: Train Loss: 0.1344, Val Loss: 0.2793, Val Accuracy: 0.5248, Val F1: 0.3655, LR: 0.000449\n",
            "Fold 3, Epoch 20: Train Loss: 0.1318, Val Loss: 0.3690, Val Accuracy: 0.5240, Val F1: 0.3645, LR: 0.000449\n",
            "Fold 3, Epoch 21: Train Loss: 0.1330, Val Loss: 0.2533, Val Accuracy: 0.5256, Val F1: 0.3652, LR: 0.000449\n",
            "Fold 3, Epoch 22: Train Loss: 0.1306, Val Loss: 0.2681, Val Accuracy: 0.5033, Val F1: 0.3583, LR: 0.000448\n",
            "Fold 3, Epoch 23: Train Loss: 0.1307, Val Loss: 0.3312, Val Accuracy: 0.5245, Val F1: 0.3646, LR: 0.000448\n",
            "Fold 3, Epoch 24: Train Loss: 0.1293, Val Loss: 0.3977, Val Accuracy: 0.5242, Val F1: 0.3642, LR: 0.000448\n",
            "Fold 3, Epoch 25: Train Loss: 0.1333, Val Loss: 0.3451, Val Accuracy: 0.5234, Val F1: 0.3643, LR: 0.000447\n",
            "Fold 3, Epoch 26: Train Loss: 0.1325, Val Loss: 0.5693, Val Accuracy: 0.5157, Val F1: 0.3617, LR: 0.000447\n",
            "Fold 3, Epoch 27: Train Loss: 0.1288, Val Loss: 0.4232, Val Accuracy: 0.5241, Val F1: 0.3646, LR: 0.000447\n",
            "Fold 3: Early stopping triggered.\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "Fold 4: Loaded compatible fine-tuned weights for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight', 'norm2.weight', 'norm2.bias', 'conv3.att_src', 'conv3.att_dst', 'conv3.bias', 'conv3.lin.weight', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n",
            "Fold 4: Initialized remaining layers with new dimensions.\n",
            "Fold 4, Epoch 1: Train Loss: 0.3184, Val Loss: 0.2852, Val Accuracy: 0.0627, Val F1: 0.0794, LR: 0.000001\n",
            "Fold 4, Epoch 2: Train Loss: 0.2934, Val Loss: 0.2452, Val Accuracy: 0.1117, Val F1: 0.1592, LR: 0.000051\n",
            "Fold 4, Epoch 3: Train Loss: 0.2538, Val Loss: 0.2177, Val Accuracy: 0.2865, Val F1: 0.3131, LR: 0.000101\n",
            "Fold 4, Epoch 4: Train Loss: 0.2170, Val Loss: 0.1876, Val Accuracy: 0.4529, Val F1: 0.3623, LR: 0.000151\n",
            "Fold 4, Epoch 5: Train Loss: 0.1950, Val Loss: 0.1709, Val Accuracy: 0.5154, Val F1: 0.3670, LR: 0.000201\n",
            "Fold 4, Epoch 6: Train Loss: 0.1705, Val Loss: 0.1512, Val Accuracy: 0.5265, Val F1: 0.3636, LR: 0.000251\n",
            "Fold 4, Epoch 7: Train Loss: 0.1570, Val Loss: 0.1643, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000300\n",
            "Fold 4, Epoch 8: Train Loss: 0.1464, Val Loss: 0.1859, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000350\n",
            "Fold 4, Epoch 9: Train Loss: 0.1439, Val Loss: 0.1554, Val Accuracy: 0.5264, Val F1: 0.3642, LR: 0.000400\n",
            "Fold 4, Epoch 10: Train Loss: 0.1408, Val Loss: 0.1670, Val Accuracy: 0.4950, Val F1: 0.3535, LR: 0.000450\n",
            "Fold 4, Epoch 11: Train Loss: 0.1427, Val Loss: 0.1796, Val Accuracy: 0.5260, Val F1: 0.3644, LR: 0.000450\n",
            "Fold 4, Epoch 12: Train Loss: 0.1403, Val Loss: 0.1702, Val Accuracy: 0.5055, Val F1: 0.3579, LR: 0.000450\n",
            "Fold 4, Epoch 13: Train Loss: 0.1378, Val Loss: 0.2180, Val Accuracy: 0.5209, Val F1: 0.3634, LR: 0.000450\n",
            "Fold 4, Epoch 14: Train Loss: 0.1355, Val Loss: 0.5492, Val Accuracy: 0.5112, Val F1: 0.3603, LR: 0.000450\n",
            "Fold 4, Epoch 15: Train Loss: 0.1337, Val Loss: 0.5534, Val Accuracy: 0.5039, Val F1: 0.3570, LR: 0.000450\n",
            "Fold 4, Epoch 16: Train Loss: 0.1329, Val Loss: 0.3986, Val Accuracy: 0.5215, Val F1: 0.3637, LR: 0.000450\n",
            "Fold 4, Epoch 17: Train Loss: 0.1317, Val Loss: 0.3498, Val Accuracy: 0.4922, Val F1: 0.3530, LR: 0.000449\n",
            "Fold 4, Epoch 18: Train Loss: 0.1357, Val Loss: 0.2451, Val Accuracy: 0.5038, Val F1: 0.3570, LR: 0.000449\n",
            "Fold 4, Epoch 19: Train Loss: 0.1328, Val Loss: 0.3066, Val Accuracy: 0.5115, Val F1: 0.3603, LR: 0.000449\n",
            "Fold 4, Epoch 20: Train Loss: 0.1316, Val Loss: 0.1948, Val Accuracy: 0.5030, Val F1: 0.3567, LR: 0.000449\n",
            "Fold 4, Epoch 21: Train Loss: 0.1308, Val Loss: 0.1631, Val Accuracy: 0.5215, Val F1: 0.3640, LR: 0.000449\n",
            "Fold 4, Epoch 22: Train Loss: 0.1310, Val Loss: 0.1923, Val Accuracy: 0.5226, Val F1: 0.3640, LR: 0.000448\n",
            "Fold 4, Epoch 23: Train Loss: 0.1289, Val Loss: 0.1655, Val Accuracy: 0.5044, Val F1: 0.3569, LR: 0.000448\n",
            "Fold 4, Epoch 24: Train Loss: 0.1285, Val Loss: 0.2007, Val Accuracy: 0.5110, Val F1: 0.3601, LR: 0.000448\n",
            "Fold 4, Epoch 25: Train Loss: 0.1282, Val Loss: 0.3060, Val Accuracy: 0.5222, Val F1: 0.3635, LR: 0.000447\n",
            "Fold 4, Epoch 26: Train Loss: 0.1299, Val Loss: 0.2508, Val Accuracy: 0.5097, Val F1: 0.3583, LR: 0.000447\n",
            "Fold 4, Epoch 27: Train Loss: 0.1313, Val Loss: 0.2790, Val Accuracy: 0.5095, Val F1: 0.3600, LR: 0.000447\n",
            "Fold 4: Early stopping triggered.\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "Fold 5: Loaded compatible fine-tuned weights for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight', 'norm2.weight', 'norm2.bias', 'conv3.att_src', 'conv3.att_dst', 'conv3.bias', 'conv3.lin.weight', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias']\n",
            "Fold 5: Initialized remaining layers with new dimensions.\n",
            "Fold 5, Epoch 1: Train Loss: 0.3226, Val Loss: 0.2799, Val Accuracy: 0.2944, Val F1: 0.2973, LR: 0.000001\n",
            "Fold 5, Epoch 2: Train Loss: 0.2902, Val Loss: 0.2229, Val Accuracy: 0.3896, Val F1: 0.3526, LR: 0.000051\n",
            "Fold 5, Epoch 3: Train Loss: 0.2543, Val Loss: 0.1946, Val Accuracy: 0.4271, Val F1: 0.3564, LR: 0.000101\n",
            "Fold 5, Epoch 4: Train Loss: 0.2209, Val Loss: 0.2359, Val Accuracy: 0.4821, Val F1: 0.3635, LR: 0.000151\n",
            "Fold 5, Epoch 5: Train Loss: 0.1944, Val Loss: 0.4963, Val Accuracy: 0.5163, Val F1: 0.3616, LR: 0.000201\n",
            "Fold 5, Epoch 6: Train Loss: 0.1724, Val Loss: 1.0611, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000251\n",
            "Fold 5, Epoch 7: Train Loss: 0.1552, Val Loss: 0.4356, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000300\n",
            "Fold 5, Epoch 8: Train Loss: 0.1476, Val Loss: 0.3418, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000350\n",
            "Fold 5, Epoch 9: Train Loss: 0.1460, Val Loss: 0.7751, Val Accuracy: 0.5268, Val F1: 0.3636, LR: 0.000400\n",
            "Fold 5, Epoch 10: Train Loss: 0.1418, Val Loss: 0.3987, Val Accuracy: 0.5268, Val F1: 0.3637, LR: 0.000450\n",
            "Fold 5, Epoch 11: Train Loss: 0.1400, Val Loss: 0.7978, Val Accuracy: 0.5269, Val F1: 0.3647, LR: 0.000450\n",
            "Fold 5, Epoch 12: Train Loss: 0.1412, Val Loss: 1.1009, Val Accuracy: 0.5261, Val F1: 0.3637, LR: 0.000450\n",
            "Fold 5, Epoch 13: Train Loss: 0.1364, Val Loss: 1.1625, Val Accuracy: 0.5262, Val F1: 0.3638, LR: 0.000450\n",
            "Fold 5, Epoch 14: Train Loss: 0.1381, Val Loss: 0.8426, Val Accuracy: 0.5250, Val F1: 0.3644, LR: 0.000450\n",
            "Fold 5, Epoch 15: Train Loss: 0.1378, Val Loss: 0.6026, Val Accuracy: 0.5245, Val F1: 0.3652, LR: 0.000450\n",
            "Fold 5, Epoch 16: Train Loss: 0.1379, Val Loss: 0.9843, Val Accuracy: 0.5236, Val F1: 0.3645, LR: 0.000450\n",
            "Fold 5, Epoch 17: Train Loss: 0.1332, Val Loss: 0.7087, Val Accuracy: 0.5242, Val F1: 0.3655, LR: 0.000449\n",
            "Fold 5, Epoch 18: Train Loss: 0.1340, Val Loss: 0.7784, Val Accuracy: 0.5237, Val F1: 0.3644, LR: 0.000449\n",
            "Fold 5, Epoch 19: Train Loss: 0.1346, Val Loss: 0.7629, Val Accuracy: 0.5244, Val F1: 0.3647, LR: 0.000449\n",
            "Fold 5, Epoch 20: Train Loss: 0.1328, Val Loss: 0.7119, Val Accuracy: 0.5243, Val F1: 0.3642, LR: 0.000449\n",
            "Fold 5, Epoch 21: Train Loss: 0.1315, Val Loss: 0.3140, Val Accuracy: 0.5260, Val F1: 0.3652, LR: 0.000449\n",
            "Fold 5, Epoch 22: Train Loss: 0.1347, Val Loss: 0.3640, Val Accuracy: 0.5253, Val F1: 0.3647, LR: 0.000448\n",
            "Fold 5, Epoch 23: Train Loss: 0.1289, Val Loss: 0.3883, Val Accuracy: 0.5243, Val F1: 0.3647, LR: 0.000448\n",
            "Fold 5, Epoch 24: Train Loss: 0.1314, Val Loss: 0.2692, Val Accuracy: 0.5125, Val F1: 0.3601, LR: 0.000448\n",
            "Fold 5, Epoch 25: Train Loss: 0.1298, Val Loss: 0.2506, Val Accuracy: 0.5251, Val F1: 0.3645, LR: 0.000447\n",
            "Fold 5, Epoch 26: Train Loss: 0.1287, Val Loss: 0.1628, Val Accuracy: 0.5243, Val F1: 0.3641, LR: 0.000447\n",
            "Fold 5, Epoch 27: Train Loss: 0.1271, Val Loss: 0.3463, Val Accuracy: 0.5252, Val F1: 0.3646, LR: 0.000447\n",
            "Fold 5, Epoch 28: Train Loss: 0.1271, Val Loss: 0.3039, Val Accuracy: 0.5253, Val F1: 0.3646, LR: 0.000446\n",
            "Fold 5, Epoch 29: Train Loss: 0.1286, Val Loss: 0.4657, Val Accuracy: 0.5243, Val F1: 0.3642, LR: 0.000446\n",
            "Fold 5, Epoch 30: Train Loss: 0.1267, Val Loss: 0.4047, Val Accuracy: 0.5245, Val F1: 0.3641, LR: 0.000445\n",
            "Fold 5, Epoch 31: Train Loss: 0.1263, Val Loss: 0.3104, Val Accuracy: 0.5257, Val F1: 0.3638, LR: 0.000445\n",
            "Fold 5: Early stopping triggered.\n",
            "\n",
            "Overall Mean Accuracy: 0.5268\n",
            "\n",
            "Detailed Performance Analysis\n",
            "\n",
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00        79\n",
            "           2       0.53      1.00      0.69      7373\n",
            "           3       0.00      0.00      0.00       207\n",
            "           4       0.00      0.00      0.00      2127\n",
            "           5       0.00      0.00      0.00         9\n",
            "           6       0.00      0.00      0.00       419\n",
            "           7       0.00      0.00      0.00        20\n",
            "           8       0.00      0.00      0.00       901\n",
            "           9       0.00      0.00      0.00       937\n",
            "          10       0.00      0.00      0.00      1006\n",
            "          11       0.00      0.00      0.00       888\n",
            "          12       0.00      0.00      0.00        28\n",
            "\n",
            "    accuracy                           0.53     13996\n",
            "   macro avg       0.04      0.08      0.05     13996\n",
            "weighted avg       0.28      0.53      0.36     13996\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00        79\n",
            "           2       0.53      1.00      0.69      7373\n",
            "           3       0.25      0.02      0.04       208\n",
            "           4       0.00      0.00      0.00      2126\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.00      0.00      0.00       418\n",
            "           7       0.00      0.00      0.00        21\n",
            "           8       0.00      0.00      0.00       901\n",
            "           9       0.00      0.00      0.00       937\n",
            "          10       0.14      0.00      0.00      1007\n",
            "          11       0.00      0.00      0.00       888\n",
            "          12       0.00      0.00      0.00        28\n",
            "\n",
            "    accuracy                           0.53     13995\n",
            "   macro avg       0.07      0.08      0.06     13995\n",
            "weighted avg       0.29      0.53      0.36     13995\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00        79\n",
            "           2       0.53      1.00      0.69      7373\n",
            "           3       0.00      0.00      0.00       208\n",
            "           4       0.00      0.00      0.00      2126\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.00      0.00      0.00       418\n",
            "           7       0.00      0.00      0.00        20\n",
            "           8       0.00      0.00      0.00       901\n",
            "           9       0.00      0.00      0.00       937\n",
            "          10       0.00      0.00      0.00      1007\n",
            "          11       0.00      0.00      0.00       888\n",
            "          12       0.00      0.00      0.00        29\n",
            "\n",
            "    accuracy                           0.53     13995\n",
            "   macro avg       0.04      0.08      0.05     13995\n",
            "weighted avg       0.28      0.53      0.36     13995\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00        79\n",
            "           2       0.53      1.00      0.69      7373\n",
            "           3       0.00      0.00      0.00       208\n",
            "           4       0.00      0.00      0.00      2126\n",
            "           5       0.00      0.00      0.00         8\n",
            "           6       0.00      0.00      0.00       418\n",
            "           7       0.00      0.00      0.00        20\n",
            "           8       0.00      0.00      0.00       900\n",
            "           9       0.00      0.00      0.00       937\n",
            "          10       0.00      0.00      0.00      1007\n",
            "          11       0.00      0.00      0.00       889\n",
            "          12       0.00      0.00      0.00        28\n",
            "\n",
            "    accuracy                           0.53     13995\n",
            "   macro avg       0.04      0.08      0.05     13995\n",
            "weighted avg       0.28      0.53      0.36     13995\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00        79\n",
            "           2       0.53      1.00      0.69      7373\n",
            "           3       0.00      0.00      0.00       207\n",
            "           4       0.00      0.00      0.00      2126\n",
            "           5       0.50      0.12      0.20         8\n",
            "           6       0.00      0.00      0.00       419\n",
            "           7       0.00      0.00      0.00        20\n",
            "           8       0.00      0.00      0.00       900\n",
            "           9       0.00      0.00      0.00       938\n",
            "          10       0.00      0.00      0.00      1007\n",
            "          11       0.50      0.01      0.02       888\n",
            "          12       0.00      0.00      0.00        28\n",
            "\n",
            "    accuracy                           0.53     13995\n",
            "   macro avg       0.12      0.09      0.07     13995\n",
            "weighted avg       0.31      0.53      0.36     13995\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch.nn import LayerNorm\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Preprocess data (assumes this was defined earlier in your pipeline)\n",
        "def preprocess_data():\n",
        "    labeled_df = pd.read_csv('/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv')\n",
        "    smiles_files = glob.glob('/content/complexes_smiles/*_complexes_smiles.csv')\n",
        "    smiles_dfs = [pd.read_csv(file) for file in smiles_files]\n",
        "    all_smiles_df = pd.concat(smiles_dfs, ignore_index=True)\n",
        "\n",
        "    if all_smiles_df['refcode'].duplicated().any():\n",
        "        print(\"Warning: Duplicate refcodes found. Dropping duplicates.\")\n",
        "        all_smiles_df = all_smiles_df.drop_duplicates(subset='refcode')\n",
        "\n",
        "    merged_df = pd.merge(labeled_df, all_smiles_df[['refcode', 'SMILES']], on='refcode', how='inner')\n",
        "    print(f\"Number of merged entries: {len(merged_df)}\")\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    merged_df['geometry_encoded'] = le.fit_transform(merged_df['geometry'])\n",
        "    print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "    def smiles_to_graph(smiles):\n",
        "        try:\n",
        "            if isinstance(smiles, str) and smiles.startswith('['):\n",
        "                smiles = eval(smiles)[0]\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            if mol is None or mol.GetNumAtoms() == 0 or mol.GetNumBonds() == 0:\n",
        "                return None\n",
        "            AllChem.Compute2DCoords(mol)\n",
        "            # Features to match pretrained: atomic number, degree, charge\n",
        "            atom_features = [[atom.GetAtomicNum(), atom.GetDegree(), atom.GetFormalCharge()] for atom in mol.GetAtoms()]\n",
        "            edge_index = []\n",
        "            for bond in mol.GetBonds():\n",
        "                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                edge_index.extend([[i, j], [j, i]])\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "            x = torch.tensor(atom_features, dtype=torch.float)\n",
        "            return Data(x=x, edge_index=edge_index)\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing SMILES {smiles}: {e}\")\n",
        "            return None\n",
        "\n",
        "    merged_df['graph'] = merged_df['SMILES'].apply(smiles_to_graph)\n",
        "    valid_df = merged_df[merged_df['graph'].notnull()].copy()\n",
        "    print(f\"Number of valid graphs: {len(valid_df)}\")\n",
        "\n",
        "    valid_df['graph'] = [\n",
        "        Data(x=g.x, edge_index=g.edge_index, batch=torch.zeros(g.x.size(0), dtype=torch.long))\n",
        "        for g in valid_df['graph']\n",
        "        if g.edge_index.size(1) > 0\n",
        "    ]\n",
        "    valid_df = valid_df[valid_df['graph'].apply(lambda x: x is not None and x.edge_index.size(1) > 0)].copy()\n",
        "    print(f\"Number of valid graphs with edges: {len(valid_df)}\")\n",
        "\n",
        "    return valid_df, le\n",
        "\n",
        "# Load and preprocess data\n",
        "valid_df, le = preprocess_data()\n",
        "\n",
        "# Split data into fine-tune and train sets\n",
        "finetune_df, train_df = train_test_split(valid_df, test_size=0.8, random_state=42)\n",
        "finetune_graphs = finetune_df['graph'].tolist()\n",
        "finetune_labels = finetune_df['geometry_encoded'].tolist()\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Calculate class weights for imbalance\n",
        "class_counts = finetune_df['geometry_encoded'].value_counts()\n",
        "class_weights = (1.0 / torch.tensor([class_counts[i] for i in range(len(le.classes_))], dtype=torch.float)).to(device)\n",
        "class_weights = torch.clamp(class_weights, min=0.1, max=10.0)\n",
        "\n",
        "# Define GATTask Model to match pretrained architecture\n",
        "class GATTask(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes, dropout=0.3):\n",
        "        super(GATTask, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim_conv1, heads=4, concat=True, dropout=dropout)\n",
        "        self.norm1 = LayerNorm(hidden_dim_conv1 * 4)\n",
        "        self.conv2 = GATConv(hidden_dim_conv1 * 4, output_dim_conv2, heads=1, concat=True, dropout=dropout)\n",
        "        # Map conv2 output to a higher dimension for classification\n",
        "        self.mapping_layer = nn.Linear(output_dim_conv2, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = self.dropout(x)\n",
        "        x = F.elu(self.mapping_layer(x))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize GATTask model to match pretrained architecture\n",
        "input_dim = 3  # Match pretrained\n",
        "hidden_dim_conv1 = 32  # Match pretrained for conv1\n",
        "output_dim_conv2 = 3   # Match pretrained for conv2 (from GATPretrain output_dim)\n",
        "hidden_dim = 32        # Desired hidden dimension for classification\n",
        "num_classes = len(le.classes_)\n",
        "model_task = GATTask(input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes, dropout=0.3).to(device)\n",
        "\n",
        "# Load pretrained weights, excluding the fc layer\n",
        "try:\n",
        "    pretrained_dict = torch.load('/content/drive/MyDrive/pretrained_gat.pth', map_location=device)\n",
        "    model_dict = model_task.state_dict()\n",
        "    # Exclude layers that don't match (fc and mapping_layer)\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and not k.startswith('fc') and not k.startswith('mapping_layer')}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model_task.load_state_dict(model_dict)\n",
        "    print(\"Pretrained weights loaded successfully for layers:\", list(pretrained_dict.keys()))\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load pretrained weights: {e}. Initializing all layers randomly.\")\n",
        "\n",
        "print(\"The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\")\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = torch.optim.Adam(model_task.parameters(), lr=1e-4, weight_decay=5e-4) # weight_decay added\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define Fine-Tuning Function\n",
        "def finetune_epoch(graphs, labels):\n",
        "    model_task.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = torch.tensor([label], dtype=torch.long).to(device)\n",
        "\n",
        "        # Normalize input features (consistent with pretraining)\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model_task(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_task.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs during fine-tuning.\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Run Fine-Tuning for more epochs\n",
        "for epoch in range(20):\n",
        "    loss = finetune_epoch(finetune_graphs, finetune_labels)\n",
        "    print(f'Finetune Epoch {epoch+1}/20, Loss: {loss:.4f}')\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model_task.state_dict(), '/content/drive/MyDrive/finetuned_gat_32dim_3dim.pth')\n",
        "print(\"Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\")\n",
        "\n",
        "# Load the fine-tuned weights\n",
        "model_task.load_state_dict(torch.load('/content/drive/MyDrive/finetuned_gat_32dim_3dim.pth', map_location=device))\n",
        "print(\"Loaded fine-tuned weights for final training.\")\n",
        "\n",
        "# Prepare the training data for the final training phase\n",
        "train_graphs = train_df['graph'].tolist()\n",
        "train_labels = train_df['geometry_encoded'].tolist()\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "train_graphs, val_graphs, train_labels, val_labels = train_test_split(\n",
        "    train_graphs, train_labels, test_size=0.1, random_state=42  # 90% train, 10% validation\n",
        ")\n",
        "\n",
        "######################## START FINAL TRAINING ########################\n",
        "\n",
        "# Define the final training function\n",
        "def train_epoch(graphs, labels):\n",
        "    model_task.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = torch.tensor([label], dtype=torch.long).to(device)\n",
        "\n",
        "        # Normalize input features (consistent with pretraining)\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer_final.zero_grad()  # Use the final optimizer\n",
        "        out = model_task(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_task.parameters(), max_norm=1.0)\n",
        "        optimizer_final.step()  # Use the final optimizer\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs during training.\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Define validation function\n",
        "def validate(graphs, labels):\n",
        "    model_task.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "            if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "                skipped_graphs += 1\n",
        "                continue\n",
        "\n",
        "            data = data.to(device)\n",
        "\n",
        "            # Normalize input features (consistent with pretraining)\n",
        "            mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "            std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "            data.x = (data.x - mean) / std\n",
        "\n",
        "            out = model_task(data)\n",
        "            preds = torch.argmax(out, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.append(label)\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy\n",
        "\n",
        "# Final training loop\n",
        "num_epochs = 100  # Increased number of epochs\n",
        "best_val_accuracy = 0.0\n",
        "patience = 10  # Increased patience\n",
        "patience_counter = 0\n",
        "\n",
        "# Define optimizer and loss function for final training\n",
        "optimizer_final = torch.optim.Adam(model_task.parameters(), lr=5e-5, weight_decay=5e-4)  # Reduced learning rate, kept weight decay\n",
        "scheduler = ReduceLROnPlateau(optimizer_final, mode='max', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(train_graphs, train_labels)\n",
        "    val_accuracy = validate(val_graphs, val_labels)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Save the best model based on validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model_task.state_dict(), '/content/drive/MyDrive/best_final_gat.pth')\n",
        "        print(f\"Best model saved with validation accuracy: {best_val_accuracy:.4f}\")\n",
        "        patience_counter = 0  # Reset patience counter\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # Step the scheduler with validation accuracy\n",
        "    scheduler.step(val_accuracy)\n",
        "\n",
        "    # Early stopping check\n",
        "    if patience_counter >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "print(\"Finished final training.\")\n",
        "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "######################## END FINAL TRAINING ########################\n",
        "\n",
        "# Load the best model for final evaluation (optional, if you have a separate test set)\n",
        "model_task.load_state_dict(torch.load('/content/drive/MyDrive/best_final_gat.pth', map_location=device))\n",
        "\n",
        "# Evaluate on the validation set one last time (or replace with your test set)\n",
        "final_val_accuracy = validate(val_graphs, val_labels)\n",
        "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkhmSlZ9H6t-",
        "outputId": "883c9386-e2a3-4db7-a893-59961b0a864a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of merged entries: 82880\n",
            "Label mapping: {'bent': np.int64(0), 'linear': np.int64(1), 'octahedral': np.int64(2), 'planar_3': np.int64(3), 'planar_4': np.int64(4), 'planar_5': np.int64(5), 'prism': np.int64(6), 'pyramid_3': np.int64(7), 'pyramid_4': np.int64(8), 'pyramid_bi': np.int64(9), 'pyramid_sq': np.int64(10), 'tetrahedral': np.int64(11), 'tshape': np.int64(12)}\n",
            "Number of valid graphs: 69976\n",
            "Number of valid graphs with edges: 69976\n",
            "Using device: cpu\n",
            "Pretrained weights loaded successfully for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight']\n",
            "The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 1/20, Loss: 1.9446\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 2/20, Loss: 1.9174\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 3/20, Loss: 1.7907\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 4/20, Loss: 1.7778\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 5/20, Loss: 1.7732\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 6/20, Loss: 1.7695\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 7/20, Loss: 1.7603\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 8/20, Loss: 1.7459\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 9/20, Loss: 1.7413\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 10/20, Loss: 1.7166\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 11/20, Loss: 1.7274\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 12/20, Loss: 1.7232\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 13/20, Loss: 1.7150\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 14/20, Loss: 1.7153\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 15/20, Loss: 1.7148\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 16/20, Loss: 1.7152\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 17/20, Loss: 1.7119\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 18/20, Loss: 1.7113\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 19/20, Loss: 1.7083\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 20/20, Loss: 1.7080\n",
            "Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\n",
            "Loaded fine-tuned weights for final training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 1/100, Training Loss: 1.7076, Validation Accuracy: 0.5263\n",
            "Best model saved with validation accuracy: 0.5263\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 2/100, Training Loss: 1.7013, Validation Accuracy: 0.5315\n",
            "Best model saved with validation accuracy: 0.5315\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 3/100, Training Loss: 1.7043, Validation Accuracy: 0.5231\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 4/100, Training Loss: 1.7021, Validation Accuracy: 0.5231\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 5/100, Training Loss: 1.6996, Validation Accuracy: 0.5144\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 6/100, Training Loss: 1.7035, Validation Accuracy: 0.5167\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 7/100, Training Loss: 1.7015, Validation Accuracy: 0.5196\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 8/100, Training Loss: 1.7000, Validation Accuracy: 0.5210\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 9/100, Training Loss: 1.6998, Validation Accuracy: 0.5072\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 10/100, Training Loss: 1.7023, Validation Accuracy: 0.5078\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 11/100, Training Loss: 1.6998, Validation Accuracy: 0.5094\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 12/100, Training Loss: 1.7034, Validation Accuracy: 0.5060\n",
            "Early stopping triggered.\n",
            "Finished final training.\n",
            "Best Validation Accuracy: 0.5315\n",
            "Final Validation Accuracy: 0.5315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch.nn import LayerNorm\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from torch_geometric.data import Data\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Preprocess data\n",
        "def preprocess_data(limit=None):\n",
        "    labeled_df = pd.read_csv('/content/drive/MyDrive/ligand_metal_with_labels_clean2.csv')\n",
        "    smiles_files = glob.glob('/content/complexes_smiles/*_complexes_smiles.csv')\n",
        "    smiles_dfs = [pd.read_csv(file) for file in smiles_files]\n",
        "    all_smiles_df = pd.concat(smiles_dfs, ignore_index=True)\n",
        "\n",
        "    if all_smiles_df['refcode'].duplicated().any():\n",
        "        print(\"Warning: Duplicate refcodes found. Dropping duplicates.\")\n",
        "        all_smiles_df = all_smiles_df.drop_duplicates(subset='refcode')\n",
        "\n",
        "    merged_df = pd.merge(labeled_df, all_smiles_df[['refcode', 'SMILES']], on='refcode', how='inner')\n",
        "    print(f\"Number of merged entries: {len(merged_df)}\")\n",
        "\n",
        "    if limit:\n",
        "        merged_df = merged_df.head(limit)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    merged_df['geometry_encoded'] = le.fit_transform(merged_df['geometry'])\n",
        "    print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "    def smiles_to_graph(smiles):\n",
        "        try:\n",
        "            if isinstance(smiles, str) and smiles.startswith('['):\n",
        "                smiles = eval(smiles)[0]\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            if mol is None or mol.GetNumAtoms() == 0 or mol.GetNumBonds() == 0:\n",
        "                return None\n",
        "            AllChem.Compute2DCoords(mol)\n",
        "\n",
        "            atom_features = []\n",
        "            for atom in mol.GetAtoms():\n",
        "                atom_num = atom.GetAtomicNum()\n",
        "                degree = atom.GetDegree()\n",
        "                charge = atom.GetFormalCharge()\n",
        "                hybridization = atom.GetHybridization()\n",
        "                aromatic = atom.GetIsAromatic()\n",
        "                num_Hs = atom.GetTotalNumHs()\n",
        "\n",
        "                atom_features.append([atom_num, degree, charge, hybridization.real, aromatic, num_Hs])\n",
        "\n",
        "            edge_index = []\n",
        "            for bond in mol.GetBonds():\n",
        "                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                edge_index.extend([[i, j], [j, i]])\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "            x = torch.tensor(atom_features, dtype=torch.float)\n",
        "            return Data(x=x, edge_index=edge_index)\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing SMILES {smiles}: {e}\")\n",
        "            return None\n",
        "\n",
        "    merged_df['graph'] = merged_df['SMILES'].apply(smiles_to_graph)\n",
        "    valid_df = merged_df[merged_df['graph'].notnull()].copy()\n",
        "    print(f\"Number of valid graphs: {len(valid_df)}\")\n",
        "\n",
        "    valid_df['graph'] = [\n",
        "        Data(x=g.x, edge_index=g.edge_index, batch=torch.zeros(g.x.size(0), dtype=torch.long))\n",
        "        for g in valid_df['graph']\n",
        "        if g.edge_index.size(1) > 0\n",
        "    ]\n",
        "    valid_df = valid_df[valid_df['graph'].apply(lambda x: x is not None and x.edge_index.size(1) > 0)].copy()\n",
        "    print(f\"Number of valid graphs with edges: {len(valid_df)}\")\n",
        "\n",
        "    return valid_df, le\n",
        "\n",
        "# Load and preprocess data\n",
        "valid_df, le = preprocess_data()\n",
        "\n",
        "# Split data into fine-tune and train sets\n",
        "finetune_df, train_df = train_test_split(valid_df, test_size=0.8, random_state=42)\n",
        "finetune_graphs = finetune_df['graph'].tolist()\n",
        "finetune_labels = finetune_df['geometry_encoded'].tolist()\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Calculate class weights for imbalance\n",
        "class_counts = finetune_df['geometry_encoded'].value_counts()\n",
        "class_weights = (1.0 / torch.tensor([class_counts[i] for i in range(len(le.classes_))], dtype=torch.float)).to(device)\n",
        "class_weights = torch.clamp(class_weights, min=0.1, max=10.0)\n",
        "\n",
        "# Define GATTask Model\n",
        "class GATTask(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes, dropout=0.3):\n",
        "        super(GATTask, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim_conv1 // 4, heads=4, concat=True, dropout=dropout)\n",
        "        self.norm1 = LayerNorm(hidden_dim_conv1)\n",
        "        self.conv2 = GATConv(hidden_dim_conv1, output_dim_conv2, heads=1, concat=True, dropout=dropout)\n",
        "        self.norm2 = LayerNorm(output_dim_conv2)\n",
        "\n",
        "        self.mapping_layer = nn.Linear(output_dim_conv2, hidden_dim)\n",
        "        self.norm_mapping = LayerNorm(hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.norm1(x)\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = self.norm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.elu(self.mapping_layer(x))\n",
        "        x = self.norm_mapping(x)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize GATTask model\n",
        "input_dim = 6\n",
        "hidden_dim_conv1 = 128\n",
        "output_dim_conv2 = 3\n",
        "hidden_dim = 64\n",
        "num_classes = len(le.classes_)\n",
        "model_task = GATTask(input_dim, hidden_dim_conv1, output_dim_conv2, hidden_dim, num_classes, dropout=0.5).to(device)\n",
        "\n",
        "# Load pretrained weights\n",
        "try:\n",
        "    pretrained_dict = torch.load('/content/drive/MyDrive/pretrained_gat.pth', map_location=device)\n",
        "    model_dict = model_task.state_dict()\n",
        "\n",
        "    # Adapt the first convolutional layer weights\n",
        "    conv1_weight = pretrained_dict['conv1.lin.weight']\n",
        "    new_conv1_weight = torch.zeros(128, 6)\n",
        "    new_conv1_weight[:, :3] = conv1_weight\n",
        "    pretrained_dict['conv1.lin.weight'] = new_conv1_weight\n",
        "\n",
        "    # Filter out layers that don't match\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and not k.startswith('fc') and not k.startswith('mapping_layer')}\n",
        "\n",
        "    # Update the model state dict\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model_task.load_state_dict(model_dict)\n",
        "    print(\"Pretrained weights loaded successfully for layers:\", list(pretrained_dict.keys()))\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load pretrained weights: {e}. Initializing all layers randomly.\")\n",
        "\n",
        "print(\"The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\")\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = torch.optim.AdamW(model_task.parameters(), lr=5e-4, weight_decay=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Define Fine-Tuning Function\n",
        "def finetune_epoch(graphs, labels, epoch):\n",
        "    model_task.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = torch.tensor([label], dtype=torch.long).to(device)\n",
        "\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model_task(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_task.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f\"Finetune Epoch {epoch+1}, Graph {i+1}/{len(graphs)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs during fine-tuning.\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "# Run Fine-Tuning\n",
        "num_finetune_epochs = 30\n",
        "for epoch in range(num_finetune_epochs):\n",
        "    loss = finetune_epoch(finetune_graphs, finetune_labels, epoch)\n",
        "    print(f'Finetune Epoch {epoch+1}/{num_finetune_epochs}, Loss: {loss:.4f}')\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model_task.state_dict(), '/content/drive/MyDrive/finetuned_gat_32dim_3dim.pth')\n",
        "print(\"Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\")\n",
        "\n",
        "# Load the fine-tuned weights\n",
        "model_task.load_state_dict(torch.load('/content/drive/MyDrive/finetuned_gat_32dim_3dim.pth', map_location=device))\n",
        "print(\"Loaded fine-tuned weights for final training.\")\n",
        "\n",
        "# Prepare the training data for the final training phase\n",
        "train_graphs = train_df['graph'].tolist()\n",
        "train_labels = train_df['geometry_encoded'].tolist()\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "train_graphs, val_graphs, train_labels, val_labels = train_test_split(\n",
        "    train_graphs, train_labels, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Define the final training function\n",
        "def train_epoch(graphs, labels, epoch):\n",
        "    model_task.train()\n",
        "    total_loss = 0\n",
        "    valid_graphs = 0\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to empty graph or no nodes/edges\")\n",
        "            continue\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = torch.tensor([label], dtype=torch.long).to(device)\n",
        "\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        if torch.isnan(data.x).any() or torch.isinf(data.x).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in input\")\n",
        "            continue\n",
        "\n",
        "        optimizer_final.zero_grad()\n",
        "        out = model_task(data)\n",
        "\n",
        "        if torch.isnan(out).any() or torch.isinf(out).any():\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to NaN or Inf in output\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            skipped_graphs += 1\n",
        "            print(f\"Skipping graph {i} due to invalid loss: {loss}\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_task.parameters(), max_norm=1.0)\n",
        "        optimizer_final.step()\n",
        "        total_loss += loss.item()\n",
        "        valid_graphs += 1\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f\"Final Train Epoch {epoch+1}, Graph {i+1}/{len(graphs)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Skipped {skipped_graphs} out of {len(graphs)} graphs during training.\")\n",
        "    return total_loss / max(1, valid_graphs)\n",
        "\n",
        "\n",
        "# Define validation function\n",
        "def validate(graphs, labels):\n",
        "    model_task.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    skipped_graphs = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data, label) in enumerate(zip(graphs, labels)):\n",
        "            if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "                skipped_graphs += 1\n",
        "                continue\n",
        "\n",
        "            data = data.to(device)\n",
        "\n",
        "            mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "            std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "            data.x = (data.x - mean) / std\n",
        "\n",
        "            out = model_task(data)\n",
        "            preds = torch.argmax(out, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.append(label)\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy\n",
        "\n",
        "# Final training loop\n",
        "num_epochs = 200\n",
        "best_val_accuracy = 0.0\n",
        "patience = 15\n",
        "patience_counter = 0\n",
        "\n",
        "# Define optimizer and loss function for final training\n",
        "optimizer_final = torch.optim.AdamW(model_task.parameters(), lr=3e-5, weight_decay=1e-3)\n",
        "scheduler = ReduceLROnPlateau(optimizer_final, mode='max', factor=0.5, patience=7, verbose=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(train_graphs, train_labels, epoch)\n",
        "    val_accuracy = validate(val_graphs, val_labels)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Save the best model based on validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model_task.state_dict(), '/content/drive/MyDrive/best_final_gat.pth')\n",
        "        print(f\"Best model saved with validation accuracy: {best_val_accuracy:.4f}\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # Step the scheduler with validation accuracy\n",
        "    scheduler.step(val_accuracy)\n",
        "\n",
        "    # Early stopping check\n",
        "    if patience_counter >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "print(\"Finished final training.\")\n",
        "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "# Load the best model for final evaluation\n",
        "model_task.load_state_dict(torch.load('/content/drive/MyDrive/best_final_gat.pth', map_location=device))\n",
        "\n",
        "# Evaluate on the validation set one last time\n",
        "final_val_accuracy = validate(val_graphs, val_labels)\n",
        "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "model_task.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (data, label) in enumerate(zip(val_graphs, val_labels)):\n",
        "        if data.edge_index.size(1) == 0 or data.x is None or data.x.size(0) == 0:\n",
        "            continue\n",
        "        data = data.to(device)\n",
        "\n",
        "        mean = torch.mean(data.x, dim=0, keepdim=True)\n",
        "        std = torch.std(data.x, dim=0, keepdim=True) + 1e-7\n",
        "        data.x = (data.x - mean) / std\n",
        "\n",
        "        out = model_task(data)\n",
        "        preds = torch.argmax(out, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.append(label)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=le.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t7HHdm4g0Xjs",
        "outputId": "68d647b8-5056-4097-e7d6-cf61386da974"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of merged entries: 82880\n",
            "Label mapping: {'bent': np.int64(0), 'linear': np.int64(1), 'octahedral': np.int64(2), 'planar_3': np.int64(3), 'planar_4': np.int64(4), 'planar_5': np.int64(5), 'prism': np.int64(6), 'pyramid_3': np.int64(7), 'pyramid_4': np.int64(8), 'pyramid_bi': np.int64(9), 'pyramid_sq': np.int64(10), 'tetrahedral': np.int64(11), 'tshape': np.int64(12)}\n",
            "Number of valid graphs: 69976\n",
            "Number of valid graphs with edges: 69976\n",
            "Using device: cpu\n",
            "Pretrained weights loaded successfully for layers: ['conv1.att_src', 'conv1.att_dst', 'conv1.bias', 'conv1.lin.weight', 'norm1.weight', 'norm1.bias', 'conv2.att_src', 'conv2.att_dst', 'conv2.bias', 'conv2.lin.weight']\n",
            "The mapping_layer and fc layer are randomly initialized for task-specific fine-tuning.\n",
            "Finetune Epoch 1, Graph 500/13995, Loss: 0.0662\n",
            "Finetune Epoch 1, Graph 1000/13995, Loss: 3.7820\n",
            "Finetune Epoch 1, Graph 1500/13995, Loss: 0.0476\n",
            "Finetune Epoch 1, Graph 2000/13995, Loss: 0.0904\n",
            "Finetune Epoch 1, Graph 2500/13995, Loss: 3.3711\n",
            "Finetune Epoch 1, Graph 3000/13995, Loss: 4.5191\n",
            "Finetune Epoch 1, Graph 3500/13995, Loss: 3.5041\n",
            "Finetune Epoch 1, Graph 4000/13995, Loss: 3.9876\n",
            "Finetune Epoch 1, Graph 4500/13995, Loss: 4.9296\n",
            "Finetune Epoch 1, Graph 5000/13995, Loss: 0.1545\n",
            "Finetune Epoch 1, Graph 5500/13995, Loss: 2.6223\n",
            "Finetune Epoch 1, Graph 6000/13995, Loss: 0.0231\n",
            "Finetune Epoch 1, Graph 6500/13995, Loss: 0.2534\n",
            "Finetune Epoch 1, Graph 7000/13995, Loss: 0.0275\n",
            "Finetune Epoch 1, Graph 7500/13995, Loss: 4.6517\n",
            "Finetune Epoch 1, Graph 8000/13995, Loss: 3.6611\n",
            "Finetune Epoch 1, Graph 8500/13995, Loss: 0.0778\n",
            "Finetune Epoch 1, Graph 9000/13995, Loss: 0.0637\n",
            "Finetune Epoch 1, Graph 9500/13995, Loss: 4.4280\n",
            "Finetune Epoch 1, Graph 10000/13995, Loss: 0.0336\n",
            "Finetune Epoch 1, Graph 10500/13995, Loss: 0.0235\n",
            "Finetune Epoch 1, Graph 11000/13995, Loss: 3.8216\n",
            "Finetune Epoch 1, Graph 11500/13995, Loss: 2.0489\n",
            "Finetune Epoch 1, Graph 12000/13995, Loss: 0.1932\n",
            "Finetune Epoch 1, Graph 12500/13995, Loss: 0.0261\n",
            "Finetune Epoch 1, Graph 13000/13995, Loss: 0.0679\n",
            "Finetune Epoch 1, Graph 13500/13995, Loss: 0.0442\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 1/30, Loss: 1.9283\n",
            "Finetune Epoch 2, Graph 500/13995, Loss: 0.0848\n",
            "Finetune Epoch 2, Graph 1000/13995, Loss: 4.1223\n",
            "Finetune Epoch 2, Graph 1500/13995, Loss: 0.0332\n",
            "Finetune Epoch 2, Graph 2000/13995, Loss: 0.0221\n",
            "Finetune Epoch 2, Graph 2500/13995, Loss: 3.2524\n",
            "Finetune Epoch 2, Graph 3000/13995, Loss: 4.3390\n",
            "Finetune Epoch 2, Graph 3500/13995, Loss: 2.6973\n",
            "Finetune Epoch 2, Graph 4000/13995, Loss: 5.4177\n",
            "Finetune Epoch 2, Graph 4500/13995, Loss: 5.1996\n",
            "Finetune Epoch 2, Graph 5000/13995, Loss: 0.5998\n",
            "Finetune Epoch 2, Graph 5500/13995, Loss: 2.3343\n",
            "Finetune Epoch 2, Graph 6000/13995, Loss: 0.0176\n",
            "Finetune Epoch 2, Graph 6500/13995, Loss: 0.0823\n",
            "Finetune Epoch 2, Graph 7000/13995, Loss: 0.0339\n",
            "Finetune Epoch 2, Graph 7500/13995, Loss: 4.1484\n",
            "Finetune Epoch 2, Graph 8000/13995, Loss: 2.1383\n",
            "Finetune Epoch 2, Graph 8500/13995, Loss: 0.0385\n",
            "Finetune Epoch 2, Graph 9000/13995, Loss: 0.3713\n",
            "Finetune Epoch 2, Graph 9500/13995, Loss: 1.9239\n",
            "Finetune Epoch 2, Graph 10000/13995, Loss: 0.0201\n",
            "Finetune Epoch 2, Graph 10500/13995, Loss: 0.0290\n",
            "Finetune Epoch 2, Graph 11000/13995, Loss: 1.7681\n",
            "Finetune Epoch 2, Graph 11500/13995, Loss: 1.5508\n",
            "Finetune Epoch 2, Graph 12000/13995, Loss: 0.0194\n",
            "Finetune Epoch 2, Graph 12500/13995, Loss: 0.0191\n",
            "Finetune Epoch 2, Graph 13000/13995, Loss: 0.0459\n",
            "Finetune Epoch 2, Graph 13500/13995, Loss: 0.1055\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 2/30, Loss: 1.7790\n",
            "Finetune Epoch 3, Graph 500/13995, Loss: 0.1502\n",
            "Finetune Epoch 3, Graph 1000/13995, Loss: 3.7695\n",
            "Finetune Epoch 3, Graph 1500/13995, Loss: 0.0211\n",
            "Finetune Epoch 3, Graph 2000/13995, Loss: 0.0622\n",
            "Finetune Epoch 3, Graph 2500/13995, Loss: 2.2614\n",
            "Finetune Epoch 3, Graph 3000/13995, Loss: 4.6672\n",
            "Finetune Epoch 3, Graph 3500/13995, Loss: 2.7823\n",
            "Finetune Epoch 3, Graph 4000/13995, Loss: 5.2530\n",
            "Finetune Epoch 3, Graph 4500/13995, Loss: 5.3215\n",
            "Finetune Epoch 3, Graph 5000/13995, Loss: 0.0220\n",
            "Finetune Epoch 3, Graph 5500/13995, Loss: 2.4838\n",
            "Finetune Epoch 3, Graph 6000/13995, Loss: 0.0211\n",
            "Finetune Epoch 3, Graph 6500/13995, Loss: 0.4656\n",
            "Finetune Epoch 3, Graph 7000/13995, Loss: 0.0543\n",
            "Finetune Epoch 3, Graph 7500/13995, Loss: 4.6140\n",
            "Finetune Epoch 3, Graph 8000/13995, Loss: 2.1062\n",
            "Finetune Epoch 3, Graph 8500/13995, Loss: 0.0342\n",
            "Finetune Epoch 3, Graph 9000/13995, Loss: 0.3630\n",
            "Finetune Epoch 3, Graph 9500/13995, Loss: 2.4508\n",
            "Finetune Epoch 3, Graph 10000/13995, Loss: 0.0334\n",
            "Finetune Epoch 3, Graph 10500/13995, Loss: 0.0300\n",
            "Finetune Epoch 3, Graph 11000/13995, Loss: 2.6716\n",
            "Finetune Epoch 3, Graph 11500/13995, Loss: 2.3111\n",
            "Finetune Epoch 3, Graph 12000/13995, Loss: 0.0282\n",
            "Finetune Epoch 3, Graph 12500/13995, Loss: 0.0114\n",
            "Finetune Epoch 3, Graph 13000/13995, Loss: 0.0309\n",
            "Finetune Epoch 3, Graph 13500/13995, Loss: 0.0275\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 3/30, Loss: 1.7531\n",
            "Finetune Epoch 4, Graph 500/13995, Loss: 0.1810\n",
            "Finetune Epoch 4, Graph 1000/13995, Loss: 3.4560\n",
            "Finetune Epoch 4, Graph 1500/13995, Loss: 0.0288\n",
            "Finetune Epoch 4, Graph 2000/13995, Loss: 0.0507\n",
            "Finetune Epoch 4, Graph 2500/13995, Loss: 1.2475\n",
            "Finetune Epoch 4, Graph 3000/13995, Loss: 4.2520\n",
            "Finetune Epoch 4, Graph 3500/13995, Loss: 3.1875\n",
            "Finetune Epoch 4, Graph 4000/13995, Loss: 4.9660\n",
            "Finetune Epoch 4, Graph 4500/13995, Loss: 4.3030\n",
            "Finetune Epoch 4, Graph 5000/13995, Loss: 0.0594\n",
            "Finetune Epoch 4, Graph 5500/13995, Loss: 2.4747\n",
            "Finetune Epoch 4, Graph 6000/13995, Loss: 0.0967\n",
            "Finetune Epoch 4, Graph 6500/13995, Loss: 0.1144\n",
            "Finetune Epoch 4, Graph 7000/13995, Loss: 0.0458\n",
            "Finetune Epoch 4, Graph 7500/13995, Loss: 4.2311\n",
            "Finetune Epoch 4, Graph 8000/13995, Loss: 2.1053\n",
            "Finetune Epoch 4, Graph 8500/13995, Loss: 0.0830\n",
            "Finetune Epoch 4, Graph 9000/13995, Loss: 0.3455\n",
            "Finetune Epoch 4, Graph 9500/13995, Loss: 2.2197\n",
            "Finetune Epoch 4, Graph 10000/13995, Loss: 0.0389\n",
            "Finetune Epoch 4, Graph 10500/13995, Loss: 0.0348\n",
            "Finetune Epoch 4, Graph 11000/13995, Loss: 2.3260\n",
            "Finetune Epoch 4, Graph 11500/13995, Loss: 1.7387\n",
            "Finetune Epoch 4, Graph 12000/13995, Loss: 0.0639\n",
            "Finetune Epoch 4, Graph 12500/13995, Loss: 0.0312\n",
            "Finetune Epoch 4, Graph 13000/13995, Loss: 0.0566\n",
            "Finetune Epoch 4, Graph 13500/13995, Loss: 0.0359\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 4/30, Loss: 1.7422\n",
            "Finetune Epoch 5, Graph 500/13995, Loss: 1.1728\n",
            "Finetune Epoch 5, Graph 1000/13995, Loss: 3.7219\n",
            "Finetune Epoch 5, Graph 1500/13995, Loss: 0.0238\n",
            "Finetune Epoch 5, Graph 2000/13995, Loss: 0.1588\n",
            "Finetune Epoch 5, Graph 2500/13995, Loss: 1.8921\n",
            "Finetune Epoch 5, Graph 3000/13995, Loss: 5.0891\n",
            "Finetune Epoch 5, Graph 3500/13995, Loss: 3.0841\n",
            "Finetune Epoch 5, Graph 4000/13995, Loss: 4.6664\n",
            "Finetune Epoch 5, Graph 4500/13995, Loss: 5.1747\n",
            "Finetune Epoch 5, Graph 5000/13995, Loss: 0.0281\n",
            "Finetune Epoch 5, Graph 5500/13995, Loss: 2.4765\n",
            "Finetune Epoch 5, Graph 6000/13995, Loss: 0.1255\n",
            "Finetune Epoch 5, Graph 6500/13995, Loss: 1.8342\n",
            "Finetune Epoch 5, Graph 7000/13995, Loss: 0.0206\n",
            "Finetune Epoch 5, Graph 7500/13995, Loss: 4.3882\n",
            "Finetune Epoch 5, Graph 8000/13995, Loss: 2.0837\n",
            "Finetune Epoch 5, Graph 8500/13995, Loss: 0.0520\n",
            "Finetune Epoch 5, Graph 9000/13995, Loss: 0.1021\n",
            "Finetune Epoch 5, Graph 9500/13995, Loss: 2.0250\n",
            "Finetune Epoch 5, Graph 10000/13995, Loss: 0.0425\n",
            "Finetune Epoch 5, Graph 10500/13995, Loss: 0.0441\n",
            "Finetune Epoch 5, Graph 11000/13995, Loss: 2.2200\n",
            "Finetune Epoch 5, Graph 11500/13995, Loss: 2.0240\n",
            "Finetune Epoch 5, Graph 12000/13995, Loss: 0.0455\n",
            "Finetune Epoch 5, Graph 12500/13995, Loss: 0.0235\n",
            "Finetune Epoch 5, Graph 13000/13995, Loss: 0.0456\n",
            "Finetune Epoch 5, Graph 13500/13995, Loss: 0.0845\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 5/30, Loss: 1.7358\n",
            "Finetune Epoch 6, Graph 500/13995, Loss: 0.4787\n",
            "Finetune Epoch 6, Graph 1000/13995, Loss: 3.5115\n",
            "Finetune Epoch 6, Graph 1500/13995, Loss: 0.0344\n",
            "Finetune Epoch 6, Graph 2000/13995, Loss: 0.1389\n",
            "Finetune Epoch 6, Graph 2500/13995, Loss: 1.2584\n",
            "Finetune Epoch 6, Graph 3000/13995, Loss: 4.9265\n",
            "Finetune Epoch 6, Graph 3500/13995, Loss: 2.6198\n",
            "Finetune Epoch 6, Graph 4000/13995, Loss: 4.8370\n",
            "Finetune Epoch 6, Graph 4500/13995, Loss: 2.5022\n",
            "Finetune Epoch 6, Graph 5000/13995, Loss: 0.0389\n",
            "Finetune Epoch 6, Graph 5500/13995, Loss: 2.7541\n",
            "Finetune Epoch 6, Graph 6000/13995, Loss: 0.0267\n",
            "Finetune Epoch 6, Graph 6500/13995, Loss: 0.5215\n",
            "Finetune Epoch 6, Graph 7000/13995, Loss: 0.0199\n",
            "Finetune Epoch 6, Graph 7500/13995, Loss: 4.2958\n",
            "Finetune Epoch 6, Graph 8000/13995, Loss: 2.0815\n",
            "Finetune Epoch 6, Graph 8500/13995, Loss: 0.0487\n",
            "Finetune Epoch 6, Graph 9000/13995, Loss: 0.6043\n",
            "Finetune Epoch 6, Graph 9500/13995, Loss: 1.7663\n",
            "Finetune Epoch 6, Graph 10000/13995, Loss: 0.0556\n",
            "Finetune Epoch 6, Graph 10500/13995, Loss: 0.0357\n",
            "Finetune Epoch 6, Graph 11000/13995, Loss: 1.9163\n",
            "Finetune Epoch 6, Graph 11500/13995, Loss: 2.2653\n",
            "Finetune Epoch 6, Graph 12000/13995, Loss: 0.0413\n",
            "Finetune Epoch 6, Graph 12500/13995, Loss: 0.0289\n",
            "Finetune Epoch 6, Graph 13000/13995, Loss: 0.0325\n",
            "Finetune Epoch 6, Graph 13500/13995, Loss: 0.1873\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 6/30, Loss: 1.7214\n",
            "Finetune Epoch 7, Graph 500/13995, Loss: 1.1045\n",
            "Finetune Epoch 7, Graph 1000/13995, Loss: 3.1220\n",
            "Finetune Epoch 7, Graph 1500/13995, Loss: 0.0374\n",
            "Finetune Epoch 7, Graph 2000/13995, Loss: 0.2028\n",
            "Finetune Epoch 7, Graph 2500/13995, Loss: 3.5756\n",
            "Finetune Epoch 7, Graph 3000/13995, Loss: 4.8700\n",
            "Finetune Epoch 7, Graph 3500/13995, Loss: 2.5577\n",
            "Finetune Epoch 7, Graph 4000/13995, Loss: 4.2962\n",
            "Finetune Epoch 7, Graph 4500/13995, Loss: 4.7777\n",
            "Finetune Epoch 7, Graph 5000/13995, Loss: 0.0365\n",
            "Finetune Epoch 7, Graph 5500/13995, Loss: 2.7115\n",
            "Finetune Epoch 7, Graph 6000/13995, Loss: 0.0377\n",
            "Finetune Epoch 7, Graph 6500/13995, Loss: 0.1415\n",
            "Finetune Epoch 7, Graph 7000/13995, Loss: 0.0254\n",
            "Finetune Epoch 7, Graph 7500/13995, Loss: 4.2842\n",
            "Finetune Epoch 7, Graph 8000/13995, Loss: 2.1109\n",
            "Finetune Epoch 7, Graph 8500/13995, Loss: 0.0761\n",
            "Finetune Epoch 7, Graph 9000/13995, Loss: 0.1770\n",
            "Finetune Epoch 7, Graph 9500/13995, Loss: 2.0493\n",
            "Finetune Epoch 7, Graph 10000/13995, Loss: 0.0206\n",
            "Finetune Epoch 7, Graph 10500/13995, Loss: 0.0326\n",
            "Finetune Epoch 7, Graph 11000/13995, Loss: 2.1850\n",
            "Finetune Epoch 7, Graph 11500/13995, Loss: 3.3414\n",
            "Finetune Epoch 7, Graph 12000/13995, Loss: 0.0422\n",
            "Finetune Epoch 7, Graph 12500/13995, Loss: 0.0191\n",
            "Finetune Epoch 7, Graph 13000/13995, Loss: 0.0279\n",
            "Finetune Epoch 7, Graph 13500/13995, Loss: 0.2418\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 7/30, Loss: 1.7061\n",
            "Finetune Epoch 8, Graph 500/13995, Loss: 0.2247\n",
            "Finetune Epoch 8, Graph 1000/13995, Loss: 3.3443\n",
            "Finetune Epoch 8, Graph 1500/13995, Loss: 0.0684\n",
            "Finetune Epoch 8, Graph 2000/13995, Loss: 0.5188\n",
            "Finetune Epoch 8, Graph 2500/13995, Loss: 2.4441\n",
            "Finetune Epoch 8, Graph 3000/13995, Loss: 4.2343\n",
            "Finetune Epoch 8, Graph 3500/13995, Loss: 2.8850\n",
            "Finetune Epoch 8, Graph 4000/13995, Loss: 4.1481\n",
            "Finetune Epoch 8, Graph 4500/13995, Loss: 4.4013\n",
            "Finetune Epoch 8, Graph 5000/13995, Loss: 0.0556\n",
            "Finetune Epoch 8, Graph 5500/13995, Loss: 2.5793\n",
            "Finetune Epoch 8, Graph 6000/13995, Loss: 0.0311\n",
            "Finetune Epoch 8, Graph 6500/13995, Loss: 0.1939\n",
            "Finetune Epoch 8, Graph 7000/13995, Loss: 0.0315\n",
            "Finetune Epoch 8, Graph 7500/13995, Loss: 4.3322\n",
            "Finetune Epoch 8, Graph 8000/13995, Loss: 2.0704\n",
            "Finetune Epoch 8, Graph 8500/13995, Loss: 0.0672\n",
            "Finetune Epoch 8, Graph 9000/13995, Loss: 0.0802\n",
            "Finetune Epoch 8, Graph 9500/13995, Loss: 2.1899\n",
            "Finetune Epoch 8, Graph 10000/13995, Loss: 0.0350\n",
            "Finetune Epoch 8, Graph 10500/13995, Loss: 0.0372\n",
            "Finetune Epoch 8, Graph 11000/13995, Loss: 2.2292\n",
            "Finetune Epoch 8, Graph 11500/13995, Loss: 1.9419\n",
            "Finetune Epoch 8, Graph 12000/13995, Loss: 0.0371\n",
            "Finetune Epoch 8, Graph 12500/13995, Loss: 0.0320\n",
            "Finetune Epoch 8, Graph 13000/13995, Loss: 0.0352\n",
            "Finetune Epoch 8, Graph 13500/13995, Loss: 0.2231\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 8/30, Loss: 1.7030\n",
            "Finetune Epoch 9, Graph 500/13995, Loss: 0.3863\n",
            "Finetune Epoch 9, Graph 1000/13995, Loss: 3.6673\n",
            "Finetune Epoch 9, Graph 1500/13995, Loss: 0.0259\n",
            "Finetune Epoch 9, Graph 2000/13995, Loss: 0.0917\n",
            "Finetune Epoch 9, Graph 2500/13995, Loss: 1.6234\n",
            "Finetune Epoch 9, Graph 3000/13995, Loss: 4.1726\n",
            "Finetune Epoch 9, Graph 3500/13995, Loss: 3.0481\n",
            "Finetune Epoch 9, Graph 4000/13995, Loss: 4.7289\n",
            "Finetune Epoch 9, Graph 4500/13995, Loss: 4.7284\n",
            "Finetune Epoch 9, Graph 5000/13995, Loss: 0.0478\n",
            "Finetune Epoch 9, Graph 5500/13995, Loss: 2.5468\n",
            "Finetune Epoch 9, Graph 6000/13995, Loss: 0.0349\n",
            "Finetune Epoch 9, Graph 6500/13995, Loss: 2.1680\n",
            "Finetune Epoch 9, Graph 7000/13995, Loss: 0.0399\n",
            "Finetune Epoch 9, Graph 7500/13995, Loss: 4.4232\n",
            "Finetune Epoch 9, Graph 8000/13995, Loss: 2.1996\n",
            "Finetune Epoch 9, Graph 8500/13995, Loss: 0.0489\n",
            "Finetune Epoch 9, Graph 9000/13995, Loss: 0.6963\n",
            "Finetune Epoch 9, Graph 9500/13995, Loss: 1.7718\n",
            "Finetune Epoch 9, Graph 10000/13995, Loss: 0.0324\n",
            "Finetune Epoch 9, Graph 10500/13995, Loss: 0.0309\n",
            "Finetune Epoch 9, Graph 11000/13995, Loss: 2.7708\n",
            "Finetune Epoch 9, Graph 11500/13995, Loss: 2.1593\n",
            "Finetune Epoch 9, Graph 12000/13995, Loss: 0.0323\n",
            "Finetune Epoch 9, Graph 12500/13995, Loss: 0.0224\n",
            "Finetune Epoch 9, Graph 13000/13995, Loss: 0.0787\n",
            "Finetune Epoch 9, Graph 13500/13995, Loss: 0.0478\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 9/30, Loss: 1.6839\n",
            "Finetune Epoch 10, Graph 500/13995, Loss: 0.0521\n",
            "Finetune Epoch 10, Graph 1000/13995, Loss: 3.4801\n",
            "Finetune Epoch 10, Graph 1500/13995, Loss: 0.0534\n",
            "Finetune Epoch 10, Graph 2000/13995, Loss: 0.1844\n",
            "Finetune Epoch 10, Graph 2500/13995, Loss: 2.3153\n",
            "Finetune Epoch 10, Graph 3000/13995, Loss: 4.5864\n",
            "Finetune Epoch 10, Graph 3500/13995, Loss: 2.8184\n",
            "Finetune Epoch 10, Graph 4000/13995, Loss: 4.5155\n",
            "Finetune Epoch 10, Graph 4500/13995, Loss: 4.5041\n",
            "Finetune Epoch 10, Graph 5000/13995, Loss: 0.0611\n",
            "Finetune Epoch 10, Graph 5500/13995, Loss: 2.5831\n",
            "Finetune Epoch 10, Graph 6000/13995, Loss: 0.0320\n",
            "Finetune Epoch 10, Graph 6500/13995, Loss: 1.4557\n",
            "Finetune Epoch 10, Graph 7000/13995, Loss: 0.0255\n",
            "Finetune Epoch 10, Graph 7500/13995, Loss: 4.1326\n",
            "Finetune Epoch 10, Graph 8000/13995, Loss: 2.1271\n",
            "Finetune Epoch 10, Graph 8500/13995, Loss: 0.0750\n",
            "Finetune Epoch 10, Graph 9000/13995, Loss: 0.2915\n",
            "Finetune Epoch 10, Graph 9500/13995, Loss: 1.8943\n",
            "Finetune Epoch 10, Graph 10000/13995, Loss: 0.0349\n",
            "Finetune Epoch 10, Graph 10500/13995, Loss: 0.0465\n",
            "Finetune Epoch 10, Graph 11000/13995, Loss: 3.1070\n",
            "Finetune Epoch 10, Graph 11500/13995, Loss: 1.6278\n",
            "Finetune Epoch 10, Graph 12000/13995, Loss: 0.0513\n",
            "Finetune Epoch 10, Graph 12500/13995, Loss: 0.0334\n",
            "Finetune Epoch 10, Graph 13000/13995, Loss: 0.0393\n",
            "Finetune Epoch 10, Graph 13500/13995, Loss: 0.0447\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 10/30, Loss: 1.6866\n",
            "Finetune Epoch 11, Graph 500/13995, Loss: 0.0771\n",
            "Finetune Epoch 11, Graph 1000/13995, Loss: 3.2637\n",
            "Finetune Epoch 11, Graph 1500/13995, Loss: 0.0367\n",
            "Finetune Epoch 11, Graph 2000/13995, Loss: 0.1901\n",
            "Finetune Epoch 11, Graph 2500/13995, Loss: 1.7402\n",
            "Finetune Epoch 11, Graph 3000/13995, Loss: 4.5925\n",
            "Finetune Epoch 11, Graph 3500/13995, Loss: 2.9661\n",
            "Finetune Epoch 11, Graph 4000/13995, Loss: 4.0385\n",
            "Finetune Epoch 11, Graph 4500/13995, Loss: 5.3060\n",
            "Finetune Epoch 11, Graph 5000/13995, Loss: 0.0543\n",
            "Finetune Epoch 11, Graph 5500/13995, Loss: 2.8604\n",
            "Finetune Epoch 11, Graph 6000/13995, Loss: 0.0344\n",
            "Finetune Epoch 11, Graph 6500/13995, Loss: 1.1239\n",
            "Finetune Epoch 11, Graph 7000/13995, Loss: 0.0211\n",
            "Finetune Epoch 11, Graph 7500/13995, Loss: 3.5192\n",
            "Finetune Epoch 11, Graph 8000/13995, Loss: 2.0654\n",
            "Finetune Epoch 11, Graph 8500/13995, Loss: 0.0371\n",
            "Finetune Epoch 11, Graph 9000/13995, Loss: 0.1230\n",
            "Finetune Epoch 11, Graph 9500/13995, Loss: 1.9163\n",
            "Finetune Epoch 11, Graph 10000/13995, Loss: 0.0352\n",
            "Finetune Epoch 11, Graph 10500/13995, Loss: 0.0319\n",
            "Finetune Epoch 11, Graph 11000/13995, Loss: 2.1955\n",
            "Finetune Epoch 11, Graph 11500/13995, Loss: 2.9341\n",
            "Finetune Epoch 11, Graph 12000/13995, Loss: 0.0258\n",
            "Finetune Epoch 11, Graph 12500/13995, Loss: 0.0161\n",
            "Finetune Epoch 11, Graph 13000/13995, Loss: 0.0628\n",
            "Finetune Epoch 11, Graph 13500/13995, Loss: 0.0351\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 11/30, Loss: 1.6755\n",
            "Finetune Epoch 12, Graph 500/13995, Loss: 0.0508\n",
            "Finetune Epoch 12, Graph 1000/13995, Loss: 4.1269\n",
            "Finetune Epoch 12, Graph 1500/13995, Loss: 0.0466\n",
            "Finetune Epoch 12, Graph 2000/13995, Loss: 0.1397\n",
            "Finetune Epoch 12, Graph 2500/13995, Loss: 1.5287\n",
            "Finetune Epoch 12, Graph 3000/13995, Loss: 4.2151\n",
            "Finetune Epoch 12, Graph 3500/13995, Loss: 2.6049\n",
            "Finetune Epoch 12, Graph 4000/13995, Loss: 4.2708\n",
            "Finetune Epoch 12, Graph 4500/13995, Loss: 5.1564\n",
            "Finetune Epoch 12, Graph 5000/13995, Loss: 0.0436\n",
            "Finetune Epoch 12, Graph 5500/13995, Loss: 2.5616\n",
            "Finetune Epoch 12, Graph 6000/13995, Loss: 0.0561\n",
            "Finetune Epoch 12, Graph 6500/13995, Loss: 0.6130\n",
            "Finetune Epoch 12, Graph 7000/13995, Loss: 0.0227\n",
            "Finetune Epoch 12, Graph 7500/13995, Loss: 4.4615\n",
            "Finetune Epoch 12, Graph 8000/13995, Loss: 2.3505\n",
            "Finetune Epoch 12, Graph 8500/13995, Loss: 0.0776\n",
            "Finetune Epoch 12, Graph 9000/13995, Loss: 0.2756\n",
            "Finetune Epoch 12, Graph 9500/13995, Loss: 1.7300\n",
            "Finetune Epoch 12, Graph 10000/13995, Loss: 0.0362\n",
            "Finetune Epoch 12, Graph 10500/13995, Loss: 0.0351\n",
            "Finetune Epoch 12, Graph 11000/13995, Loss: 1.7003\n",
            "Finetune Epoch 12, Graph 11500/13995, Loss: 2.8584\n",
            "Finetune Epoch 12, Graph 12000/13995, Loss: 0.0317\n",
            "Finetune Epoch 12, Graph 12500/13995, Loss: 0.0348\n",
            "Finetune Epoch 12, Graph 13000/13995, Loss: 0.0405\n",
            "Finetune Epoch 12, Graph 13500/13995, Loss: 0.0996\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 12/30, Loss: 1.6736\n",
            "Finetune Epoch 13, Graph 500/13995, Loss: 0.2107\n",
            "Finetune Epoch 13, Graph 1000/13995, Loss: 2.9133\n",
            "Finetune Epoch 13, Graph 1500/13995, Loss: 0.0498\n",
            "Finetune Epoch 13, Graph 2000/13995, Loss: 0.5932\n",
            "Finetune Epoch 13, Graph 2500/13995, Loss: 2.6716\n",
            "Finetune Epoch 13, Graph 3000/13995, Loss: 4.4818\n",
            "Finetune Epoch 13, Graph 3500/13995, Loss: 2.9032\n",
            "Finetune Epoch 13, Graph 4000/13995, Loss: 4.3247\n",
            "Finetune Epoch 13, Graph 4500/13995, Loss: 5.2145\n",
            "Finetune Epoch 13, Graph 5000/13995, Loss: 0.0409\n",
            "Finetune Epoch 13, Graph 5500/13995, Loss: 2.4131\n",
            "Finetune Epoch 13, Graph 6000/13995, Loss: 0.0282\n",
            "Finetune Epoch 13, Graph 6500/13995, Loss: 1.1953\n",
            "Finetune Epoch 13, Graph 7000/13995, Loss: 0.0346\n",
            "Finetune Epoch 13, Graph 7500/13995, Loss: 4.4853\n",
            "Finetune Epoch 13, Graph 8000/13995, Loss: 2.3585\n",
            "Finetune Epoch 13, Graph 8500/13995, Loss: 0.9573\n",
            "Finetune Epoch 13, Graph 9000/13995, Loss: 0.2853\n",
            "Finetune Epoch 13, Graph 9500/13995, Loss: 1.9437\n",
            "Finetune Epoch 13, Graph 10000/13995, Loss: 0.0535\n",
            "Finetune Epoch 13, Graph 10500/13995, Loss: 0.0386\n",
            "Finetune Epoch 13, Graph 11000/13995, Loss: 2.3039\n",
            "Finetune Epoch 13, Graph 11500/13995, Loss: 1.9938\n",
            "Finetune Epoch 13, Graph 12000/13995, Loss: 0.0368\n",
            "Finetune Epoch 13, Graph 12500/13995, Loss: 0.0225\n",
            "Finetune Epoch 13, Graph 13000/13995, Loss: 0.0317\n",
            "Finetune Epoch 13, Graph 13500/13995, Loss: 0.0906\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 13/30, Loss: 1.6719\n",
            "Finetune Epoch 14, Graph 500/13995, Loss: 0.2117\n",
            "Finetune Epoch 14, Graph 1000/13995, Loss: 3.5702\n",
            "Finetune Epoch 14, Graph 1500/13995, Loss: 0.0458\n",
            "Finetune Epoch 14, Graph 2000/13995, Loss: 0.1441\n",
            "Finetune Epoch 14, Graph 2500/13995, Loss: 2.6651\n",
            "Finetune Epoch 14, Graph 3000/13995, Loss: 4.2633\n",
            "Finetune Epoch 14, Graph 3500/13995, Loss: 2.9902\n",
            "Finetune Epoch 14, Graph 4000/13995, Loss: 4.6290\n",
            "Finetune Epoch 14, Graph 4500/13995, Loss: 4.7310\n",
            "Finetune Epoch 14, Graph 5000/13995, Loss: 0.0378\n",
            "Finetune Epoch 14, Graph 5500/13995, Loss: 2.3593\n",
            "Finetune Epoch 14, Graph 6000/13995, Loss: 0.0312\n",
            "Finetune Epoch 14, Graph 6500/13995, Loss: 1.4903\n",
            "Finetune Epoch 14, Graph 7000/13995, Loss: 0.0683\n",
            "Finetune Epoch 14, Graph 7500/13995, Loss: 4.1487\n",
            "Finetune Epoch 14, Graph 8000/13995, Loss: 2.1864\n",
            "Finetune Epoch 14, Graph 8500/13995, Loss: 0.0561\n",
            "Finetune Epoch 14, Graph 9000/13995, Loss: 0.0750\n",
            "Finetune Epoch 14, Graph 9500/13995, Loss: 1.8892\n",
            "Finetune Epoch 14, Graph 10000/13995, Loss: 0.0404\n",
            "Finetune Epoch 14, Graph 10500/13995, Loss: 0.0910\n",
            "Finetune Epoch 14, Graph 11000/13995, Loss: 1.9992\n",
            "Finetune Epoch 14, Graph 11500/13995, Loss: 1.7939\n",
            "Finetune Epoch 14, Graph 12000/13995, Loss: 0.0328\n",
            "Finetune Epoch 14, Graph 12500/13995, Loss: 0.0354\n",
            "Finetune Epoch 14, Graph 13000/13995, Loss: 0.0386\n",
            "Finetune Epoch 14, Graph 13500/13995, Loss: 0.0881\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 14/30, Loss: 1.6722\n",
            "Finetune Epoch 15, Graph 500/13995, Loss: 0.1814\n",
            "Finetune Epoch 15, Graph 1000/13995, Loss: 3.0056\n",
            "Finetune Epoch 15, Graph 1500/13995, Loss: 0.0513\n",
            "Finetune Epoch 15, Graph 2000/13995, Loss: 0.5774\n",
            "Finetune Epoch 15, Graph 2500/13995, Loss: 0.8214\n",
            "Finetune Epoch 15, Graph 3000/13995, Loss: 4.7719\n",
            "Finetune Epoch 15, Graph 3500/13995, Loss: 2.5440\n",
            "Finetune Epoch 15, Graph 4000/13995, Loss: 4.4905\n",
            "Finetune Epoch 15, Graph 4500/13995, Loss: 4.6337\n",
            "Finetune Epoch 15, Graph 5000/13995, Loss: 0.0730\n",
            "Finetune Epoch 15, Graph 5500/13995, Loss: 2.3354\n",
            "Finetune Epoch 15, Graph 6000/13995, Loss: 0.0268\n",
            "Finetune Epoch 15, Graph 6500/13995, Loss: 1.1882\n",
            "Finetune Epoch 15, Graph 7000/13995, Loss: 0.4511\n",
            "Finetune Epoch 15, Graph 7500/13995, Loss: 4.2969\n",
            "Finetune Epoch 15, Graph 8000/13995, Loss: 2.2985\n",
            "Finetune Epoch 15, Graph 8500/13995, Loss: 0.0571\n",
            "Finetune Epoch 15, Graph 9000/13995, Loss: 0.3370\n",
            "Finetune Epoch 15, Graph 9500/13995, Loss: 2.2443\n",
            "Finetune Epoch 15, Graph 10000/13995, Loss: 0.0449\n",
            "Finetune Epoch 15, Graph 10500/13995, Loss: 0.0524\n",
            "Finetune Epoch 15, Graph 11000/13995, Loss: 2.5273\n",
            "Finetune Epoch 15, Graph 11500/13995, Loss: 3.3816\n",
            "Finetune Epoch 15, Graph 12000/13995, Loss: 0.0370\n",
            "Finetune Epoch 15, Graph 12500/13995, Loss: 0.0273\n",
            "Finetune Epoch 15, Graph 13000/13995, Loss: 0.0548\n",
            "Finetune Epoch 15, Graph 13500/13995, Loss: 0.0371\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 15/30, Loss: 1.6620\n",
            "Finetune Epoch 16, Graph 500/13995, Loss: 0.3627\n",
            "Finetune Epoch 16, Graph 1000/13995, Loss: 3.6833\n",
            "Finetune Epoch 16, Graph 1500/13995, Loss: 0.0362\n",
            "Finetune Epoch 16, Graph 2000/13995, Loss: 0.0757\n",
            "Finetune Epoch 16, Graph 2500/13995, Loss: 0.4365\n",
            "Finetune Epoch 16, Graph 3000/13995, Loss: 4.7551\n",
            "Finetune Epoch 16, Graph 3500/13995, Loss: 3.1153\n",
            "Finetune Epoch 16, Graph 4000/13995, Loss: 3.9420\n",
            "Finetune Epoch 16, Graph 4500/13995, Loss: 5.1036\n",
            "Finetune Epoch 16, Graph 5000/13995, Loss: 0.0632\n",
            "Finetune Epoch 16, Graph 5500/13995, Loss: 2.5934\n",
            "Finetune Epoch 16, Graph 6000/13995, Loss: 0.5638\n",
            "Finetune Epoch 16, Graph 6500/13995, Loss: 1.1111\n",
            "Finetune Epoch 16, Graph 7000/13995, Loss: 0.1361\n",
            "Finetune Epoch 16, Graph 7500/13995, Loss: 4.3036\n",
            "Finetune Epoch 16, Graph 8000/13995, Loss: 2.1630\n",
            "Finetune Epoch 16, Graph 8500/13995, Loss: 0.0892\n",
            "Finetune Epoch 16, Graph 9000/13995, Loss: 0.2791\n",
            "Finetune Epoch 16, Graph 9500/13995, Loss: 1.8385\n",
            "Finetune Epoch 16, Graph 10000/13995, Loss: 0.0398\n",
            "Finetune Epoch 16, Graph 10500/13995, Loss: 0.0409\n",
            "Finetune Epoch 16, Graph 11000/13995, Loss: 1.9714\n",
            "Finetune Epoch 16, Graph 11500/13995, Loss: 3.1591\n",
            "Finetune Epoch 16, Graph 12000/13995, Loss: 0.0316\n",
            "Finetune Epoch 16, Graph 12500/13995, Loss: 0.0377\n",
            "Finetune Epoch 16, Graph 13000/13995, Loss: 0.0548\n",
            "Finetune Epoch 16, Graph 13500/13995, Loss: 0.0831\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 16/30, Loss: 1.6566\n",
            "Finetune Epoch 17, Graph 500/13995, Loss: 0.0679\n",
            "Finetune Epoch 17, Graph 1000/13995, Loss: 2.8346\n",
            "Finetune Epoch 17, Graph 1500/13995, Loss: 0.0724\n",
            "Finetune Epoch 17, Graph 2000/13995, Loss: 0.3492\n",
            "Finetune Epoch 17, Graph 2500/13995, Loss: 0.8162\n",
            "Finetune Epoch 17, Graph 3000/13995, Loss: 5.0881\n",
            "Finetune Epoch 17, Graph 3500/13995, Loss: 2.9394\n",
            "Finetune Epoch 17, Graph 4000/13995, Loss: 4.2101\n",
            "Finetune Epoch 17, Graph 4500/13995, Loss: 4.6189\n",
            "Finetune Epoch 17, Graph 5000/13995, Loss: 0.0668\n",
            "Finetune Epoch 17, Graph 5500/13995, Loss: 2.6992\n",
            "Finetune Epoch 17, Graph 6000/13995, Loss: 0.0416\n",
            "Finetune Epoch 17, Graph 6500/13995, Loss: 0.6535\n",
            "Finetune Epoch 17, Graph 7000/13995, Loss: 0.0271\n",
            "Finetune Epoch 17, Graph 7500/13995, Loss: 4.0210\n",
            "Finetune Epoch 17, Graph 8000/13995, Loss: 2.4138\n",
            "Finetune Epoch 17, Graph 8500/13995, Loss: 0.0547\n",
            "Finetune Epoch 17, Graph 9000/13995, Loss: 0.4271\n",
            "Finetune Epoch 17, Graph 9500/13995, Loss: 2.2363\n",
            "Finetune Epoch 17, Graph 10000/13995, Loss: 0.1797\n",
            "Finetune Epoch 17, Graph 10500/13995, Loss: 0.0587\n",
            "Finetune Epoch 17, Graph 11000/13995, Loss: 2.0885\n",
            "Finetune Epoch 17, Graph 11500/13995, Loss: 2.8063\n",
            "Finetune Epoch 17, Graph 12000/13995, Loss: 0.0258\n",
            "Finetune Epoch 17, Graph 12500/13995, Loss: 0.0353\n",
            "Finetune Epoch 17, Graph 13000/13995, Loss: 0.0445\n",
            "Finetune Epoch 17, Graph 13500/13995, Loss: 0.0464\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 17/30, Loss: 1.6539\n",
            "Finetune Epoch 18, Graph 500/13995, Loss: 0.1393\n",
            "Finetune Epoch 18, Graph 1000/13995, Loss: 2.5610\n",
            "Finetune Epoch 18, Graph 1500/13995, Loss: 0.0408\n",
            "Finetune Epoch 18, Graph 2000/13995, Loss: 0.6115\n",
            "Finetune Epoch 18, Graph 2500/13995, Loss: 0.6825\n",
            "Finetune Epoch 18, Graph 3000/13995, Loss: 4.3556\n",
            "Finetune Epoch 18, Graph 3500/13995, Loss: 2.5544\n",
            "Finetune Epoch 18, Graph 4000/13995, Loss: 3.2818\n",
            "Finetune Epoch 18, Graph 4500/13995, Loss: 5.1783\n",
            "Finetune Epoch 18, Graph 5000/13995, Loss: 0.0377\n",
            "Finetune Epoch 18, Graph 5500/13995, Loss: 2.7906\n",
            "Finetune Epoch 18, Graph 6000/13995, Loss: 0.0537\n",
            "Finetune Epoch 18, Graph 6500/13995, Loss: 0.4118\n",
            "Finetune Epoch 18, Graph 7000/13995, Loss: 0.0292\n",
            "Finetune Epoch 18, Graph 7500/13995, Loss: 4.3291\n",
            "Finetune Epoch 18, Graph 8000/13995, Loss: 1.9052\n",
            "Finetune Epoch 18, Graph 8500/13995, Loss: 0.0721\n",
            "Finetune Epoch 18, Graph 9000/13995, Loss: 0.1808\n",
            "Finetune Epoch 18, Graph 9500/13995, Loss: 1.5143\n",
            "Finetune Epoch 18, Graph 10000/13995, Loss: 0.0454\n",
            "Finetune Epoch 18, Graph 10500/13995, Loss: 0.0409\n",
            "Finetune Epoch 18, Graph 11000/13995, Loss: 3.2079\n",
            "Finetune Epoch 18, Graph 11500/13995, Loss: 3.4814\n",
            "Finetune Epoch 18, Graph 12000/13995, Loss: 0.0513\n",
            "Finetune Epoch 18, Graph 12500/13995, Loss: 0.0350\n",
            "Finetune Epoch 18, Graph 13000/13995, Loss: 0.0641\n",
            "Finetune Epoch 18, Graph 13500/13995, Loss: 0.0555\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 18/30, Loss: 1.6542\n",
            "Finetune Epoch 19, Graph 500/13995, Loss: 0.0735\n",
            "Finetune Epoch 19, Graph 1000/13995, Loss: 2.6201\n",
            "Finetune Epoch 19, Graph 1500/13995, Loss: 0.0704\n",
            "Finetune Epoch 19, Graph 2000/13995, Loss: 1.1203\n",
            "Finetune Epoch 19, Graph 2500/13995, Loss: 0.9299\n",
            "Finetune Epoch 19, Graph 3000/13995, Loss: 4.1795\n",
            "Finetune Epoch 19, Graph 3500/13995, Loss: 2.6883\n",
            "Finetune Epoch 19, Graph 4000/13995, Loss: 4.7448\n",
            "Finetune Epoch 19, Graph 4500/13995, Loss: 2.9759\n",
            "Finetune Epoch 19, Graph 5000/13995, Loss: 0.0535\n",
            "Finetune Epoch 19, Graph 5500/13995, Loss: 2.5999\n",
            "Finetune Epoch 19, Graph 6000/13995, Loss: 0.0376\n",
            "Finetune Epoch 19, Graph 6500/13995, Loss: 0.8536\n",
            "Finetune Epoch 19, Graph 7000/13995, Loss: 0.0285\n",
            "Finetune Epoch 19, Graph 7500/13995, Loss: 4.2982\n",
            "Finetune Epoch 19, Graph 8000/13995, Loss: 1.8129\n",
            "Finetune Epoch 19, Graph 8500/13995, Loss: 0.0953\n",
            "Finetune Epoch 19, Graph 9000/13995, Loss: 0.2839\n",
            "Finetune Epoch 19, Graph 9500/13995, Loss: 1.9333\n",
            "Finetune Epoch 19, Graph 10000/13995, Loss: 0.0403\n",
            "Finetune Epoch 19, Graph 10500/13995, Loss: 0.0784\n",
            "Finetune Epoch 19, Graph 11000/13995, Loss: 2.9772\n",
            "Finetune Epoch 19, Graph 11500/13995, Loss: 2.7042\n",
            "Finetune Epoch 19, Graph 12000/13995, Loss: 0.0581\n",
            "Finetune Epoch 19, Graph 12500/13995, Loss: 0.0291\n",
            "Finetune Epoch 19, Graph 13000/13995, Loss: 0.0802\n",
            "Finetune Epoch 19, Graph 13500/13995, Loss: 0.0411\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 19/30, Loss: 1.6493\n",
            "Finetune Epoch 20, Graph 500/13995, Loss: 0.1215\n",
            "Finetune Epoch 20, Graph 1000/13995, Loss: 2.8700\n",
            "Finetune Epoch 20, Graph 1500/13995, Loss: 0.0981\n",
            "Finetune Epoch 20, Graph 2000/13995, Loss: 0.2235\n",
            "Finetune Epoch 20, Graph 2500/13995, Loss: 0.7559\n",
            "Finetune Epoch 20, Graph 3000/13995, Loss: 4.4024\n",
            "Finetune Epoch 20, Graph 3500/13995, Loss: 2.5628\n",
            "Finetune Epoch 20, Graph 4000/13995, Loss: 4.2667\n",
            "Finetune Epoch 20, Graph 4500/13995, Loss: 4.4672\n",
            "Finetune Epoch 20, Graph 5000/13995, Loss: 0.0597\n",
            "Finetune Epoch 20, Graph 5500/13995, Loss: 2.5065\n",
            "Finetune Epoch 20, Graph 6000/13995, Loss: 0.0436\n",
            "Finetune Epoch 20, Graph 6500/13995, Loss: 2.0933\n",
            "Finetune Epoch 20, Graph 7000/13995, Loss: 0.0505\n",
            "Finetune Epoch 20, Graph 7500/13995, Loss: 3.6109\n",
            "Finetune Epoch 20, Graph 8000/13995, Loss: 1.9797\n",
            "Finetune Epoch 20, Graph 8500/13995, Loss: 0.0729\n",
            "Finetune Epoch 20, Graph 9000/13995, Loss: 0.5858\n",
            "Finetune Epoch 20, Graph 9500/13995, Loss: 1.4837\n",
            "Finetune Epoch 20, Graph 10000/13995, Loss: 0.0480\n",
            "Finetune Epoch 20, Graph 10500/13995, Loss: 0.0882\n",
            "Finetune Epoch 20, Graph 11000/13995, Loss: 1.9804\n",
            "Finetune Epoch 20, Graph 11500/13995, Loss: 2.9399\n",
            "Finetune Epoch 20, Graph 12000/13995, Loss: 0.0446\n",
            "Finetune Epoch 20, Graph 12500/13995, Loss: 0.0760\n",
            "Finetune Epoch 20, Graph 13000/13995, Loss: 0.0503\n",
            "Finetune Epoch 20, Graph 13500/13995, Loss: 0.1255\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 20/30, Loss: 1.6522\n",
            "Finetune Epoch 21, Graph 500/13995, Loss: 0.1368\n",
            "Finetune Epoch 21, Graph 1000/13995, Loss: 3.1189\n",
            "Finetune Epoch 21, Graph 1500/13995, Loss: 0.1838\n",
            "Finetune Epoch 21, Graph 2000/13995, Loss: 0.4167\n",
            "Finetune Epoch 21, Graph 2500/13995, Loss: 0.9072\n",
            "Finetune Epoch 21, Graph 3000/13995, Loss: 4.5359\n",
            "Finetune Epoch 21, Graph 3500/13995, Loss: 2.6579\n",
            "Finetune Epoch 21, Graph 4000/13995, Loss: 1.3972\n",
            "Finetune Epoch 21, Graph 4500/13995, Loss: 4.1025\n",
            "Finetune Epoch 21, Graph 5000/13995, Loss: 0.0474\n",
            "Finetune Epoch 21, Graph 5500/13995, Loss: 2.4606\n",
            "Finetune Epoch 21, Graph 6000/13995, Loss: 0.0630\n",
            "Finetune Epoch 21, Graph 6500/13995, Loss: 1.8699\n",
            "Finetune Epoch 21, Graph 7000/13995, Loss: 0.1292\n",
            "Finetune Epoch 21, Graph 7500/13995, Loss: 4.3623\n",
            "Finetune Epoch 21, Graph 8000/13995, Loss: 2.0195\n",
            "Finetune Epoch 21, Graph 8500/13995, Loss: 0.0623\n",
            "Finetune Epoch 21, Graph 9000/13995, Loss: 0.1829\n",
            "Finetune Epoch 21, Graph 9500/13995, Loss: 1.5837\n",
            "Finetune Epoch 21, Graph 10000/13995, Loss: 0.0584\n",
            "Finetune Epoch 21, Graph 10500/13995, Loss: 0.0468\n",
            "Finetune Epoch 21, Graph 11000/13995, Loss: 2.9785\n",
            "Finetune Epoch 21, Graph 11500/13995, Loss: 2.0108\n",
            "Finetune Epoch 21, Graph 12000/13995, Loss: 0.0526\n",
            "Finetune Epoch 21, Graph 12500/13995, Loss: 0.0462\n",
            "Finetune Epoch 21, Graph 13000/13995, Loss: 0.0479\n",
            "Finetune Epoch 21, Graph 13500/13995, Loss: 0.0477\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 21/30, Loss: 1.6469\n",
            "Finetune Epoch 22, Graph 500/13995, Loss: 0.2858\n",
            "Finetune Epoch 22, Graph 1000/13995, Loss: 2.7573\n",
            "Finetune Epoch 22, Graph 1500/13995, Loss: 0.0563\n",
            "Finetune Epoch 22, Graph 2000/13995, Loss: 0.2123\n",
            "Finetune Epoch 22, Graph 2500/13995, Loss: 3.2021\n",
            "Finetune Epoch 22, Graph 3000/13995, Loss: 4.4353\n",
            "Finetune Epoch 22, Graph 3500/13995, Loss: 2.5553\n",
            "Finetune Epoch 22, Graph 4000/13995, Loss: 3.6188\n",
            "Finetune Epoch 22, Graph 4500/13995, Loss: 5.0890\n",
            "Finetune Epoch 22, Graph 5000/13995, Loss: 0.0404\n",
            "Finetune Epoch 22, Graph 5500/13995, Loss: 2.6259\n",
            "Finetune Epoch 22, Graph 6000/13995, Loss: 0.0484\n",
            "Finetune Epoch 22, Graph 6500/13995, Loss: 3.4346\n",
            "Finetune Epoch 22, Graph 7000/13995, Loss: 0.0277\n",
            "Finetune Epoch 22, Graph 7500/13995, Loss: 3.9822\n",
            "Finetune Epoch 22, Graph 8000/13995, Loss: 1.8173\n",
            "Finetune Epoch 22, Graph 8500/13995, Loss: 0.1069\n",
            "Finetune Epoch 22, Graph 9000/13995, Loss: 0.1495\n",
            "Finetune Epoch 22, Graph 9500/13995, Loss: 1.9211\n",
            "Finetune Epoch 22, Graph 10000/13995, Loss: 0.0741\n",
            "Finetune Epoch 22, Graph 10500/13995, Loss: 0.0764\n",
            "Finetune Epoch 22, Graph 11000/13995, Loss: 2.3417\n",
            "Finetune Epoch 22, Graph 11500/13995, Loss: 2.4969\n",
            "Finetune Epoch 22, Graph 12000/13995, Loss: 0.0514\n",
            "Finetune Epoch 22, Graph 12500/13995, Loss: 0.0412\n",
            "Finetune Epoch 22, Graph 13000/13995, Loss: 0.0519\n",
            "Finetune Epoch 22, Graph 13500/13995, Loss: 0.0772\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 22/30, Loss: 1.6456\n",
            "Finetune Epoch 23, Graph 500/13995, Loss: 0.1156\n",
            "Finetune Epoch 23, Graph 1000/13995, Loss: 2.4217\n",
            "Finetune Epoch 23, Graph 1500/13995, Loss: 0.0648\n",
            "Finetune Epoch 23, Graph 2000/13995, Loss: 0.5508\n",
            "Finetune Epoch 23, Graph 2500/13995, Loss: 1.5482\n",
            "Finetune Epoch 23, Graph 3000/13995, Loss: 4.6959\n",
            "Finetune Epoch 23, Graph 3500/13995, Loss: 2.4858\n",
            "Finetune Epoch 23, Graph 4000/13995, Loss: 2.9874\n",
            "Finetune Epoch 23, Graph 4500/13995, Loss: 4.5947\n",
            "Finetune Epoch 23, Graph 5000/13995, Loss: 0.0406\n",
            "Finetune Epoch 23, Graph 5500/13995, Loss: 2.6291\n",
            "Finetune Epoch 23, Graph 6000/13995, Loss: 0.0791\n",
            "Finetune Epoch 23, Graph 6500/13995, Loss: 0.8691\n",
            "Finetune Epoch 23, Graph 7000/13995, Loss: 0.0492\n",
            "Finetune Epoch 23, Graph 7500/13995, Loss: 3.9317\n",
            "Finetune Epoch 23, Graph 8000/13995, Loss: 1.8975\n",
            "Finetune Epoch 23, Graph 8500/13995, Loss: 0.0556\n",
            "Finetune Epoch 23, Graph 9000/13995, Loss: 0.2595\n",
            "Finetune Epoch 23, Graph 9500/13995, Loss: 1.9870\n",
            "Finetune Epoch 23, Graph 10000/13995, Loss: 0.0569\n",
            "Finetune Epoch 23, Graph 10500/13995, Loss: 0.0397\n",
            "Finetune Epoch 23, Graph 11000/13995, Loss: 2.2742\n",
            "Finetune Epoch 23, Graph 11500/13995, Loss: 3.1587\n",
            "Finetune Epoch 23, Graph 12000/13995, Loss: 0.0586\n",
            "Finetune Epoch 23, Graph 12500/13995, Loss: 0.0349\n",
            "Finetune Epoch 23, Graph 13000/13995, Loss: 0.0366\n",
            "Finetune Epoch 23, Graph 13500/13995, Loss: 0.0328\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 23/30, Loss: 1.6399\n",
            "Finetune Epoch 24, Graph 500/13995, Loss: 0.3183\n",
            "Finetune Epoch 24, Graph 1000/13995, Loss: 2.5008\n",
            "Finetune Epoch 24, Graph 1500/13995, Loss: 0.0765\n",
            "Finetune Epoch 24, Graph 2000/13995, Loss: 0.2818\n",
            "Finetune Epoch 24, Graph 2500/13995, Loss: 0.5993\n",
            "Finetune Epoch 24, Graph 3000/13995, Loss: 4.4112\n",
            "Finetune Epoch 24, Graph 3500/13995, Loss: 2.5747\n",
            "Finetune Epoch 24, Graph 4000/13995, Loss: 2.5268\n",
            "Finetune Epoch 24, Graph 4500/13995, Loss: 4.7771\n",
            "Finetune Epoch 24, Graph 5000/13995, Loss: 0.0480\n",
            "Finetune Epoch 24, Graph 5500/13995, Loss: 2.5819\n",
            "Finetune Epoch 24, Graph 6000/13995, Loss: 0.0466\n",
            "Finetune Epoch 24, Graph 6500/13995, Loss: 2.1711\n",
            "Finetune Epoch 24, Graph 7000/13995, Loss: 0.0478\n",
            "Finetune Epoch 24, Graph 7500/13995, Loss: 4.2431\n",
            "Finetune Epoch 24, Graph 8000/13995, Loss: 2.0142\n",
            "Finetune Epoch 24, Graph 8500/13995, Loss: 0.0978\n",
            "Finetune Epoch 24, Graph 9000/13995, Loss: 0.1547\n",
            "Finetune Epoch 24, Graph 9500/13995, Loss: 2.1223\n",
            "Finetune Epoch 24, Graph 10000/13995, Loss: 0.0437\n",
            "Finetune Epoch 24, Graph 10500/13995, Loss: 0.0765\n",
            "Finetune Epoch 24, Graph 11000/13995, Loss: 2.5302\n",
            "Finetune Epoch 24, Graph 11500/13995, Loss: 2.3641\n",
            "Finetune Epoch 24, Graph 12000/13995, Loss: 0.1352\n",
            "Finetune Epoch 24, Graph 12500/13995, Loss: 0.0275\n",
            "Finetune Epoch 24, Graph 13000/13995, Loss: 0.0897\n",
            "Finetune Epoch 24, Graph 13500/13995, Loss: 0.0449\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 24/30, Loss: 1.6433\n",
            "Finetune Epoch 25, Graph 500/13995, Loss: 0.1202\n",
            "Finetune Epoch 25, Graph 1000/13995, Loss: 2.4090\n",
            "Finetune Epoch 25, Graph 1500/13995, Loss: 0.0464\n",
            "Finetune Epoch 25, Graph 2000/13995, Loss: 0.4089\n",
            "Finetune Epoch 25, Graph 2500/13995, Loss: 1.1875\n",
            "Finetune Epoch 25, Graph 3000/13995, Loss: 4.4909\n",
            "Finetune Epoch 25, Graph 3500/13995, Loss: 2.5829\n",
            "Finetune Epoch 25, Graph 4000/13995, Loss: 2.9764\n",
            "Finetune Epoch 25, Graph 4500/13995, Loss: 4.7680\n",
            "Finetune Epoch 25, Graph 5000/13995, Loss: 0.0356\n",
            "Finetune Epoch 25, Graph 5500/13995, Loss: 2.8236\n",
            "Finetune Epoch 25, Graph 6000/13995, Loss: 0.0584\n",
            "Finetune Epoch 25, Graph 6500/13995, Loss: 1.1150\n",
            "Finetune Epoch 25, Graph 7000/13995, Loss: 0.0454\n",
            "Finetune Epoch 25, Graph 7500/13995, Loss: 4.2036\n",
            "Finetune Epoch 25, Graph 8000/13995, Loss: 2.1734\n",
            "Finetune Epoch 25, Graph 8500/13995, Loss: 0.1753\n",
            "Finetune Epoch 25, Graph 9000/13995, Loss: 0.3793\n",
            "Finetune Epoch 25, Graph 9500/13995, Loss: 1.5179\n",
            "Finetune Epoch 25, Graph 10000/13995, Loss: 0.0546\n",
            "Finetune Epoch 25, Graph 10500/13995, Loss: 0.0499\n",
            "Finetune Epoch 25, Graph 11000/13995, Loss: 1.8794\n",
            "Finetune Epoch 25, Graph 11500/13995, Loss: 3.3086\n",
            "Finetune Epoch 25, Graph 12000/13995, Loss: 0.0625\n",
            "Finetune Epoch 25, Graph 12500/13995, Loss: 0.0294\n",
            "Finetune Epoch 25, Graph 13000/13995, Loss: 0.0632\n",
            "Finetune Epoch 25, Graph 13500/13995, Loss: 0.0459\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 25/30, Loss: 1.6376\n",
            "Finetune Epoch 26, Graph 500/13995, Loss: 0.1378\n",
            "Finetune Epoch 26, Graph 1000/13995, Loss: 2.5929\n",
            "Finetune Epoch 26, Graph 1500/13995, Loss: 0.0491\n",
            "Finetune Epoch 26, Graph 2000/13995, Loss: 2.0465\n",
            "Finetune Epoch 26, Graph 2500/13995, Loss: 2.0954\n",
            "Finetune Epoch 26, Graph 3000/13995, Loss: 3.3263\n",
            "Finetune Epoch 26, Graph 3500/13995, Loss: 2.4970\n",
            "Finetune Epoch 26, Graph 4000/13995, Loss: 3.0448\n",
            "Finetune Epoch 26, Graph 4500/13995, Loss: 5.1360\n",
            "Finetune Epoch 26, Graph 5000/13995, Loss: 0.0480\n",
            "Finetune Epoch 26, Graph 5500/13995, Loss: 2.8179\n",
            "Finetune Epoch 26, Graph 6000/13995, Loss: 0.0497\n",
            "Finetune Epoch 26, Graph 6500/13995, Loss: 0.7955\n",
            "Finetune Epoch 26, Graph 7000/13995, Loss: 0.0566\n",
            "Finetune Epoch 26, Graph 7500/13995, Loss: 4.4980\n",
            "Finetune Epoch 26, Graph 8000/13995, Loss: 2.1216\n",
            "Finetune Epoch 26, Graph 8500/13995, Loss: 0.0677\n",
            "Finetune Epoch 26, Graph 9000/13995, Loss: 0.3948\n",
            "Finetune Epoch 26, Graph 9500/13995, Loss: 1.4105\n",
            "Finetune Epoch 26, Graph 10000/13995, Loss: 0.0407\n",
            "Finetune Epoch 26, Graph 10500/13995, Loss: 0.0442\n",
            "Finetune Epoch 26, Graph 11000/13995, Loss: 2.0687\n",
            "Finetune Epoch 26, Graph 11500/13995, Loss: 3.2931\n",
            "Finetune Epoch 26, Graph 12000/13995, Loss: 0.0916\n",
            "Finetune Epoch 26, Graph 12500/13995, Loss: 0.0325\n",
            "Finetune Epoch 26, Graph 13000/13995, Loss: 0.0587\n",
            "Finetune Epoch 26, Graph 13500/13995, Loss: 0.0787\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 26/30, Loss: 1.6331\n",
            "Finetune Epoch 27, Graph 500/13995, Loss: 0.0660\n",
            "Finetune Epoch 27, Graph 1000/13995, Loss: 2.5852\n",
            "Finetune Epoch 27, Graph 1500/13995, Loss: 0.0584\n",
            "Finetune Epoch 27, Graph 2000/13995, Loss: 0.4939\n",
            "Finetune Epoch 27, Graph 2500/13995, Loss: 0.7040\n",
            "Finetune Epoch 27, Graph 3000/13995, Loss: 4.2340\n",
            "Finetune Epoch 27, Graph 3500/13995, Loss: 2.4620\n",
            "Finetune Epoch 27, Graph 4000/13995, Loss: 2.0754\n",
            "Finetune Epoch 27, Graph 4500/13995, Loss: 4.2585\n",
            "Finetune Epoch 27, Graph 5000/13995, Loss: 0.0608\n",
            "Finetune Epoch 27, Graph 5500/13995, Loss: 2.6762\n",
            "Finetune Epoch 27, Graph 6000/13995, Loss: 0.0756\n",
            "Finetune Epoch 27, Graph 6500/13995, Loss: 0.3242\n",
            "Finetune Epoch 27, Graph 7000/13995, Loss: 0.1489\n",
            "Finetune Epoch 27, Graph 7500/13995, Loss: 3.9058\n",
            "Finetune Epoch 27, Graph 8000/13995, Loss: 1.9431\n",
            "Finetune Epoch 27, Graph 8500/13995, Loss: 0.0485\n",
            "Finetune Epoch 27, Graph 9000/13995, Loss: 0.1984\n",
            "Finetune Epoch 27, Graph 9500/13995, Loss: 1.6257\n",
            "Finetune Epoch 27, Graph 10000/13995, Loss: 0.0345\n",
            "Finetune Epoch 27, Graph 10500/13995, Loss: 0.0437\n",
            "Finetune Epoch 27, Graph 11000/13995, Loss: 2.2345\n",
            "Finetune Epoch 27, Graph 11500/13995, Loss: 2.9396\n",
            "Finetune Epoch 27, Graph 12000/13995, Loss: 0.0592\n",
            "Finetune Epoch 27, Graph 12500/13995, Loss: 0.0500\n",
            "Finetune Epoch 27, Graph 13000/13995, Loss: 0.1046\n",
            "Finetune Epoch 27, Graph 13500/13995, Loss: 0.0954\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 27/30, Loss: 1.6321\n",
            "Finetune Epoch 28, Graph 500/13995, Loss: 0.0429\n",
            "Finetune Epoch 28, Graph 1000/13995, Loss: 2.7088\n",
            "Finetune Epoch 28, Graph 1500/13995, Loss: 0.0392\n",
            "Finetune Epoch 28, Graph 2000/13995, Loss: 0.2587\n",
            "Finetune Epoch 28, Graph 2500/13995, Loss: 0.9673\n",
            "Finetune Epoch 28, Graph 3000/13995, Loss: 4.4983\n",
            "Finetune Epoch 28, Graph 3500/13995, Loss: 2.9915\n",
            "Finetune Epoch 28, Graph 4000/13995, Loss: 3.3628\n",
            "Finetune Epoch 28, Graph 4500/13995, Loss: 4.3569\n",
            "Finetune Epoch 28, Graph 5000/13995, Loss: 0.0495\n",
            "Finetune Epoch 28, Graph 5500/13995, Loss: 2.4812\n",
            "Finetune Epoch 28, Graph 6000/13995, Loss: 0.1439\n",
            "Finetune Epoch 28, Graph 6500/13995, Loss: 0.9750\n",
            "Finetune Epoch 28, Graph 7000/13995, Loss: 0.0369\n",
            "Finetune Epoch 28, Graph 7500/13995, Loss: 4.4893\n",
            "Finetune Epoch 28, Graph 8000/13995, Loss: 1.9372\n",
            "Finetune Epoch 28, Graph 8500/13995, Loss: 0.0868\n",
            "Finetune Epoch 28, Graph 9000/13995, Loss: 0.2424\n",
            "Finetune Epoch 28, Graph 9500/13995, Loss: 1.5135\n",
            "Finetune Epoch 28, Graph 10000/13995, Loss: 0.0378\n",
            "Finetune Epoch 28, Graph 10500/13995, Loss: 0.0611\n",
            "Finetune Epoch 28, Graph 11000/13995, Loss: 1.9660\n",
            "Finetune Epoch 28, Graph 11500/13995, Loss: 1.8348\n",
            "Finetune Epoch 28, Graph 12000/13995, Loss: 0.0390\n",
            "Finetune Epoch 28, Graph 12500/13995, Loss: 0.0380\n",
            "Finetune Epoch 28, Graph 13000/13995, Loss: 0.0365\n",
            "Finetune Epoch 28, Graph 13500/13995, Loss: 0.0604\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 28/30, Loss: 1.6341\n",
            "Finetune Epoch 29, Graph 500/13995, Loss: 0.4514\n",
            "Finetune Epoch 29, Graph 1000/13995, Loss: 2.4817\n",
            "Finetune Epoch 29, Graph 1500/13995, Loss: 0.0355\n",
            "Finetune Epoch 29, Graph 2000/13995, Loss: 3.1319\n",
            "Finetune Epoch 29, Graph 2500/13995, Loss: 1.1648\n",
            "Finetune Epoch 29, Graph 3000/13995, Loss: 4.7233\n",
            "Finetune Epoch 29, Graph 3500/13995, Loss: 2.5957\n",
            "Finetune Epoch 29, Graph 4000/13995, Loss: 2.5097\n",
            "Finetune Epoch 29, Graph 4500/13995, Loss: 4.6959\n",
            "Finetune Epoch 29, Graph 5000/13995, Loss: 0.0443\n",
            "Finetune Epoch 29, Graph 5500/13995, Loss: 2.7543\n",
            "Finetune Epoch 29, Graph 6000/13995, Loss: 0.0451\n",
            "Finetune Epoch 29, Graph 6500/13995, Loss: 0.2793\n",
            "Finetune Epoch 29, Graph 7000/13995, Loss: 0.0448\n",
            "Finetune Epoch 29, Graph 7500/13995, Loss: 4.0697\n",
            "Finetune Epoch 29, Graph 8000/13995, Loss: 2.0248\n",
            "Finetune Epoch 29, Graph 8500/13995, Loss: 0.1149\n",
            "Finetune Epoch 29, Graph 9000/13995, Loss: 0.4190\n",
            "Finetune Epoch 29, Graph 9500/13995, Loss: 1.5991\n",
            "Finetune Epoch 29, Graph 10000/13995, Loss: 0.0306\n",
            "Finetune Epoch 29, Graph 10500/13995, Loss: 0.0615\n",
            "Finetune Epoch 29, Graph 11000/13995, Loss: 2.0539\n",
            "Finetune Epoch 29, Graph 11500/13995, Loss: 2.7588\n",
            "Finetune Epoch 29, Graph 12000/13995, Loss: 0.0558\n",
            "Finetune Epoch 29, Graph 12500/13995, Loss: 0.0349\n",
            "Finetune Epoch 29, Graph 13000/13995, Loss: 0.0566\n",
            "Finetune Epoch 29, Graph 13500/13995, Loss: 0.0722\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 29/30, Loss: 1.6352\n",
            "Finetune Epoch 30, Graph 500/13995, Loss: 0.2737\n",
            "Finetune Epoch 30, Graph 1000/13995, Loss: 2.2586\n",
            "Finetune Epoch 30, Graph 1500/13995, Loss: 0.0407\n",
            "Finetune Epoch 30, Graph 2000/13995, Loss: 1.4876\n",
            "Finetune Epoch 30, Graph 2500/13995, Loss: 0.6401\n",
            "Finetune Epoch 30, Graph 3000/13995, Loss: 3.9444\n",
            "Finetune Epoch 30, Graph 3500/13995, Loss: 2.3789\n",
            "Finetune Epoch 30, Graph 4000/13995, Loss: 1.8787\n",
            "Finetune Epoch 30, Graph 4500/13995, Loss: 4.4643\n",
            "Finetune Epoch 30, Graph 5000/13995, Loss: 0.0597\n",
            "Finetune Epoch 30, Graph 5500/13995, Loss: 2.7236\n",
            "Finetune Epoch 30, Graph 6000/13995, Loss: 0.1260\n",
            "Finetune Epoch 30, Graph 6500/13995, Loss: 1.0217\n",
            "Finetune Epoch 30, Graph 7000/13995, Loss: 0.0278\n",
            "Finetune Epoch 30, Graph 7500/13995, Loss: 3.5885\n",
            "Finetune Epoch 30, Graph 8000/13995, Loss: 1.9130\n",
            "Finetune Epoch 30, Graph 8500/13995, Loss: 0.0876\n",
            "Finetune Epoch 30, Graph 9000/13995, Loss: 0.1596\n",
            "Finetune Epoch 30, Graph 9500/13995, Loss: 1.6064\n",
            "Finetune Epoch 30, Graph 10000/13995, Loss: 0.0394\n",
            "Finetune Epoch 30, Graph 10500/13995, Loss: 0.0373\n",
            "Finetune Epoch 30, Graph 11000/13995, Loss: 2.4745\n",
            "Finetune Epoch 30, Graph 11500/13995, Loss: 2.6928\n",
            "Finetune Epoch 30, Graph 12000/13995, Loss: 0.0319\n",
            "Finetune Epoch 30, Graph 12500/13995, Loss: 0.0277\n",
            "Finetune Epoch 30, Graph 13000/13995, Loss: 0.0485\n",
            "Finetune Epoch 30, Graph 13500/13995, Loss: 0.0436\n",
            "Skipped 0 out of 13995 graphs during fine-tuning.\n",
            "Finetune Epoch 30/30, Loss: 1.6271\n",
            "Fine-tuned model saved as finetuned_gat_32dim_3dim.pth\n",
            "Loaded fine-tuned weights for final training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Train Epoch 1, Graph 500/50382, Loss: 0.3928\n",
            "Final Train Epoch 1, Graph 1000/50382, Loss: 2.3220\n",
            "Final Train Epoch 1, Graph 1500/50382, Loss: 4.4959\n",
            "Final Train Epoch 1, Graph 2000/50382, Loss: 0.6689\n",
            "Final Train Epoch 1, Graph 2500/50382, Loss: 0.8533\n",
            "Final Train Epoch 1, Graph 3000/50382, Loss: 1.5758\n",
            "Final Train Epoch 1, Graph 3500/50382, Loss: 2.3199\n",
            "Final Train Epoch 1, Graph 4000/50382, Loss: 4.1873\n",
            "Final Train Epoch 1, Graph 4500/50382, Loss: 0.0417\n",
            "Final Train Epoch 1, Graph 5000/50382, Loss: 0.0751\n",
            "Final Train Epoch 1, Graph 5500/50382, Loss: 0.0605\n",
            "Final Train Epoch 1, Graph 6000/50382, Loss: 4.2874\n",
            "Final Train Epoch 1, Graph 6500/50382, Loss: 0.0495\n",
            "Final Train Epoch 1, Graph 7000/50382, Loss: 4.4282\n",
            "Final Train Epoch 1, Graph 7500/50382, Loss: 1.9185\n",
            "Final Train Epoch 1, Graph 8000/50382, Loss: 1.0298\n",
            "Final Train Epoch 1, Graph 8500/50382, Loss: 0.0622\n",
            "Final Train Epoch 1, Graph 9000/50382, Loss: 0.0592\n",
            "Final Train Epoch 1, Graph 9500/50382, Loss: 0.5850\n",
            "Final Train Epoch 1, Graph 10000/50382, Loss: 0.0639\n",
            "Final Train Epoch 1, Graph 10500/50382, Loss: 1.9623\n",
            "Final Train Epoch 1, Graph 11000/50382, Loss: 0.4240\n",
            "Final Train Epoch 1, Graph 11500/50382, Loss: 4.3434\n",
            "Final Train Epoch 1, Graph 12000/50382, Loss: 4.3430\n",
            "Final Train Epoch 1, Graph 12500/50382, Loss: 3.6322\n",
            "Final Train Epoch 1, Graph 13000/50382, Loss: 0.0495\n",
            "Final Train Epoch 1, Graph 13500/50382, Loss: 0.8300\n",
            "Final Train Epoch 1, Graph 14000/50382, Loss: 1.1708\n",
            "Final Train Epoch 1, Graph 14500/50382, Loss: 0.0630\n",
            "Final Train Epoch 1, Graph 15000/50382, Loss: 0.8725\n",
            "Final Train Epoch 1, Graph 15500/50382, Loss: 2.4120\n",
            "Final Train Epoch 1, Graph 16000/50382, Loss: 0.0650\n",
            "Final Train Epoch 1, Graph 16500/50382, Loss: 0.2705\n",
            "Final Train Epoch 1, Graph 17000/50382, Loss: 5.0710\n",
            "Final Train Epoch 1, Graph 17500/50382, Loss: 4.2599\n",
            "Final Train Epoch 1, Graph 18000/50382, Loss: 0.3990\n",
            "Final Train Epoch 1, Graph 18500/50382, Loss: 0.1576\n",
            "Final Train Epoch 1, Graph 19000/50382, Loss: 0.0514\n",
            "Final Train Epoch 1, Graph 19500/50382, Loss: 0.0669\n",
            "Final Train Epoch 1, Graph 20000/50382, Loss: 0.1848\n",
            "Final Train Epoch 1, Graph 20500/50382, Loss: 4.0461\n",
            "Final Train Epoch 1, Graph 21000/50382, Loss: 2.3698\n",
            "Final Train Epoch 1, Graph 21500/50382, Loss: 5.0979\n",
            "Final Train Epoch 1, Graph 22000/50382, Loss: 0.1199\n",
            "Final Train Epoch 1, Graph 22500/50382, Loss: 2.4659\n",
            "Final Train Epoch 1, Graph 23000/50382, Loss: 0.0394\n",
            "Final Train Epoch 1, Graph 23500/50382, Loss: 0.0446\n",
            "Final Train Epoch 1, Graph 24000/50382, Loss: 0.3644\n",
            "Final Train Epoch 1, Graph 24500/50382, Loss: 4.1472\n",
            "Final Train Epoch 1, Graph 25000/50382, Loss: 1.2153\n",
            "Final Train Epoch 1, Graph 25500/50382, Loss: 0.0346\n",
            "Final Train Epoch 1, Graph 26000/50382, Loss: 1.6753\n",
            "Final Train Epoch 1, Graph 26500/50382, Loss: 0.0494\n",
            "Final Train Epoch 1, Graph 27000/50382, Loss: 0.0391\n",
            "Final Train Epoch 1, Graph 27500/50382, Loss: 0.0434\n",
            "Final Train Epoch 1, Graph 28000/50382, Loss: 0.0546\n",
            "Final Train Epoch 1, Graph 28500/50382, Loss: 5.0404\n",
            "Final Train Epoch 1, Graph 29000/50382, Loss: 0.0506\n",
            "Final Train Epoch 1, Graph 29500/50382, Loss: 0.0553\n",
            "Final Train Epoch 1, Graph 30000/50382, Loss: 0.0665\n",
            "Final Train Epoch 1, Graph 30500/50382, Loss: 0.1251\n",
            "Final Train Epoch 1, Graph 31000/50382, Loss: 4.5566\n",
            "Final Train Epoch 1, Graph 31500/50382, Loss: 0.0398\n",
            "Final Train Epoch 1, Graph 32000/50382, Loss: 0.0515\n",
            "Final Train Epoch 1, Graph 32500/50382, Loss: 0.0620\n",
            "Final Train Epoch 1, Graph 33000/50382, Loss: 2.5490\n",
            "Final Train Epoch 1, Graph 33500/50382, Loss: 1.6446\n",
            "Final Train Epoch 1, Graph 34000/50382, Loss: 0.0878\n",
            "Final Train Epoch 1, Graph 34500/50382, Loss: 0.0674\n",
            "Final Train Epoch 1, Graph 35000/50382, Loss: 1.3323\n",
            "Final Train Epoch 1, Graph 35500/50382, Loss: 4.2793\n",
            "Final Train Epoch 1, Graph 36000/50382, Loss: 3.8427\n",
            "Final Train Epoch 1, Graph 36500/50382, Loss: 0.0462\n",
            "Final Train Epoch 1, Graph 37000/50382, Loss: 0.0725\n",
            "Final Train Epoch 1, Graph 37500/50382, Loss: 0.0665\n",
            "Final Train Epoch 1, Graph 38000/50382, Loss: 0.0471\n",
            "Final Train Epoch 1, Graph 38500/50382, Loss: 1.9594\n",
            "Final Train Epoch 1, Graph 39000/50382, Loss: 0.0417\n",
            "Final Train Epoch 1, Graph 39500/50382, Loss: 3.9036\n",
            "Final Train Epoch 1, Graph 40000/50382, Loss: 0.0479\n",
            "Final Train Epoch 1, Graph 40500/50382, Loss: 0.0571\n",
            "Final Train Epoch 1, Graph 41000/50382, Loss: 1.0009\n",
            "Final Train Epoch 1, Graph 41500/50382, Loss: 0.2799\n",
            "Final Train Epoch 1, Graph 42000/50382, Loss: 0.0412\n",
            "Final Train Epoch 1, Graph 42500/50382, Loss: 1.2998\n",
            "Final Train Epoch 1, Graph 43000/50382, Loss: 0.8740\n",
            "Final Train Epoch 1, Graph 43500/50382, Loss: 0.5070\n",
            "Final Train Epoch 1, Graph 44000/50382, Loss: 0.0636\n",
            "Final Train Epoch 1, Graph 44500/50382, Loss: 1.4382\n",
            "Final Train Epoch 1, Graph 45000/50382, Loss: 1.5347\n",
            "Final Train Epoch 1, Graph 45500/50382, Loss: 3.4455\n",
            "Final Train Epoch 1, Graph 46000/50382, Loss: 0.0936\n",
            "Final Train Epoch 1, Graph 46500/50382, Loss: 0.0488\n",
            "Final Train Epoch 1, Graph 47000/50382, Loss: 0.0660\n",
            "Final Train Epoch 1, Graph 47500/50382, Loss: 0.0462\n",
            "Final Train Epoch 1, Graph 48000/50382, Loss: 0.0798\n",
            "Final Train Epoch 1, Graph 48500/50382, Loss: 1.3282\n",
            "Final Train Epoch 1, Graph 49000/50382, Loss: 0.0570\n",
            "Final Train Epoch 1, Graph 49500/50382, Loss: 5.3447\n",
            "Final Train Epoch 1, Graph 50000/50382, Loss: 0.1335\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 1/200, Training Loss: 1.6379, Validation Accuracy: 0.4871\n",
            "Best model saved with validation accuracy: 0.4871\n",
            "Final Train Epoch 2, Graph 500/50382, Loss: 0.5078\n",
            "Final Train Epoch 2, Graph 1000/50382, Loss: 2.5498\n",
            "Final Train Epoch 2, Graph 1500/50382, Loss: 3.0420\n",
            "Final Train Epoch 2, Graph 2000/50382, Loss: 0.6006\n",
            "Final Train Epoch 2, Graph 2500/50382, Loss: 0.4667\n",
            "Final Train Epoch 2, Graph 3000/50382, Loss: 1.4104\n",
            "Final Train Epoch 2, Graph 3500/50382, Loss: 2.4588\n",
            "Final Train Epoch 2, Graph 4000/50382, Loss: 2.0160\n",
            "Final Train Epoch 2, Graph 4500/50382, Loss: 0.0593\n",
            "Final Train Epoch 2, Graph 5000/50382, Loss: 0.0480\n",
            "Final Train Epoch 2, Graph 5500/50382, Loss: 0.0372\n",
            "Final Train Epoch 2, Graph 6000/50382, Loss: 1.9403\n",
            "Final Train Epoch 2, Graph 6500/50382, Loss: 0.0554\n",
            "Final Train Epoch 2, Graph 7000/50382, Loss: 2.3494\n",
            "Final Train Epoch 2, Graph 7500/50382, Loss: 1.8967\n",
            "Final Train Epoch 2, Graph 8000/50382, Loss: 1.1660\n",
            "Final Train Epoch 2, Graph 8500/50382, Loss: 0.0618\n",
            "Final Train Epoch 2, Graph 9000/50382, Loss: 0.0574\n",
            "Final Train Epoch 2, Graph 9500/50382, Loss: 0.5198\n",
            "Final Train Epoch 2, Graph 10000/50382, Loss: 0.0741\n",
            "Final Train Epoch 2, Graph 10500/50382, Loss: 1.6479\n",
            "Final Train Epoch 2, Graph 11000/50382, Loss: 0.0755\n",
            "Final Train Epoch 2, Graph 11500/50382, Loss: 3.9681\n",
            "Final Train Epoch 2, Graph 12000/50382, Loss: 3.6297\n",
            "Final Train Epoch 2, Graph 12500/50382, Loss: 4.5692\n",
            "Final Train Epoch 2, Graph 13000/50382, Loss: 0.0599\n",
            "Final Train Epoch 2, Graph 13500/50382, Loss: 1.8749\n",
            "Final Train Epoch 2, Graph 14000/50382, Loss: 3.0506\n",
            "Final Train Epoch 2, Graph 14500/50382, Loss: 0.0458\n",
            "Final Train Epoch 2, Graph 15000/50382, Loss: 2.2926\n",
            "Final Train Epoch 2, Graph 15500/50382, Loss: 3.9980\n",
            "Final Train Epoch 2, Graph 16000/50382, Loss: 0.0932\n",
            "Final Train Epoch 2, Graph 16500/50382, Loss: 0.4537\n",
            "Final Train Epoch 2, Graph 17000/50382, Loss: 3.1991\n",
            "Final Train Epoch 2, Graph 17500/50382, Loss: 3.8659\n",
            "Final Train Epoch 2, Graph 18000/50382, Loss: 0.7046\n",
            "Final Train Epoch 2, Graph 18500/50382, Loss: 0.1376\n",
            "Final Train Epoch 2, Graph 19000/50382, Loss: 0.0707\n",
            "Final Train Epoch 2, Graph 19500/50382, Loss: 0.0395\n",
            "Final Train Epoch 2, Graph 20000/50382, Loss: 0.0481\n",
            "Final Train Epoch 2, Graph 20500/50382, Loss: 4.5012\n",
            "Final Train Epoch 2, Graph 21000/50382, Loss: 1.7749\n",
            "Final Train Epoch 2, Graph 21500/50382, Loss: 4.5645\n",
            "Final Train Epoch 2, Graph 22000/50382, Loss: 0.0560\n",
            "Final Train Epoch 2, Graph 22500/50382, Loss: 2.2499\n",
            "Final Train Epoch 2, Graph 23000/50382, Loss: 0.0467\n",
            "Final Train Epoch 2, Graph 23500/50382, Loss: 0.0502\n",
            "Final Train Epoch 2, Graph 24000/50382, Loss: 0.7833\n",
            "Final Train Epoch 2, Graph 24500/50382, Loss: 4.1223\n",
            "Final Train Epoch 2, Graph 25000/50382, Loss: 2.1427\n",
            "Final Train Epoch 2, Graph 25500/50382, Loss: 0.0373\n",
            "Final Train Epoch 2, Graph 26000/50382, Loss: 1.9416\n",
            "Final Train Epoch 2, Graph 26500/50382, Loss: 0.0670\n",
            "Final Train Epoch 2, Graph 27000/50382, Loss: 0.0356\n",
            "Final Train Epoch 2, Graph 27500/50382, Loss: 0.0673\n",
            "Final Train Epoch 2, Graph 28000/50382, Loss: 0.0468\n",
            "Final Train Epoch 2, Graph 28500/50382, Loss: 4.1905\n",
            "Final Train Epoch 2, Graph 29000/50382, Loss: 0.0493\n",
            "Final Train Epoch 2, Graph 29500/50382, Loss: 0.0553\n",
            "Final Train Epoch 2, Graph 30000/50382, Loss: 0.0528\n",
            "Final Train Epoch 2, Graph 30500/50382, Loss: 0.1590\n",
            "Final Train Epoch 2, Graph 31000/50382, Loss: 3.9813\n",
            "Final Train Epoch 2, Graph 31500/50382, Loss: 0.0436\n",
            "Final Train Epoch 2, Graph 32000/50382, Loss: 0.0425\n",
            "Final Train Epoch 2, Graph 32500/50382, Loss: 0.0595\n",
            "Final Train Epoch 2, Graph 33000/50382, Loss: 1.6371\n",
            "Final Train Epoch 2, Graph 33500/50382, Loss: 1.4293\n",
            "Final Train Epoch 2, Graph 34000/50382, Loss: 0.1500\n",
            "Final Train Epoch 2, Graph 34500/50382, Loss: 0.0485\n",
            "Final Train Epoch 2, Graph 35000/50382, Loss: 2.1760\n",
            "Final Train Epoch 2, Graph 35500/50382, Loss: 4.9772\n",
            "Final Train Epoch 2, Graph 36000/50382, Loss: 4.1833\n",
            "Final Train Epoch 2, Graph 36500/50382, Loss: 0.0525\n",
            "Final Train Epoch 2, Graph 37000/50382, Loss: 0.0703\n",
            "Final Train Epoch 2, Graph 37500/50382, Loss: 0.0544\n",
            "Final Train Epoch 2, Graph 38000/50382, Loss: 0.0800\n",
            "Final Train Epoch 2, Graph 38500/50382, Loss: 1.5296\n",
            "Final Train Epoch 2, Graph 39000/50382, Loss: 0.0416\n",
            "Final Train Epoch 2, Graph 39500/50382, Loss: 4.0386\n",
            "Final Train Epoch 2, Graph 40000/50382, Loss: 0.0425\n",
            "Final Train Epoch 2, Graph 40500/50382, Loss: 0.0742\n",
            "Final Train Epoch 2, Graph 41000/50382, Loss: 1.6633\n",
            "Final Train Epoch 2, Graph 41500/50382, Loss: 0.4796\n",
            "Final Train Epoch 2, Graph 42000/50382, Loss: 0.0522\n",
            "Final Train Epoch 2, Graph 42500/50382, Loss: 1.7611\n",
            "Final Train Epoch 2, Graph 43000/50382, Loss: 1.1613\n",
            "Final Train Epoch 2, Graph 43500/50382, Loss: 0.1155\n",
            "Final Train Epoch 2, Graph 44000/50382, Loss: 0.0606\n",
            "Final Train Epoch 2, Graph 44500/50382, Loss: 1.6970\n",
            "Final Train Epoch 2, Graph 45000/50382, Loss: 1.6689\n",
            "Final Train Epoch 2, Graph 45500/50382, Loss: 4.3496\n",
            "Final Train Epoch 2, Graph 46000/50382, Loss: 0.1115\n",
            "Final Train Epoch 2, Graph 46500/50382, Loss: 0.0592\n",
            "Final Train Epoch 2, Graph 47000/50382, Loss: 0.0560\n",
            "Final Train Epoch 2, Graph 47500/50382, Loss: 0.0500\n",
            "Final Train Epoch 2, Graph 48000/50382, Loss: 0.0636\n",
            "Final Train Epoch 2, Graph 48500/50382, Loss: 0.7551\n",
            "Final Train Epoch 2, Graph 49000/50382, Loss: 0.0640\n",
            "Final Train Epoch 2, Graph 49500/50382, Loss: 5.6683\n",
            "Final Train Epoch 2, Graph 50000/50382, Loss: 0.2097\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 2/200, Training Loss: 1.6314, Validation Accuracy: 0.4921\n",
            "Best model saved with validation accuracy: 0.4921\n",
            "Final Train Epoch 3, Graph 500/50382, Loss: 0.3146\n",
            "Final Train Epoch 3, Graph 1000/50382, Loss: 0.9726\n",
            "Final Train Epoch 3, Graph 1500/50382, Loss: 2.5851\n",
            "Final Train Epoch 3, Graph 2000/50382, Loss: 0.6366\n",
            "Final Train Epoch 3, Graph 2500/50382, Loss: 0.9476\n",
            "Final Train Epoch 3, Graph 3000/50382, Loss: 1.1701\n",
            "Final Train Epoch 3, Graph 3500/50382, Loss: 2.5784\n",
            "Final Train Epoch 3, Graph 4000/50382, Loss: 3.2461\n",
            "Final Train Epoch 3, Graph 4500/50382, Loss: 0.0982\n",
            "Final Train Epoch 3, Graph 5000/50382, Loss: 0.0469\n",
            "Final Train Epoch 3, Graph 5500/50382, Loss: 0.0768\n",
            "Final Train Epoch 3, Graph 6000/50382, Loss: 4.5562\n",
            "Final Train Epoch 3, Graph 6500/50382, Loss: 0.0457\n",
            "Final Train Epoch 3, Graph 7000/50382, Loss: 2.7758\n",
            "Final Train Epoch 3, Graph 7500/50382, Loss: 1.8473\n",
            "Final Train Epoch 3, Graph 8000/50382, Loss: 1.8186\n",
            "Final Train Epoch 3, Graph 8500/50382, Loss: 0.0961\n",
            "Final Train Epoch 3, Graph 9000/50382, Loss: 0.0418\n",
            "Final Train Epoch 3, Graph 9500/50382, Loss: 0.3754\n",
            "Final Train Epoch 3, Graph 10000/50382, Loss: 0.1343\n",
            "Final Train Epoch 3, Graph 10500/50382, Loss: 1.0441\n",
            "Final Train Epoch 3, Graph 11000/50382, Loss: 0.1181\n",
            "Final Train Epoch 3, Graph 11500/50382, Loss: 4.3224\n",
            "Final Train Epoch 3, Graph 12000/50382, Loss: 3.9036\n",
            "Final Train Epoch 3, Graph 12500/50382, Loss: 4.7270\n",
            "Final Train Epoch 3, Graph 13000/50382, Loss: 0.0519\n",
            "Final Train Epoch 3, Graph 13500/50382, Loss: 1.4244\n",
            "Final Train Epoch 3, Graph 14000/50382, Loss: 1.8879\n",
            "Final Train Epoch 3, Graph 14500/50382, Loss: 0.0552\n",
            "Final Train Epoch 3, Graph 15000/50382, Loss: 0.9248\n",
            "Final Train Epoch 3, Graph 15500/50382, Loss: 4.7677\n",
            "Final Train Epoch 3, Graph 16000/50382, Loss: 0.0756\n",
            "Final Train Epoch 3, Graph 16500/50382, Loss: 0.1924\n",
            "Final Train Epoch 3, Graph 17000/50382, Loss: 4.4837\n",
            "Final Train Epoch 3, Graph 17500/50382, Loss: 3.8697\n",
            "Final Train Epoch 3, Graph 18000/50382, Loss: 0.6234\n",
            "Final Train Epoch 3, Graph 18500/50382, Loss: 0.1876\n",
            "Final Train Epoch 3, Graph 19000/50382, Loss: 0.0655\n",
            "Final Train Epoch 3, Graph 19500/50382, Loss: 0.0906\n",
            "Final Train Epoch 3, Graph 20000/50382, Loss: 0.0516\n",
            "Final Train Epoch 3, Graph 20500/50382, Loss: 4.2408\n",
            "Final Train Epoch 3, Graph 21000/50382, Loss: 1.9760\n",
            "Final Train Epoch 3, Graph 21500/50382, Loss: 3.9850\n",
            "Final Train Epoch 3, Graph 22000/50382, Loss: 0.0917\n",
            "Final Train Epoch 3, Graph 22500/50382, Loss: 2.2316\n",
            "Final Train Epoch 3, Graph 23000/50382, Loss: 0.0392\n",
            "Final Train Epoch 3, Graph 23500/50382, Loss: 0.0629\n",
            "Final Train Epoch 3, Graph 24000/50382, Loss: 0.2821\n",
            "Final Train Epoch 3, Graph 24500/50382, Loss: 4.2514\n",
            "Final Train Epoch 3, Graph 25000/50382, Loss: 1.0854\n",
            "Final Train Epoch 3, Graph 25500/50382, Loss: 0.1194\n",
            "Final Train Epoch 3, Graph 26000/50382, Loss: 2.1998\n",
            "Final Train Epoch 3, Graph 26500/50382, Loss: 0.0853\n",
            "Final Train Epoch 3, Graph 27000/50382, Loss: 0.0415\n",
            "Final Train Epoch 3, Graph 27500/50382, Loss: 0.0613\n",
            "Final Train Epoch 3, Graph 28000/50382, Loss: 0.0507\n",
            "Final Train Epoch 3, Graph 28500/50382, Loss: 4.4972\n",
            "Final Train Epoch 3, Graph 29000/50382, Loss: 0.0582\n",
            "Final Train Epoch 3, Graph 29500/50382, Loss: 0.0550\n",
            "Final Train Epoch 3, Graph 30000/50382, Loss: 0.0519\n",
            "Final Train Epoch 3, Graph 30500/50382, Loss: 0.0620\n",
            "Final Train Epoch 3, Graph 31000/50382, Loss: 4.6404\n",
            "Final Train Epoch 3, Graph 31500/50382, Loss: 0.0473\n",
            "Final Train Epoch 3, Graph 32000/50382, Loss: 0.0670\n",
            "Final Train Epoch 3, Graph 32500/50382, Loss: 0.0454\n",
            "Final Train Epoch 3, Graph 33000/50382, Loss: 2.9499\n",
            "Final Train Epoch 3, Graph 33500/50382, Loss: 1.6283\n",
            "Final Train Epoch 3, Graph 34000/50382, Loss: 0.1864\n",
            "Final Train Epoch 3, Graph 34500/50382, Loss: 0.0482\n",
            "Final Train Epoch 3, Graph 35000/50382, Loss: 2.7644\n",
            "Final Train Epoch 3, Graph 35500/50382, Loss: 5.1448\n",
            "Final Train Epoch 3, Graph 36000/50382, Loss: 4.1742\n",
            "Final Train Epoch 3, Graph 36500/50382, Loss: 0.0415\n",
            "Final Train Epoch 3, Graph 37000/50382, Loss: 0.0503\n",
            "Final Train Epoch 3, Graph 37500/50382, Loss: 0.0566\n",
            "Final Train Epoch 3, Graph 38000/50382, Loss: 0.0451\n",
            "Final Train Epoch 3, Graph 38500/50382, Loss: 2.0757\n",
            "Final Train Epoch 3, Graph 39000/50382, Loss: 0.0442\n",
            "Final Train Epoch 3, Graph 39500/50382, Loss: 4.6266\n",
            "Final Train Epoch 3, Graph 40000/50382, Loss: 0.0899\n",
            "Final Train Epoch 3, Graph 40500/50382, Loss: 0.0635\n",
            "Final Train Epoch 3, Graph 41000/50382, Loss: 2.0747\n",
            "Final Train Epoch 3, Graph 41500/50382, Loss: 0.2680\n",
            "Final Train Epoch 3, Graph 42000/50382, Loss: 0.0540\n",
            "Final Train Epoch 3, Graph 42500/50382, Loss: 1.4892\n",
            "Final Train Epoch 3, Graph 43000/50382, Loss: 2.6318\n",
            "Final Train Epoch 3, Graph 43500/50382, Loss: 0.0638\n",
            "Final Train Epoch 3, Graph 44000/50382, Loss: 0.0613\n",
            "Final Train Epoch 3, Graph 44500/50382, Loss: 1.7337\n",
            "Final Train Epoch 3, Graph 45000/50382, Loss: 2.0634\n",
            "Final Train Epoch 3, Graph 45500/50382, Loss: 2.6989\n",
            "Final Train Epoch 3, Graph 46000/50382, Loss: 0.2143\n",
            "Final Train Epoch 3, Graph 46500/50382, Loss: 0.0930\n",
            "Final Train Epoch 3, Graph 47000/50382, Loss: 0.0531\n",
            "Final Train Epoch 3, Graph 47500/50382, Loss: 0.0622\n",
            "Final Train Epoch 3, Graph 48000/50382, Loss: 0.0463\n",
            "Final Train Epoch 3, Graph 48500/50382, Loss: 1.1323\n",
            "Final Train Epoch 3, Graph 49000/50382, Loss: 0.0501\n",
            "Final Train Epoch 3, Graph 49500/50382, Loss: 5.7654\n",
            "Final Train Epoch 3, Graph 50000/50382, Loss: 0.0611\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 3/200, Training Loss: 1.6294, Validation Accuracy: 0.4790\n",
            "Final Train Epoch 4, Graph 500/50382, Loss: 0.8240\n",
            "Final Train Epoch 4, Graph 1000/50382, Loss: 1.0195\n",
            "Final Train Epoch 4, Graph 1500/50382, Loss: 3.8662\n",
            "Final Train Epoch 4, Graph 2000/50382, Loss: 1.0616\n",
            "Final Train Epoch 4, Graph 2500/50382, Loss: 0.7993\n",
            "Final Train Epoch 4, Graph 3000/50382, Loss: 1.2919\n",
            "Final Train Epoch 4, Graph 3500/50382, Loss: 2.6397\n",
            "Final Train Epoch 4, Graph 4000/50382, Loss: 3.8153\n",
            "Final Train Epoch 4, Graph 4500/50382, Loss: 0.2453\n",
            "Final Train Epoch 4, Graph 5000/50382, Loss: 0.0481\n",
            "Final Train Epoch 4, Graph 5500/50382, Loss: 0.0432\n",
            "Final Train Epoch 4, Graph 6000/50382, Loss: 2.8564\n",
            "Final Train Epoch 4, Graph 6500/50382, Loss: 0.0488\n",
            "Final Train Epoch 4, Graph 7000/50382, Loss: 3.5006\n",
            "Final Train Epoch 4, Graph 7500/50382, Loss: 2.0683\n",
            "Final Train Epoch 4, Graph 8000/50382, Loss: 0.6865\n",
            "Final Train Epoch 4, Graph 8500/50382, Loss: 0.0466\n",
            "Final Train Epoch 4, Graph 9000/50382, Loss: 0.0504\n",
            "Final Train Epoch 4, Graph 9500/50382, Loss: 0.0586\n",
            "Final Train Epoch 4, Graph 10000/50382, Loss: 0.0620\n",
            "Final Train Epoch 4, Graph 10500/50382, Loss: 1.3383\n",
            "Final Train Epoch 4, Graph 11000/50382, Loss: 0.1427\n",
            "Final Train Epoch 4, Graph 11500/50382, Loss: 3.4333\n",
            "Final Train Epoch 4, Graph 12000/50382, Loss: 3.1509\n",
            "Final Train Epoch 4, Graph 12500/50382, Loss: 3.5540\n",
            "Final Train Epoch 4, Graph 13000/50382, Loss: 0.0558\n",
            "Final Train Epoch 4, Graph 13500/50382, Loss: 1.5984\n",
            "Final Train Epoch 4, Graph 14000/50382, Loss: 3.3814\n",
            "Final Train Epoch 4, Graph 14500/50382, Loss: 0.0583\n",
            "Final Train Epoch 4, Graph 15000/50382, Loss: 1.1456\n",
            "Final Train Epoch 4, Graph 15500/50382, Loss: 4.2730\n",
            "Final Train Epoch 4, Graph 16000/50382, Loss: 0.0824\n",
            "Final Train Epoch 4, Graph 16500/50382, Loss: 1.1800\n",
            "Final Train Epoch 4, Graph 17000/50382, Loss: 5.0637\n",
            "Final Train Epoch 4, Graph 17500/50382, Loss: 4.0856\n",
            "Final Train Epoch 4, Graph 18000/50382, Loss: 0.3025\n",
            "Final Train Epoch 4, Graph 18500/50382, Loss: 0.1477\n",
            "Final Train Epoch 4, Graph 19000/50382, Loss: 0.0656\n",
            "Final Train Epoch 4, Graph 19500/50382, Loss: 0.0834\n",
            "Final Train Epoch 4, Graph 20000/50382, Loss: 0.0481\n",
            "Final Train Epoch 4, Graph 20500/50382, Loss: 3.4744\n",
            "Final Train Epoch 4, Graph 21000/50382, Loss: 2.0867\n",
            "Final Train Epoch 4, Graph 21500/50382, Loss: 5.2485\n",
            "Final Train Epoch 4, Graph 22000/50382, Loss: 0.0804\n",
            "Final Train Epoch 4, Graph 22500/50382, Loss: 2.3472\n",
            "Final Train Epoch 4, Graph 23000/50382, Loss: 0.0641\n",
            "Final Train Epoch 4, Graph 23500/50382, Loss: 0.0413\n",
            "Final Train Epoch 4, Graph 24000/50382, Loss: 0.3217\n",
            "Final Train Epoch 4, Graph 24500/50382, Loss: 4.1655\n",
            "Final Train Epoch 4, Graph 25000/50382, Loss: 0.7703\n",
            "Final Train Epoch 4, Graph 25500/50382, Loss: 0.0623\n",
            "Final Train Epoch 4, Graph 26000/50382, Loss: 1.3675\n",
            "Final Train Epoch 4, Graph 26500/50382, Loss: 0.0382\n",
            "Final Train Epoch 4, Graph 27000/50382, Loss: 0.0693\n",
            "Final Train Epoch 4, Graph 27500/50382, Loss: 0.0494\n",
            "Final Train Epoch 4, Graph 28000/50382, Loss: 0.0381\n",
            "Final Train Epoch 4, Graph 28500/50382, Loss: 4.7605\n",
            "Final Train Epoch 4, Graph 29000/50382, Loss: 0.0456\n",
            "Final Train Epoch 4, Graph 29500/50382, Loss: 0.0641\n",
            "Final Train Epoch 4, Graph 30000/50382, Loss: 0.0506\n",
            "Final Train Epoch 4, Graph 30500/50382, Loss: 0.1201\n",
            "Final Train Epoch 4, Graph 31000/50382, Loss: 4.5083\n",
            "Final Train Epoch 4, Graph 31500/50382, Loss: 0.0436\n",
            "Final Train Epoch 4, Graph 32000/50382, Loss: 0.0441\n",
            "Final Train Epoch 4, Graph 32500/50382, Loss: 0.0393\n",
            "Final Train Epoch 4, Graph 33000/50382, Loss: 1.4343\n",
            "Final Train Epoch 4, Graph 33500/50382, Loss: 1.3094\n",
            "Final Train Epoch 4, Graph 34000/50382, Loss: 0.1058\n",
            "Final Train Epoch 4, Graph 34500/50382, Loss: 0.0510\n",
            "Final Train Epoch 4, Graph 35000/50382, Loss: 1.8616\n",
            "Final Train Epoch 4, Graph 35500/50382, Loss: 5.0305\n",
            "Final Train Epoch 4, Graph 36000/50382, Loss: 3.9981\n",
            "Final Train Epoch 4, Graph 36500/50382, Loss: 0.0414\n",
            "Final Train Epoch 4, Graph 37000/50382, Loss: 0.0828\n",
            "Final Train Epoch 4, Graph 37500/50382, Loss: 0.0435\n",
            "Final Train Epoch 4, Graph 38000/50382, Loss: 0.0476\n",
            "Final Train Epoch 4, Graph 38500/50382, Loss: 2.7354\n",
            "Final Train Epoch 4, Graph 39000/50382, Loss: 0.0435\n",
            "Final Train Epoch 4, Graph 39500/50382, Loss: 4.2519\n",
            "Final Train Epoch 4, Graph 40000/50382, Loss: 0.0521\n",
            "Final Train Epoch 4, Graph 40500/50382, Loss: 0.0570\n",
            "Final Train Epoch 4, Graph 41000/50382, Loss: 1.8789\n",
            "Final Train Epoch 4, Graph 41500/50382, Loss: 0.3980\n",
            "Final Train Epoch 4, Graph 42000/50382, Loss: 0.0415\n",
            "Final Train Epoch 4, Graph 42500/50382, Loss: 1.3946\n",
            "Final Train Epoch 4, Graph 43000/50382, Loss: 1.0084\n",
            "Final Train Epoch 4, Graph 43500/50382, Loss: 0.1419\n",
            "Final Train Epoch 4, Graph 44000/50382, Loss: 0.0771\n",
            "Final Train Epoch 4, Graph 44500/50382, Loss: 1.8289\n",
            "Final Train Epoch 4, Graph 45000/50382, Loss: 1.0405\n",
            "Final Train Epoch 4, Graph 45500/50382, Loss: 4.1754\n",
            "Final Train Epoch 4, Graph 46000/50382, Loss: 0.4068\n",
            "Final Train Epoch 4, Graph 46500/50382, Loss: 0.0526\n",
            "Final Train Epoch 4, Graph 47000/50382, Loss: 0.0555\n",
            "Final Train Epoch 4, Graph 47500/50382, Loss: 0.0492\n",
            "Final Train Epoch 4, Graph 48000/50382, Loss: 0.0477\n",
            "Final Train Epoch 4, Graph 48500/50382, Loss: 0.7839\n",
            "Final Train Epoch 4, Graph 49000/50382, Loss: 0.0556\n",
            "Final Train Epoch 4, Graph 49500/50382, Loss: 4.9055\n",
            "Final Train Epoch 4, Graph 50000/50382, Loss: 0.0595\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 4/200, Training Loss: 1.6306, Validation Accuracy: 0.4713\n",
            "Final Train Epoch 5, Graph 500/50382, Loss: 0.5790\n",
            "Final Train Epoch 5, Graph 1000/50382, Loss: 2.0910\n",
            "Final Train Epoch 5, Graph 1500/50382, Loss: 4.6602\n",
            "Final Train Epoch 5, Graph 2000/50382, Loss: 0.9695\n",
            "Final Train Epoch 5, Graph 2500/50382, Loss: 1.5063\n",
            "Final Train Epoch 5, Graph 3000/50382, Loss: 0.8808\n",
            "Final Train Epoch 5, Graph 3500/50382, Loss: 2.2953\n",
            "Final Train Epoch 5, Graph 4000/50382, Loss: 3.4197\n",
            "Final Train Epoch 5, Graph 4500/50382, Loss: 0.1857\n",
            "Final Train Epoch 5, Graph 5000/50382, Loss: 0.0676\n",
            "Final Train Epoch 5, Graph 5500/50382, Loss: 0.0461\n",
            "Final Train Epoch 5, Graph 6000/50382, Loss: 4.3287\n",
            "Final Train Epoch 5, Graph 6500/50382, Loss: 0.0524\n",
            "Final Train Epoch 5, Graph 7000/50382, Loss: 2.9249\n",
            "Final Train Epoch 5, Graph 7500/50382, Loss: 1.9479\n",
            "Final Train Epoch 5, Graph 8000/50382, Loss: 0.8179\n",
            "Final Train Epoch 5, Graph 8500/50382, Loss: 0.0817\n",
            "Final Train Epoch 5, Graph 9000/50382, Loss: 0.0560\n",
            "Final Train Epoch 5, Graph 9500/50382, Loss: 0.2865\n",
            "Final Train Epoch 5, Graph 10000/50382, Loss: 0.0503\n",
            "Final Train Epoch 5, Graph 10500/50382, Loss: 1.2313\n",
            "Final Train Epoch 5, Graph 11000/50382, Loss: 0.0761\n",
            "Final Train Epoch 5, Graph 11500/50382, Loss: 3.8125\n",
            "Final Train Epoch 5, Graph 12000/50382, Loss: 3.5257\n",
            "Final Train Epoch 5, Graph 12500/50382, Loss: 4.1338\n",
            "Final Train Epoch 5, Graph 13000/50382, Loss: 0.1070\n",
            "Final Train Epoch 5, Graph 13500/50382, Loss: 1.4359\n",
            "Final Train Epoch 5, Graph 14000/50382, Loss: 3.2799\n",
            "Final Train Epoch 5, Graph 14500/50382, Loss: 0.0573\n",
            "Final Train Epoch 5, Graph 15000/50382, Loss: 0.9646\n",
            "Final Train Epoch 5, Graph 15500/50382, Loss: 4.4598\n",
            "Final Train Epoch 5, Graph 16000/50382, Loss: 0.0544\n",
            "Final Train Epoch 5, Graph 16500/50382, Loss: 0.3659\n",
            "Final Train Epoch 5, Graph 17000/50382, Loss: 5.5983\n",
            "Final Train Epoch 5, Graph 17500/50382, Loss: 4.3799\n",
            "Final Train Epoch 5, Graph 18000/50382, Loss: 0.2705\n",
            "Final Train Epoch 5, Graph 18500/50382, Loss: 0.1208\n",
            "Final Train Epoch 5, Graph 19000/50382, Loss: 0.1002\n",
            "Final Train Epoch 5, Graph 19500/50382, Loss: 0.0597\n",
            "Final Train Epoch 5, Graph 20000/50382, Loss: 0.1257\n",
            "Final Train Epoch 5, Graph 20500/50382, Loss: 4.2889\n",
            "Final Train Epoch 5, Graph 21000/50382, Loss: 2.1881\n",
            "Final Train Epoch 5, Graph 21500/50382, Loss: 4.4428\n",
            "Final Train Epoch 5, Graph 22000/50382, Loss: 0.2471\n",
            "Final Train Epoch 5, Graph 22500/50382, Loss: 2.1826\n",
            "Final Train Epoch 5, Graph 23000/50382, Loss: 0.0576\n",
            "Final Train Epoch 5, Graph 23500/50382, Loss: 0.0530\n",
            "Final Train Epoch 5, Graph 24000/50382, Loss: 0.8634\n",
            "Final Train Epoch 5, Graph 24500/50382, Loss: 4.0372\n",
            "Final Train Epoch 5, Graph 25000/50382, Loss: 1.6560\n",
            "Final Train Epoch 5, Graph 25500/50382, Loss: 0.0405\n",
            "Final Train Epoch 5, Graph 26000/50382, Loss: 2.1093\n",
            "Final Train Epoch 5, Graph 26500/50382, Loss: 0.0664\n",
            "Final Train Epoch 5, Graph 27000/50382, Loss: 0.0805\n",
            "Final Train Epoch 5, Graph 27500/50382, Loss: 0.0508\n",
            "Final Train Epoch 5, Graph 28000/50382, Loss: 0.0722\n",
            "Final Train Epoch 5, Graph 28500/50382, Loss: 5.0477\n",
            "Final Train Epoch 5, Graph 29000/50382, Loss: 0.0532\n",
            "Final Train Epoch 5, Graph 29500/50382, Loss: 0.0534\n",
            "Final Train Epoch 5, Graph 30000/50382, Loss: 0.0496\n",
            "Final Train Epoch 5, Graph 30500/50382, Loss: 0.1701\n",
            "Final Train Epoch 5, Graph 31000/50382, Loss: 4.1651\n",
            "Final Train Epoch 5, Graph 31500/50382, Loss: 0.0517\n",
            "Final Train Epoch 5, Graph 32000/50382, Loss: 0.0495\n",
            "Final Train Epoch 5, Graph 32500/50382, Loss: 0.0543\n",
            "Final Train Epoch 5, Graph 33000/50382, Loss: 1.9767\n",
            "Final Train Epoch 5, Graph 33500/50382, Loss: 1.5166\n",
            "Final Train Epoch 5, Graph 34000/50382, Loss: 0.2065\n",
            "Final Train Epoch 5, Graph 34500/50382, Loss: 0.0556\n",
            "Final Train Epoch 5, Graph 35000/50382, Loss: 2.0711\n",
            "Final Train Epoch 5, Graph 35500/50382, Loss: 4.6376\n",
            "Final Train Epoch 5, Graph 36000/50382, Loss: 4.4009\n",
            "Final Train Epoch 5, Graph 36500/50382, Loss: 0.0394\n",
            "Final Train Epoch 5, Graph 37000/50382, Loss: 0.0619\n",
            "Final Train Epoch 5, Graph 37500/50382, Loss: 0.0591\n",
            "Final Train Epoch 5, Graph 38000/50382, Loss: 0.0775\n",
            "Final Train Epoch 5, Graph 38500/50382, Loss: 2.0002\n",
            "Final Train Epoch 5, Graph 39000/50382, Loss: 0.0505\n",
            "Final Train Epoch 5, Graph 39500/50382, Loss: 4.4387\n",
            "Final Train Epoch 5, Graph 40000/50382, Loss: 0.0615\n",
            "Final Train Epoch 5, Graph 40500/50382, Loss: 0.0537\n",
            "Final Train Epoch 5, Graph 41000/50382, Loss: 1.1255\n",
            "Final Train Epoch 5, Graph 41500/50382, Loss: 0.2259\n",
            "Final Train Epoch 5, Graph 42000/50382, Loss: 0.0466\n",
            "Final Train Epoch 5, Graph 42500/50382, Loss: 1.4652\n",
            "Final Train Epoch 5, Graph 43000/50382, Loss: 1.1617\n",
            "Final Train Epoch 5, Graph 43500/50382, Loss: 0.5416\n",
            "Final Train Epoch 5, Graph 44000/50382, Loss: 0.0425\n",
            "Final Train Epoch 5, Graph 44500/50382, Loss: 1.3643\n",
            "Final Train Epoch 5, Graph 45000/50382, Loss: 1.8036\n",
            "Final Train Epoch 5, Graph 45500/50382, Loss: 4.2991\n",
            "Final Train Epoch 5, Graph 46000/50382, Loss: 0.2495\n",
            "Final Train Epoch 5, Graph 46500/50382, Loss: 0.0479\n",
            "Final Train Epoch 5, Graph 47000/50382, Loss: 0.0505\n",
            "Final Train Epoch 5, Graph 47500/50382, Loss: 0.0653\n",
            "Final Train Epoch 5, Graph 48000/50382, Loss: 0.0516\n",
            "Final Train Epoch 5, Graph 48500/50382, Loss: 0.2668\n",
            "Final Train Epoch 5, Graph 49000/50382, Loss: 0.0506\n",
            "Final Train Epoch 5, Graph 49500/50382, Loss: 5.1838\n",
            "Final Train Epoch 5, Graph 50000/50382, Loss: 0.0682\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 5/200, Training Loss: 1.6337, Validation Accuracy: 0.4708\n",
            "Final Train Epoch 6, Graph 500/50382, Loss: 0.1919\n",
            "Final Train Epoch 6, Graph 1000/50382, Loss: 3.3848\n",
            "Final Train Epoch 6, Graph 1500/50382, Loss: 3.3703\n",
            "Final Train Epoch 6, Graph 2000/50382, Loss: 0.8963\n",
            "Final Train Epoch 6, Graph 2500/50382, Loss: 1.0179\n",
            "Final Train Epoch 6, Graph 3000/50382, Loss: 1.0942\n",
            "Final Train Epoch 6, Graph 3500/50382, Loss: 2.2711\n",
            "Final Train Epoch 6, Graph 4000/50382, Loss: 4.0823\n",
            "Final Train Epoch 6, Graph 4500/50382, Loss: 0.1689\n",
            "Final Train Epoch 6, Graph 5000/50382, Loss: 0.0529\n",
            "Final Train Epoch 6, Graph 5500/50382, Loss: 0.0356\n",
            "Final Train Epoch 6, Graph 6000/50382, Loss: 4.0772\n",
            "Final Train Epoch 6, Graph 6500/50382, Loss: 0.0534\n",
            "Final Train Epoch 6, Graph 7000/50382, Loss: 2.7404\n",
            "Final Train Epoch 6, Graph 7500/50382, Loss: 1.9086\n",
            "Final Train Epoch 6, Graph 8000/50382, Loss: 2.3636\n",
            "Final Train Epoch 6, Graph 8500/50382, Loss: 0.0482\n",
            "Final Train Epoch 6, Graph 9000/50382, Loss: 0.0494\n",
            "Final Train Epoch 6, Graph 9500/50382, Loss: 0.4638\n",
            "Final Train Epoch 6, Graph 10000/50382, Loss: 0.0641\n",
            "Final Train Epoch 6, Graph 10500/50382, Loss: 1.6281\n",
            "Final Train Epoch 6, Graph 11000/50382, Loss: 0.1306\n",
            "Final Train Epoch 6, Graph 11500/50382, Loss: 2.9968\n",
            "Final Train Epoch 6, Graph 12000/50382, Loss: 3.3505\n",
            "Final Train Epoch 6, Graph 12500/50382, Loss: 3.7243\n",
            "Final Train Epoch 6, Graph 13000/50382, Loss: 0.0649\n",
            "Final Train Epoch 6, Graph 13500/50382, Loss: 1.6716\n",
            "Final Train Epoch 6, Graph 14000/50382, Loss: 0.3696\n",
            "Final Train Epoch 6, Graph 14500/50382, Loss: 0.0597\n",
            "Final Train Epoch 6, Graph 15000/50382, Loss: 1.5472\n",
            "Final Train Epoch 6, Graph 15500/50382, Loss: 4.4644\n",
            "Final Train Epoch 6, Graph 16000/50382, Loss: 0.0612\n",
            "Final Train Epoch 6, Graph 16500/50382, Loss: 1.1682\n",
            "Final Train Epoch 6, Graph 17000/50382, Loss: 2.9436\n",
            "Final Train Epoch 6, Graph 17500/50382, Loss: 4.2718\n",
            "Final Train Epoch 6, Graph 18000/50382, Loss: 0.4730\n",
            "Final Train Epoch 6, Graph 18500/50382, Loss: 0.1956\n",
            "Final Train Epoch 6, Graph 19000/50382, Loss: 0.0405\n",
            "Final Train Epoch 6, Graph 19500/50382, Loss: 0.0564\n",
            "Final Train Epoch 6, Graph 20000/50382, Loss: 0.0717\n",
            "Final Train Epoch 6, Graph 20500/50382, Loss: 4.3924\n",
            "Final Train Epoch 6, Graph 21000/50382, Loss: 1.6730\n",
            "Final Train Epoch 6, Graph 21500/50382, Loss: 3.7289\n",
            "Final Train Epoch 6, Graph 22000/50382, Loss: 0.1635\n",
            "Final Train Epoch 6, Graph 22500/50382, Loss: 2.2540\n",
            "Final Train Epoch 6, Graph 23000/50382, Loss: 0.0883\n",
            "Final Train Epoch 6, Graph 23500/50382, Loss: 0.0625\n",
            "Final Train Epoch 6, Graph 24000/50382, Loss: 0.4823\n",
            "Final Train Epoch 6, Graph 24500/50382, Loss: 3.6223\n",
            "Final Train Epoch 6, Graph 25000/50382, Loss: 1.8063\n",
            "Final Train Epoch 6, Graph 25500/50382, Loss: 0.0353\n",
            "Final Train Epoch 6, Graph 26000/50382, Loss: 1.2628\n",
            "Final Train Epoch 6, Graph 26500/50382, Loss: 0.5755\n",
            "Final Train Epoch 6, Graph 27000/50382, Loss: 0.0645\n",
            "Final Train Epoch 6, Graph 27500/50382, Loss: 0.0782\n",
            "Final Train Epoch 6, Graph 28000/50382, Loss: 0.0525\n",
            "Final Train Epoch 6, Graph 28500/50382, Loss: 3.7300\n",
            "Final Train Epoch 6, Graph 29000/50382, Loss: 0.0405\n",
            "Final Train Epoch 6, Graph 29500/50382, Loss: 0.0557\n",
            "Final Train Epoch 6, Graph 30000/50382, Loss: 0.0614\n",
            "Final Train Epoch 6, Graph 30500/50382, Loss: 0.0619\n",
            "Final Train Epoch 6, Graph 31000/50382, Loss: 4.2850\n",
            "Final Train Epoch 6, Graph 31500/50382, Loss: 0.0526\n",
            "Final Train Epoch 6, Graph 32000/50382, Loss: 0.0465\n",
            "Final Train Epoch 6, Graph 32500/50382, Loss: 0.0426\n",
            "Final Train Epoch 6, Graph 33000/50382, Loss: 2.1784\n",
            "Final Train Epoch 6, Graph 33500/50382, Loss: 1.2853\n",
            "Final Train Epoch 6, Graph 34000/50382, Loss: 0.1333\n",
            "Final Train Epoch 6, Graph 34500/50382, Loss: 0.0461\n",
            "Final Train Epoch 6, Graph 35000/50382, Loss: 3.9088\n",
            "Final Train Epoch 6, Graph 35500/50382, Loss: 4.9926\n",
            "Final Train Epoch 6, Graph 36000/50382, Loss: 4.1489\n",
            "Final Train Epoch 6, Graph 36500/50382, Loss: 0.0695\n",
            "Final Train Epoch 6, Graph 37000/50382, Loss: 0.0829\n",
            "Final Train Epoch 6, Graph 37500/50382, Loss: 0.0613\n",
            "Final Train Epoch 6, Graph 38000/50382, Loss: 0.0596\n",
            "Final Train Epoch 6, Graph 38500/50382, Loss: 1.1273\n",
            "Final Train Epoch 6, Graph 39000/50382, Loss: 0.0757\n",
            "Final Train Epoch 6, Graph 39500/50382, Loss: 4.5150\n",
            "Final Train Epoch 6, Graph 40000/50382, Loss: 0.0544\n",
            "Final Train Epoch 6, Graph 40500/50382, Loss: 0.0575\n",
            "Final Train Epoch 6, Graph 41000/50382, Loss: 2.1281\n",
            "Final Train Epoch 6, Graph 41500/50382, Loss: 0.1058\n",
            "Final Train Epoch 6, Graph 42000/50382, Loss: 0.0651\n",
            "Final Train Epoch 6, Graph 42500/50382, Loss: 1.5854\n",
            "Final Train Epoch 6, Graph 43000/50382, Loss: 0.5312\n",
            "Final Train Epoch 6, Graph 43500/50382, Loss: 0.2578\n",
            "Final Train Epoch 6, Graph 44000/50382, Loss: 0.0602\n",
            "Final Train Epoch 6, Graph 44500/50382, Loss: 1.4436\n",
            "Final Train Epoch 6, Graph 45000/50382, Loss: 1.6297\n",
            "Final Train Epoch 6, Graph 45500/50382, Loss: 3.5619\n",
            "Final Train Epoch 6, Graph 46000/50382, Loss: 0.4269\n",
            "Final Train Epoch 6, Graph 46500/50382, Loss: 0.0641\n",
            "Final Train Epoch 6, Graph 47000/50382, Loss: 0.0653\n",
            "Final Train Epoch 6, Graph 47500/50382, Loss: 0.0547\n",
            "Final Train Epoch 6, Graph 48000/50382, Loss: 0.0458\n",
            "Final Train Epoch 6, Graph 48500/50382, Loss: 1.5173\n",
            "Final Train Epoch 6, Graph 49000/50382, Loss: 0.0614\n",
            "Final Train Epoch 6, Graph 49500/50382, Loss: 5.1906\n",
            "Final Train Epoch 6, Graph 50000/50382, Loss: 0.9024\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 6/200, Training Loss: 1.6322, Validation Accuracy: 0.4763\n",
            "Final Train Epoch 7, Graph 500/50382, Loss: 0.4510\n",
            "Final Train Epoch 7, Graph 1000/50382, Loss: 1.4748\n",
            "Final Train Epoch 7, Graph 1500/50382, Loss: 3.8395\n",
            "Final Train Epoch 7, Graph 2000/50382, Loss: 0.7199\n",
            "Final Train Epoch 7, Graph 2500/50382, Loss: 0.9258\n",
            "Final Train Epoch 7, Graph 3000/50382, Loss: 1.7642\n",
            "Final Train Epoch 7, Graph 3500/50382, Loss: 2.3488\n",
            "Final Train Epoch 7, Graph 4000/50382, Loss: 4.2207\n",
            "Final Train Epoch 7, Graph 4500/50382, Loss: 0.1614\n",
            "Final Train Epoch 7, Graph 5000/50382, Loss: 0.0562\n",
            "Final Train Epoch 7, Graph 5500/50382, Loss: 0.0453\n",
            "Final Train Epoch 7, Graph 6000/50382, Loss: 1.8826\n",
            "Final Train Epoch 7, Graph 6500/50382, Loss: 0.0633\n",
            "Final Train Epoch 7, Graph 7000/50382, Loss: 4.6703\n",
            "Final Train Epoch 7, Graph 7500/50382, Loss: 1.8855\n",
            "Final Train Epoch 7, Graph 8000/50382, Loss: 1.2472\n",
            "Final Train Epoch 7, Graph 8500/50382, Loss: 0.0420\n",
            "Final Train Epoch 7, Graph 9000/50382, Loss: 0.0474\n",
            "Final Train Epoch 7, Graph 9500/50382, Loss: 0.4136\n",
            "Final Train Epoch 7, Graph 10000/50382, Loss: 0.0446\n",
            "Final Train Epoch 7, Graph 10500/50382, Loss: 1.6257\n",
            "Final Train Epoch 7, Graph 11000/50382, Loss: 0.0529\n",
            "Final Train Epoch 7, Graph 11500/50382, Loss: 4.4131\n",
            "Final Train Epoch 7, Graph 12000/50382, Loss: 3.2860\n",
            "Final Train Epoch 7, Graph 12500/50382, Loss: 3.0222\n",
            "Final Train Epoch 7, Graph 13000/50382, Loss: 0.0525\n",
            "Final Train Epoch 7, Graph 13500/50382, Loss: 2.6285\n",
            "Final Train Epoch 7, Graph 14000/50382, Loss: 3.0204\n",
            "Final Train Epoch 7, Graph 14500/50382, Loss: 0.0526\n",
            "Final Train Epoch 7, Graph 15000/50382, Loss: 0.5628\n",
            "Final Train Epoch 7, Graph 15500/50382, Loss: 3.8037\n",
            "Final Train Epoch 7, Graph 16000/50382, Loss: 0.0553\n",
            "Final Train Epoch 7, Graph 16500/50382, Loss: 0.5982\n",
            "Final Train Epoch 7, Graph 17000/50382, Loss: 5.5075\n",
            "Final Train Epoch 7, Graph 17500/50382, Loss: 4.2086\n",
            "Final Train Epoch 7, Graph 18000/50382, Loss: 0.9606\n",
            "Final Train Epoch 7, Graph 18500/50382, Loss: 0.2709\n",
            "Final Train Epoch 7, Graph 19000/50382, Loss: 0.0653\n",
            "Final Train Epoch 7, Graph 19500/50382, Loss: 0.0600\n",
            "Final Train Epoch 7, Graph 20000/50382, Loss: 0.0556\n",
            "Final Train Epoch 7, Graph 20500/50382, Loss: 4.3141\n",
            "Final Train Epoch 7, Graph 21000/50382, Loss: 1.5514\n",
            "Final Train Epoch 7, Graph 21500/50382, Loss: 4.5020\n",
            "Final Train Epoch 7, Graph 22000/50382, Loss: 0.3112\n",
            "Final Train Epoch 7, Graph 22500/50382, Loss: 2.2138\n",
            "Final Train Epoch 7, Graph 23000/50382, Loss: 0.0467\n",
            "Final Train Epoch 7, Graph 23500/50382, Loss: 0.0576\n",
            "Final Train Epoch 7, Graph 24000/50382, Loss: 0.3563\n",
            "Final Train Epoch 7, Graph 24500/50382, Loss: 4.1954\n",
            "Final Train Epoch 7, Graph 25000/50382, Loss: 2.0719\n",
            "Final Train Epoch 7, Graph 25500/50382, Loss: 0.0513\n",
            "Final Train Epoch 7, Graph 26000/50382, Loss: 1.1634\n",
            "Final Train Epoch 7, Graph 26500/50382, Loss: 0.0698\n",
            "Final Train Epoch 7, Graph 27000/50382, Loss: 0.0632\n",
            "Final Train Epoch 7, Graph 27500/50382, Loss: 0.0498\n",
            "Final Train Epoch 7, Graph 28000/50382, Loss: 0.0657\n",
            "Final Train Epoch 7, Graph 28500/50382, Loss: 4.6627\n",
            "Final Train Epoch 7, Graph 29000/50382, Loss: 0.2314\n",
            "Final Train Epoch 7, Graph 29500/50382, Loss: 0.0635\n",
            "Final Train Epoch 7, Graph 30000/50382, Loss: 0.0460\n",
            "Final Train Epoch 7, Graph 30500/50382, Loss: 0.0834\n",
            "Final Train Epoch 7, Graph 31000/50382, Loss: 3.7132\n",
            "Final Train Epoch 7, Graph 31500/50382, Loss: 0.0409\n",
            "Final Train Epoch 7, Graph 32000/50382, Loss: 0.0528\n",
            "Final Train Epoch 7, Graph 32500/50382, Loss: 0.0432\n",
            "Final Train Epoch 7, Graph 33000/50382, Loss: 1.4250\n",
            "Final Train Epoch 7, Graph 33500/50382, Loss: 1.4006\n",
            "Final Train Epoch 7, Graph 34000/50382, Loss: 0.6154\n",
            "Final Train Epoch 7, Graph 34500/50382, Loss: 0.0590\n",
            "Final Train Epoch 7, Graph 35000/50382, Loss: 2.0625\n",
            "Final Train Epoch 7, Graph 35500/50382, Loss: 5.1266\n",
            "Final Train Epoch 7, Graph 36000/50382, Loss: 4.6171\n",
            "Final Train Epoch 7, Graph 36500/50382, Loss: 0.0433\n",
            "Final Train Epoch 7, Graph 37000/50382, Loss: 0.0637\n",
            "Final Train Epoch 7, Graph 37500/50382, Loss: 0.0627\n",
            "Final Train Epoch 7, Graph 38000/50382, Loss: 0.0491\n",
            "Final Train Epoch 7, Graph 38500/50382, Loss: 1.9818\n",
            "Final Train Epoch 7, Graph 39000/50382, Loss: 0.0418\n",
            "Final Train Epoch 7, Graph 39500/50382, Loss: 4.5532\n",
            "Final Train Epoch 7, Graph 40000/50382, Loss: 0.2604\n",
            "Final Train Epoch 7, Graph 40500/50382, Loss: 0.0779\n",
            "Final Train Epoch 7, Graph 41000/50382, Loss: 2.9810\n",
            "Final Train Epoch 7, Graph 41500/50382, Loss: 0.1050\n",
            "Final Train Epoch 7, Graph 42000/50382, Loss: 0.0633\n",
            "Final Train Epoch 7, Graph 42500/50382, Loss: 1.7922\n",
            "Final Train Epoch 7, Graph 43000/50382, Loss: 1.1505\n",
            "Final Train Epoch 7, Graph 43500/50382, Loss: 0.2850\n",
            "Final Train Epoch 7, Graph 44000/50382, Loss: 0.0506\n",
            "Final Train Epoch 7, Graph 44500/50382, Loss: 1.3262\n",
            "Final Train Epoch 7, Graph 45000/50382, Loss: 1.2547\n",
            "Final Train Epoch 7, Graph 45500/50382, Loss: 4.1366\n",
            "Final Train Epoch 7, Graph 46000/50382, Loss: 0.2954\n",
            "Final Train Epoch 7, Graph 46500/50382, Loss: 0.0579\n",
            "Final Train Epoch 7, Graph 47000/50382, Loss: 0.0934\n",
            "Final Train Epoch 7, Graph 47500/50382, Loss: 0.0655\n",
            "Final Train Epoch 7, Graph 48000/50382, Loss: 0.0536\n",
            "Final Train Epoch 7, Graph 48500/50382, Loss: 0.4355\n",
            "Final Train Epoch 7, Graph 49000/50382, Loss: 0.0627\n",
            "Final Train Epoch 7, Graph 49500/50382, Loss: 5.5712\n",
            "Final Train Epoch 7, Graph 50000/50382, Loss: 0.0525\n",
            "Skipped 0 out of 50382 graphs during training.\n",
            "Epoch 7/200, Training Loss: 1.6326, Validation Accuracy: 0.4758\n",
            "Final Train Epoch 8, Graph 500/50382, Loss: 0.3639\n",
            "Final Train Epoch 8, Graph 1000/50382, Loss: 2.8084\n",
            "Final Train Epoch 8, Graph 1500/50382, Loss: 2.5177\n",
            "Final Train Epoch 8, Graph 2000/50382, Loss: 0.6110\n",
            "Final Train Epoch 8, Graph 2500/50382, Loss: 1.2381\n",
            "Final Train Epoch 8, Graph 3000/50382, Loss: 0.8168\n",
            "Final Train Epoch 8, Graph 3500/50382, Loss: 2.8372\n",
            "Final Train Epoch 8, Graph 4000/50382, Loss: 2.8491\n",
            "Final Train Epoch 8, Graph 4500/50382, Loss: 0.1305\n",
            "Final Train Epoch 8, Graph 5000/50382, Loss: 0.0476\n",
            "Final Train Epoch 8, Graph 5500/50382, Loss: 0.0398\n",
            "Final Train Epoch 8, Graph 6000/50382, Loss: 3.5741\n",
            "Final Train Epoch 8, Graph 6500/50382, Loss: 0.0615\n",
            "Final Train Epoch 8, Graph 7000/50382, Loss: 3.7566\n",
            "Final Train Epoch 8, Graph 7500/50382, Loss: 1.9171\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2db4969f13ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-2db4969f13ac>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(graphs, labels, epoch)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0moptimizer_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mvalid_graphs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_graph_capture_health_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_built\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         ):\n\u001b[1;32m    436\u001b[0m             \u001b[0mcapturing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_current_stream_capturing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_compiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_nvml_based_avail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# The user has set an env variable to request this availability check that attempts to avoid fork poisoning by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# using NVML at the cost of a weaker CUDA availability assessment. Note that if NVML discovery/initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_nvml_based_avail\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_nvml_based_avail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PYTORCH_NVML_BASED_CUDA_CHECK\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36mgetenv\u001b[0;34m(key, default)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoWYqq/4ZZ/y5iPkl/ROGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}